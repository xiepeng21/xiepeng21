<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>【书山有路-1】学会提问</title>
    <link href="/posts/4fc14101/"/>
    <url>/posts/4fc14101/</url>
    
    <content type="html"><![CDATA[<p>我们一起来读《学会提问》这本书吧。作者是美国的尼尔·布朗和美国的斯图尔特·基利，由机械工业出版社出版。</p><span id="more"></span><p><img src="/../images/%E5%AD%A6%E4%BC%9A%E6%8F%90%E9%97%AE.png" alt="学会提问"></p><p>之前很喜欢看“杨澜访谈录”，她提的问题，提问的方式，给人一种做了很多准备，经过认真思考的感觉，也能让被采访者感觉到舒服。这是需要学习的。</p><p>“你们需要通过理科课程的学习，获取知识和解决问题的技能，治疗癌症和艾滋病，开发新能源技术，和保护人类的生存环境。你们需要从文科学习中培养洞察力和批判性思维，消灭贫困、愚昧、犯罪和歧视现象。”–奥巴马『美国某高中开学演讲』</p><h3 id="一、提出好问题"><a href="#一、提出好问题" class="headerlink" title="一、提出好问题"></a>一、提出好问题</h3><p>理想的效果是，经常提出问题将成为你的身份标记和存在宣言，而不仅是你从书本上学来的一套本领。现实情况下，很多人不知道如何提问、不知道何时提问、担心提问后别人如何看待自己、自以为学会了，没问题问、根本就不关心讨论的话题，无问题可问等等。听别人讲话时，就可以通过提问，让自己保持思考，保持专注。</p><p>带着问题去读书。</p><p>淘金式思维重视在获取知识的过程中与知识展开积极互动，海绵式思维强调单纯的知识获取结果。实际操作过程中，往往是淘金式思维和海绵式思维结合的方式进行，首先要有足够的沙子供你淘金，沙子本身是普通的，但是里面的金子是金贵的，通过我们的慧眼，来筛选和识别沙中的黄金。</p><h3 id="二、问问论题和结论是什么"><a href="#二、问问论题和结论是什么" class="headerlink" title="二、问问论题和结论是什么"></a>二、问问论题和结论是什么</h3><p>要成为会批判性思考问题的人，第一步就得培养找准论题和结论的能力。</p><p>别人的结论也就是他试图传递给你的信息，目的在于塑造你的信念和行为。</p><p>论题的两种类型：描述性论题和规定性论题，前者是有关世界过去、现在或未来是什么样的问题，后者是有关世界应该是什么样的问题。</p><h3 id="三、理由是什么"><a href="#三、理由是什么" class="headerlink" title="三、理由是什么"></a>三、理由是什么</h3><p>我们人类总是好奇为什么有人要做出这样的决策，为什么会有人会持有这样的观点，而理由则为满足人们这样的好奇心提供了答案。</p><p>所谓理由，就是指用来支撑或证明结论的看法、证据、隐喻、类比和其他陈述。你会发现一个理由越长越复杂，复述一下就越有助于你准确找到这个理由。</p><p>论证大厦的三大柱石：论题、结论、理由。一个人有没有头脑，主要的标志就要看他能否提供充足的证据来支撑他的看法，尤其当这些看法存在争议没有定论时更是这样。</p><h3 id="四、有哪些词语意思不明确"><a href="#四、有哪些词语意思不明确" class="headerlink" title="四、有哪些词语意思不明确"></a>四、有哪些词语意思不明确</h3><p>如果你能找准一位作者或演说者的结论和理由，那么你已经大踏步迈向理性思考的终极目标–形成自己的理性判断。</p><p>准确辨认关键词或短语的确切含义是决定你是否同意别人观点的必要步骤。</p><p>我们常常误解所读的文章或听到的言论的意思，因为我们常常想当然地以为很多词的意思都是显而易见的。</p><h3 id="五、什么是价值观假设和描述性假设"><a href="#五、什么是价值观假设和描述性假设" class="headerlink" title="五、什么是价值观假设和描述性假设"></a>五、什么是价值观假设和描述性假设</h3><p>价值观假设，是指这个世界应该是什么样。</p><p>描述性假设，是指这个世界过去、现在、未来真实情况是什么样。</p><h3 id="六、推理过程中有没有谬误"><a href="#六、推理过程中有没有谬误" class="headerlink" title="六、推理过程中有没有谬误"></a>六、推理过程中有没有谬误</h3><p>人身攻击谬误指针对个人的人身攻击或侮辱，而不是直接反驳其提供的理由。</p><p>公众常常并没有对一个问题做出足够的研究使他们能进行合乎逻辑的判断。</p><p>除非我们知道这些权威对这一论题拥有特别的专门知识，否则我们就要将这个理由视为谬误。这种类型的谬误叫做诉诸可疑权威谬误。</p><h3 id="七、证据的效力如何"><a href="#七、证据的效力如何" class="headerlink" title="七、证据的效力如何"></a>七、证据的效力如何</h3><p>一个断言的证据数量越多、质量越高，我们可以信赖它的程度就越高，我们也就越可以称这样的断言为“事实”。</p><p>怎么确定其可靠性，我们通常会问如下问题：</p><ul><li><p>你的证明是什么</p></li><li><p>你怎么知道它是真的</p></li><li><p>证据在哪里</p></li><li><p>你为什么相信它</p></li><li><p>你确信它是真的吗</p></li><li><p>你能证明吗</p></li></ul><p>所谓直觉，就是我们相信自己对某件事有直接的洞察力，却不能有意识地说出理由的过程。</p><h3 id="八、个人观察与研究报告的效力如何"><a href="#八、个人观察与研究报告的效力如何" class="headerlink" title="八、个人观察与研究报告的效力如何"></a>八、个人观察与研究报告的效力如何</h3><p>一种有价值的证据就是个人观察，它是很多日常推理和科学研究的基础。我们所“见”所说的都是经过一系列的价值观、偏见、态度和期望值过滤后剩下来的东西。</p><p>有一种类型的权威意见常常大量依赖于观察，并且常常占有特殊的分量，那就是研究报告。</p><p>科学研究强调可验证性、可控性和精确性。</p><h3 id="九、有没有替代原因"><a href="#九、有没有替代原因" class="headerlink" title="九、有没有替代原因"></a>九、有没有替代原因</h3><p>要想弄清楚一件事，就必须弄清楚引起这件事的原因。很多事件紧随在其他事件后面发生，却并不是由前面事件所引发的，并不能证明两者之间有因果关系，可能只是一个巧合。</p><p>可能的原因不止一个，这往往出现在我们日常的人际交往，以往或正在发生的世界大事，科学研究的结果。别人行为的动因，可能既来自其内部因素的作用（如个人性格特点），也可能来自外部因素的作用（如环境的影响）。</p><p>大部分持论者只给你那些他们喜欢的原因，独立思考的读者或者听众必须自己找出替代原因。找到多个替代原因可以让批判性思考的人真正变得理智而谦逊。寻找替代原因时，考虑采用不同的视角，关注事件涉及的不同利益方。</p><h3 id="十、-数据会欺骗你吗"><a href="#十、-数据会欺骗你吗" class="headerlink" title="十、 数据会欺骗你吗"></a>十、 数据会欺骗你吗</h3><p>统计数据能，而且经常会撒谎，它们并不真实代表它们想要证明的一切。当你遇到听起来让人动心的数字或者百分比，一定要当心。当你遇到数据的时候，还应问一句“有什么相关的信息缺失了”。统计数据往往只能是基于事实做出的一些估计。</p><p>数据的来源会直接影响到所得出结果的可靠性，所以我们在对统计数据的结果做出反应前，我们需要问一问数据是怎么得来的？</p><p>不仅判断一个平均值时平均数、中位数还是众数非常重要，判定最小数值和最大数值之间的差距（即全距range）以及每个数值出现的频率（数值分布），常常也显得十分重要。比如，知道病人存活时间的完整分布可能会改变这名癌症患者对未来的看法。</p><h3 id="十一、-有哪些重要信息被省略了"><a href="#十一、-有哪些重要信息被省略了" class="headerlink" title="十一、 有哪些重要信息被省略了"></a>十一、 有哪些重要信息被省略了</h3><p>几乎所有的结论或者产品都有一些正面的特点，真正的自主思考需要我们坚持不懈地寻找作者到底隐瞒了什么信息，不论他是无心省略还是有意隐瞒。</p><p>重要的省略信息就是那些影响到推理过程的信息。考虑一件事情是否有负面效果，这样的问题能让我们在追随被提倡的行动的浪潮时停下来思考思考。</p><p>批判思考的人看重好奇心和合理性，那些力图说服你的人常常想要打消你的好奇心，鼓励你依靠违反常理的情绪来形成你的选择。</p><h3 id="十二、能得出哪些合理的结论"><a href="#十二、能得出哪些合理的结论" class="headerlink" title="十二、能得出哪些合理的结论"></a>十二、能得出哪些合理的结论</h3><p>因为我们所有人都具有不同水平的认知准确度、不同的参照体系和先验知识，对哪些假设更为可取我们不断表达不同意见。</p><p>运用两分法思考问题的人常常是一成不变的，容不得异议存在，因为他们不能理解语境对特定答案产生的重要性。</p><p>你可以使用“什么时候”、“什么地点”和“为什么”等问题来帮助你得出备选的结论。一旦我们认识到种种可能存在的结论，我们每个人都会体验到个人选择得到提升的那种激动。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>大声说出你的关键问题，好像你对此充满了好奇。</p><p>在你发现一个问题的最佳答案之后，请依据这个答案采取行动。</p><p>让批判性思维成为创造新身份的基石，你会为这个新身份而感到骄傲自豪。</p>]]></content>
    
    
    <categories>
      
      <category>随笔感悟</category>
      
    </categories>
    
    
    <tags>
      
      <tag>书山有路</tag>
      
      <tag>读书笔记</tag>
      
      <tag>学会提问</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>从ChatGPT谈起</title>
    <link href="/posts/98df0397/"/>
    <url>/posts/98df0397/</url>
    
    <content type="html"><![CDATA[<p>ChatGPT来了，Are you ready?</p><span id="more"></span><p>今年以来，以ChatGPT为代表的大模型，掀起了大模型的研究、试用、商用、讨论大浪潮，一浪接一浪，不断出现的大模型让人眼花缭乱，犹如刘姥姥进大观园，冲击着我们过往的认知，一方面让人感叹技术的快速发展，带来了更多的机会和惊喜，另一方面让人思考技术背后的隐患，以及可能会带来的对人类社会的危害。</p><p>今天将回到这次大模型浪潮的主角，<strong>ChatGPT</strong>,让我一起来探索它、使用它、分析它、和它一起成长。</p><h3 id="Why"><a href="#Why" class="headerlink" title="Why"></a>Why</h3><p>首先，为什么会出现ChatGPT这类预训练大模型呢？<br>随着预训练模型的发展，NLP技术的快速迭代更新，在探索<strong>通用人工智能</strong>的征程中，出现了ChatGPT这类智能问答文本生成网站，吸引了来自全球各地的使用者，短时间内，积累了大量的问答数据，让其他后发者难以望其项背，使人们看到了智能问答领域广阔的应用前景以及背后潜在的商业价值，ChatGPT的功能多样性也使得这一网站深入人心，极具发展优势。</p><p>让ChatGPT更容易推断出用户的意图，产生质变的根本原因是已在InstructGPT使用的“人类反馈的强化学习（RLHF）”技术。-OpenAI联合创始人、研究科学家John Schulman</p><p>一句话小结，可以说是ChatGPT相较于以前的模型，变得更多（数据），更大（模型），更快（运算），更强（能力）。</p><h3 id="What"><a href="#What" class="headerlink" title="What"></a>What</h3><p>其次，什么是ChatGPT?<br>这是一个具有智能问答功能的文本生成模型，或者远不止文本生成？感兴趣的话，你可以访问<a href="https://chat.openai.com/">https://chat.openai.com/</a> 亲自使用一下，相关的使用教程，网上已经有很多了，就不列举了。</p><h3 id="How"><a href="#How" class="headerlink" title="How"></a>How</h3><p>然后，ChatGPT的技术原理是什么呢？<br>基于GPT-3.5+Reinforcement learning技术，模型图如图1所示<br><img src="/../images/ChatGPT_Diagram.png" alt="ChatGPT_Diagram.png"></p><center>图1：ChatGPT模型框架</center><p>更多的技术细节，可以参考官方博客介绍：<a href="https://openai.com/blog/chatgpt/">https://openai.com/blog/chatgpt/</a> </p><h3 id="How-much"><a href="#How-much" class="headerlink" title="How much"></a>How much</h3><p>接着，ChatGPT有哪些核心能力呢？</p><ol><li>摘要生成能力：根据一篇文章生成一段摘要</li><li>内容生成能力：根据提示词，创作一篇文章</li><li>文字生成图片：在ChatGPT的Plus版本中可以实现，给出提示词，生成图片</li><li>逻辑能力：回答一些逻辑问题</li><li>常识理解能力：回答一些常识性问题</li><li>代码能力：比如根据提示，编写代码；检查代码中的错误</li><li>数学能力：做数学题</li><li>诗歌能力：中英文写诗</li><li>生活建议：根据你的需求，给出一些建议</li></ol><p>当然ChatGPT还也有不少缺点，比如：</p><ol><li>训练数据还是2021年之前的，无法回答之后的问题，现在通过插件、升级，可以回答联网的内容了</li><li>没有联网，没法搜索实时新闻，现在也基本上解决了这个问题</li><li>没有个人意见，只能回答事实性问题，但训练数据会出现事实性错误，导致给出的结果也存在事实性错误，“ChatGPT言无忌”，不用为自己说的话负责</li><li>不适合用于隐私、安全高要求方面的场景</li><li>具有偏见性、欺骗性、对隐私和公共安全可能构成风险</li><li>最重要的是缺少爱的能力，缺少共情的能力，也就是将心比心的能力，关于这一点，之间自己也有思考过人和人工智能的差别（人的优势在于随机应变，归纳推理，临机决断。机器的优势在于常规重复，计算推理，并行处理，除此之外，人还具有吃（食物）住（房子）行（交通）游（旅游）娱（娱乐）购（购物）等生存需求，爱（爱情）亲（亲情）友（友情）等情感需求，个人实现与社会认可等精神需求。人会为了实现这些需求，去思考，去行动，去达成。最后，提及个人觉得最重要的一点，关于人机的区别，人具有爱的能力，爱己爱人爱物。），可以借鉴。<a href="https://www.zhihu.com/question/463911897/answer/1935969469">https://www.zhihu.com/question/463911897/answer/1935969469</a></li></ol><h3 id="What-then"><a href="#What-then" class="headerlink" title="What then"></a>What then</h3><p>最后，从ChatGPT开始，未来会走向何方？<br>我们先来看看从ChatGPT出现后，有哪些大模型产品也出现了?</p><ol><li>讯飞星火认知大模型</li><li>Perplexity</li><li>Forefront Chat</li><li>Bing AI</li><li>Bard</li><li>ChatGLM</li><li>Claude<br>…<br>还有更多</li></ol><p>留给我们可以思考的问题，也还有很多，比如：</p><ol><li>中国能否做出ChatGPT这类领跑型的智能问答系统，关键瓶颈在哪里？</li><li>大量可靠准确的中文数据从哪里获得，怎么获得？</li><li>模型是否一定需要大模型（黑盒模型），小模型，可解释性强的模型是否可以？</li><li>ChatGPT带来的隐私、安全、伦理问题该如何解决？</li><li>ChatGPT以及类ChatGPT的模型，将带来什么样的新型人机关系？<br>…</li></ol><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>新工具会不断出现、变化，使用工具的人也得适应变化，主动学习，终身学习。</p><p>欢迎在评论区给出您的想法和建议，期待和您一起讨论。</p><hr><p>“问渠那得清如许？为有源头活水来”</p><p>–我在半亩方塘等你 :)</p><h3 id="更多资源"><a href="#更多资源" class="headerlink" title="更多资源"></a>更多资源</h3><ol><li>【渐构】万字科普GPT4为何会颠覆现有工作流；为何你要关注微软Copilot、文心一言等大模型 <a href="https://www.bilibili.com/video/BV1MY4y1R7EN/?buvid=YD4375DDDB8980D94AB8BF119C31778966FE&is_story_h5=false&mid=XBbQe5CI/FgyweFiTv2yEQ==&p=1&plat_id=114&share_from=ugc&share_medium=iphone&share_plat=ios&share_session_id=47459377-6B33-4046-825A-76F52E61CB40&share_source=WEIXIN_MONMENT&share_tag=s_i&timestamp=1679115401&unique_k=pxTF5Zl&up_id=344849038&vd_source=ad804d63c4e2c9d24cee23b0c9599379">https://www.bilibili.com/video/BV1MY4y1R7EN/?buvid=YD4375DDDB8980D94AB8BF119C31778966FE&amp;is_story_h5=false&amp;mid=XBbQe5CI%2FFgyweFiTv2yEQ%3D%3D&amp;p=1&amp;plat_id=114&amp;share_from=ugc&amp;share_medium=iphone&amp;share_plat=ios&amp;share_session_id=47459377-6B33-4046-825A-76F52E61CB40&amp;share_source=WEIXIN_MONMENT&amp;share_tag=s_i&amp;timestamp=1679115401&amp;unique_k=pxTF5Zl&amp;up_id=344849038&amp;vd_source=ad804d63c4e2c9d24cee23b0c9599379</a></li><li>BERT. <a href="https://github.com/google-research/bert">https://github.com/google-research/bert</a></li><li>GPT. <a href="https://github.com/openai/finetune-transformer-lm">https://github.com/openai/finetune-transformer-lm</a></li><li>GPT-2. <a href="https://github.com/openai/gpt-2">https://github.com/openai/gpt-2</a></li><li>BART. <a href="https://github.com/huggingface/transformers">https://github.com/huggingface/transformers</a></li><li>GPT-3. <a href="https://github.com/openai/gpt-3">https://github.com/openai/gpt-3</a></li><li>大模型时代下做科研的四个思路【论文精读·52】 <a href="https://www.bilibili.com/video/BV1oX4y1d7X6/">https://www.bilibili.com/video/BV1oX4y1d7X6/</a></li><li>InstructGPT 论文精读【论文精读·48】 <a href="https://www.bilibili.com/video/BV1hd4y187CR/">https://www.bilibili.com/video/BV1hd4y187CR/</a></li><li>GPT，GPT-2，GPT-3 论文精读【论文精读】<a href="https://www.bilibili.com/video/BV1AF411b7xQ/?spm_id_from=333.999.0.0">https://www.bilibili.com/video/BV1AF411b7xQ/?spm_id_from=333.999.0.0</a></li><li>GPT-4论文精读【论文精读·53】 <a href="https://www.bilibili.com/video/BV1vM4y1U7b5/?spm_id_from=333.999.0.0">https://www.bilibili.com/video/BV1vM4y1U7b5/?spm_id_from=333.999.0.0</a></li><li>OpenAI 对 GPT-4的官方解读 <a href="https://openai.com/research/gpt-4">https://openai.com/research/gpt-4</a> </li><li>深度学习论文精读-李沐 <a href="https://github.com/mli/paper-reading">https://github.com/mli/paper-reading</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>随笔感悟</category>
      
    </categories>
    
    
    <tags>
      
      <tag>ChatGPT</tag>
      
      <tag>大模型</tag>
      
      <tag>人机关系</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>节气养生-寒露</title>
    <link href="/posts/68e0eb59/"/>
    <url>/posts/68e0eb59/</url>
    
    <content type="html"><![CDATA[<p>节气养生，寒露脚不露。</p><span id="more"></span><p>今日寒露，白露身不露，寒露脚不露。天气渐渐转凉，一层秋雨一层凉，走在路上，感受到秋雨绵绵，远处烟雨蒙蒙的气息。</p><p>养生方面，应注重滋阴润肺，调养精神，保持乐观豁达的心情，天气变凉，注意增添衣物，预防感冒，调整起居，养成早睡早起的习惯，在大雾天气，减少外出运动，在室内运动为主。室内运动推荐做扎马步，俯卧撑，抬腿提膝等，运动前做好热身运动，运动后做好拉伸，不宜过度出汗。</p><p>此外，还有一些养生小妙招，比如早晚泡脚，最好是晚上泡个脚，有助于睡眠，大概20-30分钟，在晚饭后1个小时之后。这个节气，也需要预防肩周炎，按压合谷穴或肩井穴。泡完脚后，可根据自身需要做足底按摩，按压太溪穴，太冲穴，太白穴等，调养肾，肝，脾。</p><p>最后，寒露节气也有吃螃蟹的习俗，赏菊吃蟹，菊黄蟹肥，不过一些不适合吃螃蟹的朋友，要注意忌口。</p><h3 id="参考资料："><a href="#参考资料：" class="headerlink" title="参考资料："></a>参考资料：</h3><ol><li>《二十四节气养生经》-李志敏，天津科学技术出版社，2016.</li></ol><hr><p>欢迎各位提出建议、问题，我们一起交流、学习、成长。</p><p>“问渠那得清如许？为有源头活水来” ヾ(◍°∇°◍)ﾉﾞ</p><p>– 我在半亩方塘等你 ^_^</p>]]></content>
    
    
    <categories>
      
      <category>随笔感悟</category>
      
    </categories>
    
    
    <tags>
      
      <tag>养生</tag>
      
      <tag>节气</tag>
      
      <tag>寒露</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>2022年国庆小记</title>
    <link href="/posts/9fb794da/"/>
    <url>/posts/9fb794da/</url>
    
    <content type="html"><![CDATA[<p>趁年轻，去运动，去思考，去见识，成长自己。</p><span id="more"></span><p>疫情之下，保持一个良好的身心状态，对于应对各方面的压力，随地随地可能发生的变化，过好生活就显得至关重要。今天是国庆假期的第一天，由于疫情的缘故，不能安排旅行，就只能待在成都，待在自己平时生活的地方，读书、学习、散步、思考、网上交流。</p><p>趁着这个机会，将之前运动的一些经验和心得记录一下，希望对那些愿意调整自己身心状态，在身体和心理上感觉更加舒服些的朋友们有所帮助。</p><p>从2020年发生疫情以来，今年快到第3年了，时间过得很快，一溜烟的，但是疫情给我们带来的苦闷或者心烦，确实一直持续的，久久难以散去。希望有那么一天，我们可以开心地面对面交谈，热情地问候，幸福地拥抱。</p><p>从2021年12月10日，开始发起#趁年轻 去运动#的活动，到2022年09月29日，保持运动，同时记录的习惯，自己已经运动130天整。最开始在操场跑步，后来在校园里跑步，再后来在室内做无器械运动，身体发生了明显的改变，手臂的肌肉变得更加结实，腿部变得更加有力，精气神变得更加棒。总的来说，一个感受就是，如果室外条件适合，就在室外运动，室内条件合适，就在室内运动，最重要的是，运动起来，注意安全。关于跑步，还在知乎写过一篇文章（<a href="https://zhuanlan.zhihu.com/p/438670862">空气质量知多少，早上跑步好不好？</a>），感兴趣的朋友也可以去看看。无器械运动推荐这本书（<a href="https://book.douban.com/subject/11608712/">无器械健身</a>）。</p><p>有时候，心情比较烦闷或者比较无聊的时候，也会选择看书、看电影，看纪录片，从年初到现在，大概看了11本书，23部电影，5部纪录片，在身体没法到远方旅行的时候，让思想和心灵去远航也是一次难得的体验，这是一次次穿越时空，跨越江河的旅行，很棒。如果你不知道选什么书看，这里有份书单，供你选阅（<a href="https://xiepeng21.cn/2019-01-02/2019%E5%B9%B4%E4%B9%A6%E5%8D%95.html">2019年书单</a>）。想找经典的电影，可以看看豆瓣电影Top250列表（<a href="https://movie.douban.com/top250">豆瓣电影Top250</a>），里面很多电影质量很高，值得一看。纪录片的话，自己之前整理了一个列表（<a href="https://www.zhihu.com/question/534427413/answer/2505056045">纪录片推荐</a>），可以选择自己感兴趣的纪录片来看，挺有意思的。</p><p>如果晚上睡不太好，也会听听轻音乐，助眠音乐，做冥想练习（<a href="https://www.17mingxiang.com/">Now冥想</a>），回到当下，放空自己的大脑，对于缓解压力，睡个好觉，挺有帮助。</p><p>10月的第一天，碎碎念，写了这些。今年剩下的日子还剩3个月，2022年已经过了3&#x2F;4，希望我们都能安心生活，踏实做事，一点一点，在一件件小事上，修炼自己，保持身心健康，向阳生长。</p><hr><p>欢迎各位提出建议、问题，我们一起交流、学习、成长。</p><p>“问渠那得清如许？为有源头活水来” ヾ(◍°∇°◍)ﾉﾞ</p><p>– 我在半亩方塘等你 ^_^</p>]]></content>
    
    
    <categories>
      
      <category>随笔感悟</category>
      
    </categories>
    
    
    <tags>
      
      <tag>阅读</tag>
      
      <tag>趁年轻，去运动</tag>
      
      <tag>国庆</tag>
      
      <tag>电影</tag>
      
      <tag>纪录片</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>概率密度估计</title>
    <link href="/posts/f3b8224e/"/>
    <url>/posts/f3b8224e/</url>
    
    <content type="html"><![CDATA[<p>今天来理一下<strong>概率密度</strong>、<strong>概率密度函数</strong>、<strong>概率密度估计</strong>和<strong>核密度估计</strong>之间的关系，并介绍如何用Python绘制<strong>直方图</strong>，求解<strong>核密度估计</strong>。</p><span id="more"></span><h3 id="概率密度"><a href="#概率密度" class="headerlink" title="概率密度"></a>概率密度</h3><p>首先，介绍一下<strong>概率密度</strong>（Probability density, PD），它用来表示观测值和其概率之间的关系。概率是面积，概率密度是单位观测值的概率，即概率密度&#x3D;概率&#x2F;随机变量的单位。概率密度的总体形状被称为概率分布。</p><h3 id="概率密度函数"><a href="#概率密度函数" class="headerlink" title="概率密度函数"></a>概率密度函数</h3><p>其次，什么是<strong>概率密度函数</strong>（Probability density function，PDF），它有时也称为密度函数，概率分布函数。是一个连续分布函数的导数，指一个值到它的概率密度的函数映射。直观上来看，是将直方图的组距切割得越来越细，观察其顶部逐渐接近一条曲线，这条曲线就是概率密度函数的图形。（参考<a href="https://www.youtube.com/watch?v=L9rxyLcb-gE">概率密度函数</a>）如图1所示，为正态分布的概率密度函数，横轴为随机变量的取值，纵轴为概率密度函数的值，随机变量的取值落在某个区域内的概率为概率密度函数在这个区域上的积分。当概率密度函数存在时，累积分布函数（CDF）是概率密度函数（PDF）的积分。（参考<a href="https://zh.wikipedia.org/zh-cn/%E6%A9%9F%E7%8E%87%E5%AF%86%E5%BA%A6%E5%87%BD%E6%95%B8">概率密度函数</a>）</p><p><img src="/../images/%E6%AD%A3%E6%80%81%E5%88%86%E5%B8%83%E7%9A%84%E6%A6%82%E7%8E%87%E5%AF%86%E5%BA%A6%E5%87%BD%E6%95%B0.png" alt="正态分布的概率密度函数.png"></p><center>图1：正态分布的概率密度函数</center><h3 id="概率密度估计"><a href="#概率密度估计" class="headerlink" title="概率密度估计"></a>概率密度估计</h3><p>接着，那什么又是<strong>概率密度估计</strong>（Probability density estimation, PDE）呢？通常是在不知道一个随机变量的PDF，需要去逼近这个PDF，这个逼近的过程就是概率密度估计。概率密度估计的步骤为：</p><ol><li>用一个<strong>直方图</strong>来检查随机样本中观测值的密度，从直方图可以大致看出数据服从什么样的分布，如正态分布等。如果看不出明显的分布，则需要构建一个模型来估计分布；</li><li>估计分布的参数，也叫做<strong>参数密度估计</strong>；</li><li>针对数据样本不符合常见的概率分布时，则需要采用非参数密度估计（使用所有样本来进行密度估计），常见的<strong>非参数密度估计</strong>方法包括<strong>核平滑法</strong>（Kernel smoothing）或<strong>核密度估计</strong>（Kernel density estimation, KDE）。</li></ol><p>非参数密度估计包含2个重要的参数，平滑参数（Smoothing parameter）和核函数（Kernel function）。（参考<a href="https://www.cnblogs.com/marsggbo/p/12115257.html">概率密度估计介绍</a>）</p><h3 id="核密度估计"><a href="#核密度估计" class="headerlink" title="核密度估计"></a>核密度估计</h3><p>然后，介绍下非参数密度估计中的一类重要方法，<strong>核密度估计</strong>（Kernel density estimation, KDE）。它是一种非参数估计方法，针对于数据样本不符合常见的概率分布，需要使用所有样本来进行密度估计。‘核’可以理解为一个函数，用来提供权重。在网上看到一种理解，挺有意思。那就是核密度函数是一种“平滑（smooth）”的手段，相当于说“我说我很牛逼你可能不信，但是你可以听我的朋友们怎么评价我的，加权平均下就能更好地了解我了”。</p><p>设$(x_1,x_2,…,x_n)$是独立同分布的$n$个样本点，它的<strong>概率密度函数</strong>是$f$，于是<strong>核密度估计函数</strong>为：<br>$$\hat{f}<em>h(x)&#x3D;\frac{1}{n} \sum</em>{i&#x3D;1}^n K_h\left(x-x_i\right)&#x3D;\frac{1}{n h} \sum_{i&#x3D;1}^n K\left(\frac{x-x_i}{h}\right)$$<br>其中$h$是人为设定的，叫作<strong>平滑参数</strong>（smoothing parameter），也叫作<strong>带宽</strong>（bandwidth）。</p><h3 id="用Python绘制直方图，求解核密度估计"><a href="#用Python绘制直方图，求解核密度估计" class="headerlink" title="用Python绘制直方图，求解核密度估计"></a>用Python绘制直方图，求解核密度估计</h3><ul><li>用Python的数据可视化库matplotlib和seaborn绘制直方图。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs Python"><span class="hljs-keyword">import</span> seaborn <span class="hljs-keyword">as</span> sns<br><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><br><br>sns.<span class="hljs-built_in">set</span>()<br><br>np.random.seed(<span class="hljs-number">0</span>)<br><br>x = np.random.randn(<span class="hljs-number">100</span>)<br><br><span class="hljs-comment">### plot the hist in seaborn</span><br>sns.displot(x, bins=<span class="hljs-number">20</span>, kde=<span class="hljs-literal">False</span>, label=<span class="hljs-string">&#x27;sns.histplot&#x27;</span>)<br><br>plt.show()<br></code></pre></td></tr></table></figure><p><img src="/../images/%E7%9B%B4%E6%96%B9%E5%9B%BE.png" alt="直方图.png"></p><center>图2：绘制的直方图</center><ul><li>用Python的Scikit-learn库计算、绘制核密度估计图。还可以使用Scipy，Statsmodels库。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><code class="hljs Python"><span class="hljs-keyword">from</span> scipy.stats.distributions <span class="hljs-keyword">import</span> norm<br><br><span class="hljs-keyword">from</span> sklearn.neighbors <span class="hljs-keyword">import</span> KernelDensity<br><br><br>N = <span class="hljs-number">100</span><br><br>np.random.seed(<span class="hljs-number">0</span>)<br><br>X = np.concatenate((np.random.normal(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-built_in">int</span>(<span class="hljs-number">0.4</span> * N)), np.random.normal(<span class="hljs-number">5</span>, <span class="hljs-number">1</span>, <span class="hljs-built_in">int</span>(<span class="hljs-number">0.6</span> * N))))[:, np.newaxis]<br><br>X_plot = np.linspace(-<span class="hljs-number">5</span>, <span class="hljs-number">10</span>, <span class="hljs-number">100</span>)[:, np.newaxis]<br><br>true_dens = (<span class="hljs-number">0.4</span> * norm(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>).pdf(X_plot[:, <span class="hljs-number">0</span>]) + <span class="hljs-number">0.6</span> * norm(<span class="hljs-number">5</span>, <span class="hljs-number">1</span>).pdf(X_plot[:, <span class="hljs-number">0</span>])) <br><br>fig, ax = plt.subplots()<br><br>ax.fill(X_plot[:, <span class="hljs-number">0</span>], true_dens, fc=<span class="hljs-string">&#x27;black&#x27;</span>, alpha=<span class="hljs-number">0.2</span>, label=<span class="hljs-string">&#x27;input distribution&#x27;</span>)<br><br>colors = [<span class="hljs-string">&#x27;red&#x27;</span>, <span class="hljs-string">&#x27;green&#x27;</span>, <span class="hljs-string">&#x27;yellow&#x27;</span>]<br><br>bws = [<span class="hljs-number">0.1</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">1</span>]<br><br>lw = <span class="hljs-number">2</span><br><br><span class="hljs-keyword">for</span> color, bw <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(colors, bws):<br><br>        kde = KernelDensity(kernel=<span class="hljs-string">&#x27;gaussian&#x27;</span>, bandwidth=bw).fit(X)<br><br>        log_dens = kde.score_samples(X_plot)<br><br>        ax.plot(X_plot[:, <span class="hljs-number">0</span>], np.exp(log_dens), color=color, lw=lw,<br><br>                linestyle=<span class="hljs-string">&#x27;-&#x27;</span>, label=<span class="hljs-string">&quot;bandwidth = &#x27;&#123;0&#125;&#x27;&quot;</span>.<span class="hljs-built_in">format</span>(bw))<br><br>ax.text(<span class="hljs-number">6</span>, <span class="hljs-number">0.38</span>, <span class="hljs-string">&quot;N=&#123;0&#125; points&quot;</span>.<span class="hljs-built_in">format</span>(N))  <br><br>ax.legend(loc=<span class="hljs-string">&#x27;upper left&#x27;</span>)<br><br>ax.plot(X[:, <span class="hljs-number">0</span>], -<span class="hljs-number">0.005</span> - <span class="hljs-number">0.01</span> * np.random.random(X.shape[<span class="hljs-number">0</span>]), <span class="hljs-string">&#x27;+k&#x27;</span>)<br><br>ax.set_xlim(-<span class="hljs-number">4</span>, <span class="hljs-number">9</span>)<br><br>ax.set_ylim(-<span class="hljs-number">0.02</span>, <span class="hljs-number">0.4</span>)<br></code></pre></td></tr></table></figure><p><img src="/../images/%E7%BB%98%E5%88%B6%E7%9A%84%E6%A0%B8%E5%AF%86%E5%BA%A6%E4%BC%B0%E8%AE%A1%E5%9B%BE.png" alt="绘制的核密度估计图.png"></p><center>图3：绘制的不同bandwidth下的核密度估计图</center><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><ol><li><a href="https://www.youtube.com/watch?v=L9rxyLcb-gE">概率密度函数</a></li><li><a href="%E6%A6%82%E7%8E%87%E5%AF%86%E5%BA%A6%E5%87%BD%E6%95%B0">维基百科-概率密度函数</a></li><li><a href="https://www.cnblogs.com/marsggbo/p/12115257.html">概率密度估计介绍</a></li><li><a href="https://www.cnblogs.com/shzt/articles/12689856.html">绘制直方图与求解核密度估计的Python方法</a></li></ol><hr><p>欢迎各位提出建议、问题，我们一起交流、学习、成长。</p><p>“问渠那得清如许？为有源头活水来” ヾ(◍°∇°◍)ﾉﾞ</p><p>– 我在半亩方塘等你 ^_^</p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>概率密度估计</tag>
      
      <tag>概率密度</tag>
      
      <tag>概率密度函数</tag>
      
      <tag>核密度估计</tag>
      
      <tag>直方图</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【时空数据挖掘】推开窗，看一看</title>
    <link href="/posts/24230420/"/>
    <url>/posts/24230420/</url>
    
    <content type="html"><![CDATA[<p>炎热的夏季已经过去，秋爽来学。开学了，要开始新一阶段的学习、生活了。空调吹久了，推开窗，看一看，说不定有新发现呢？^_^</p><span id="more"></span><p>最近到了开学季，新的一学年开始了。回顾自己最开始接触时空数据挖掘、城市计算、机器学习领域，还是2018年。4年过去了，从最开始的陌生、好奇，到学习、探索、交流过程中的困惑、失落、激动、喜悦，直到现在，还在不断学习、思考、总结的过程中。前段时间，在知乎写了一系列关于时空数据挖掘的文章，也回答了一些关于如何阅读论文，如何入门时空数据挖掘领域的问题。在2020年暑假参加了京东城市组织的城市计算首届夏令营活动，参与到时空数据融合、城市大数据分析、城市交通预测等科研项目中。因此，积累了一些经验、有一些心得体会，写下来，作为自己的成长记录，也希望对新入门这个领域的同学、研究者有一些帮助，能对该领域的发展做出自己的一份贡献。</p><p>那么，首先，我们会问，什么是时空数据挖掘，从这6个字来看，可以分为两部分，时空+数据挖掘，提到时空，第一印象可能就是想到《错位时空》这首歌，“我吹过你吹过的晚风，那我们算不算相拥”，还有疫情期间出现的“时空伴随者”这个词，时空伴随者是指一个人与确诊患者手机号码在同一时空网格（范围为800m*800m）共同停留超过10分钟，且最近14天任一方号码累计停留时间超过30小时以上，查出的号码为时空伴随者号码。想必，大家对时空这一个词有一个直观的印象了。时空，就是时间和空间两个维度，风和人都是时空维度下的对象，我们研究空气质量、天气预报、交通预测、密接人员发现等，都会对对象所处的时间段、空间范围进行分析，分析其时空特征，进行数据分析、建模，得出有意思的分析结果。然后，数据挖掘，与日常听到的数据分析、大数据、机器学习、人工智能等词语，都有一定联系，其主要是指对数据进行清洗、处理、分析、可视化的过程，研究频繁模式挖掘、分类、聚类、异常检测等任务。推荐阅读韩家炜老师的《数据挖掘：概念与技术》这本书，当时我也是开始看这本书进入数据挖掘领域。最后，介绍一下，时空数据挖掘的定义、任务、数据、方法、论文以及如何入门。</p><h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><p>采用人工智能和大数据技术对城市时空数据进行分析与挖掘，旨在挖掘时空数据，理解城市本质，解决城市问题。</p><h3 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h3><p>从任务的特点、属性、层级进行分类，可分为底层的数据处理层级的任务，中层的时空模式发现任务，以及顶层的应用任务。如图1所示。</p><p><img src="/../images/%E6%97%B6%E7%A9%BA%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98-%E4%BB%BB%E5%8A%A1.png" alt="时空数据挖掘-任务.png"></p><center>图1：时空数据挖掘-任务</center><p>其中，底层任务包括时空数据预处理，时空数据融合和时空数据管理等。中层任务包括时空数据模式挖掘。顶层任务包括时空预测，时空推荐，异常检测，调度和优化等。</p><h3 id="数据"><a href="#数据" class="headerlink" title="数据"></a>数据</h3><p>针对时空数据挖掘，数据是必不可少的原料，而且这类数据具有明显的时空特性，包括时间特性（时间的邻近性、周期性、趋势性等）、空间特性（距离远近，空间层次等）。有必要将<strong>时空数据</strong>进行分类，对时空数据进行了如图2分类：</p><p><img src="/../images/%E6%97%B6%E7%A9%BA%E6%95%B0%E6%8D%AE.png" alt="时空数据.png"></p><center>图2：时空数据挖掘-时空数据分类</center><p>按时空动态，可以分成空间静态点数据、空间点时序数据、时空动态点数据、空间静态网数据、空间静态时间动态网数据、时空动态网数据。这种分类方式是由京东城市的Yu Zheng老师团队提出，具有时空特色。如图3所示：</p><p><img src="/../images/ST%20dataset.png" alt="ST dataset.png"></p><center>图3：时空数据-时空动态分类</center><p>按个体交互，可以分为个体数据和环境数据。侧重于个体、群体、环境之间的交互和协同。</p><p>按数据构造，可以分为基本单元数据、组合数据、关系数据。这种分类方式，适合于对数据进行形式化组织和描述，具有层次递进关系。</p><p>按点线面，可以分为基于点、基于线、基于面的数据。这种分类，和几何上的点线面结构，可以直观地对应上，是比较自然的一种分类方式。如图4所示：</p><p><img src="/../images/%E7%82%B9%E7%BA%BF%E9%9D%A2.png" alt="点线面.png"></p><center>图4：时空数据-点线面分类</center><p>后面的三种分类方式，是笔者在参加2020年京东城市计算夏令营的时候，与北航Jingyuan Wang老师和Dayan Pan, Geyuan Wang同学等的交流、讨论中形成的，感谢他们。</p><p>以上的四种时空数据分类方法，可以给读者以不同的视角来看待时空数据，在进行时空数据挖掘时，能对时空数据有全面、充分的理解。如果有其他的分类方式或者一些建议、疑问，欢迎在留言区提问，交流。</p><p>此外，针对数据质量不高的问题，采用数据补全、数据增强、数据融合等方式进行预处理、分析。</p><p>关于时空数据、多模态数据与多源异构数据的联系与区别的思考：</p><p>时空数据：主要是指带有时间和空间特性的一类数据，比如GPS轨迹，其有时间戳，位置信息；地铁刷卡数据，其有乘客进站时间站点、出站时间站点信息等。</p><p>多模态数据：主要是指文本、音频、图像、视频等不同模态类型的数据。</p><p>多源异构数据：主要是包括多源和异构两种特性，前者是指数据的来源多样，比如来源于交通领域的交通路网、网约车出行订单数据、公共交通刷卡数据与来自环境气象的空气质量、降雨量数据，后者是指数据的类型和格式不一样，比如交通路网是网状结构数据，空间位置相对固定，时间变化频率慢，订单、刷卡、空气质量数据是时空序列，随着时间和空间发生变化。</p><p>时空数据多见于时空数据挖掘、城市计算、智能交通系统等领域；多模态数据覆盖范围更广，计算机视觉、自然语言处理、数据挖掘领域都有研究；多源异构数据主要侧重于从数据的多来源，结构差异的角度对数据进行描述，可以看做是时空数据和多模态数据的特性之一，另外还有缺失性、不平衡性、动态突变性等，根据具体的数据集质量情况而定。</p><p>三者关系可以大致如下：多模态数据&gt;时空数据，多源异构数据用于描述这两类数据的部分特性，从多源和异构角度。</p><h3 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h3><h4 id="层次体系构建"><a href="#层次体系构建" class="headerlink" title="层次体系构建"></a>层次体系构建</h4><p>为了更好地进行时空数据挖掘，我们提出了一种时空数据挖掘的层次体系，包括数据层、任务层、方法层。如图5所示。</p><p><img src="/../images/%E6%97%B6%E7%A9%BA%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98-%E5%B1%82%E6%AC%A1%E4%BD%93%E7%B3%BB.png" alt="时空数据挖掘-层次体系.png"></p><center>图5：时空数据挖掘-层次体系</center><p>该层次体系，首先从数据出发，将时空数据分为静态数据、时间动态数据和时空动态数据，更加详细的时空数据分类方式，可以参考前文数据部分；然后针对时空任务，分成了底层任务、中层任务和顶层任务，更具体的任务分类，可以参考前文任务部分；最后针对特定的数据和任务，选择相应的时空数据挖掘方法，更多的时空数据挖掘方法，可以参考下文方法部分。</p><p>在进行具体时空数据挖掘研究中，也可以参照上述的层次体系，思考要研究的时空数据、时空任务、时空方法，从整体的角度进行分析，希望其能对于您的研究有所助益。</p><p>注：时空数据挖掘的层次体系构建，感谢北航的Jingyuan Wang和Geyuan Wang等的讨论、交流。</p><h4 id="方法论"><a href="#方法论" class="headerlink" title="方法论"></a>方法论</h4><p>笔者对时空数据挖掘中常用方法进行分类，主要是站在方法论的角度，进行大致分类。因为方法往往是跟任务、数据和需求等是紧密联系，还需根据实际情况，实际分析。方法的分类，如图6所示。</p><p><img src="/../images/%E6%97%B6%E7%A9%BA%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98-%E6%96%B9%E6%B3%95.png" alt="时空数据挖掘-方法.png"></p><center>图6：时空数据挖掘方法</center><p>时空数据挖掘的方法主要分为时空数据预处理方法、传统的机器学习方法、先进的机器学习方法和常用技术框架。</p><p>由于人工智能、机器学习、数据挖掘领域的快速发展，一些新的学习方法和技术框架也在不断涌现。时空数据挖掘领域针对时空数据挖掘领域的任务、数据也在提出一些具有时空特色和多场景应用背景下的新方法。</p><p>注：上述的时空数据挖掘方法分类是在和北航Jingyuan Wang、Geyuan Wang等老师、同学的讨论下形成，感谢他们。</p><h3 id="论文"><a href="#论文" class="headerlink" title="论文"></a>论文</h3><p>为了及时跟踪学术前沿论文，准确把握时空数据挖掘领域发展方向，提升对时空数据挖掘的理解，帮助我们更好地学习、研究，对2016-2022年的时空数据挖掘领域的顶级会议、期刊论文进行了梳理。由于工作量较大，加之笔者时间有限，整理的论文还有很多需要完善修改的地方，后续将继续更新。感兴趣的朋友，也可以在<a href="https://github.com/xiepeng21/research_spatio-temporal-data-mining">我的论文库</a>里发起<a href="https://www.zhihu.com/question/21682976">pull request</a>或提出修改建议。</p><h4 id="按会议"><a href="#按会议" class="headerlink" title="按会议"></a>按会议</h4><ul><li><p>AAAI（2019-2022）：</p><ul><li><a href="https://zhuanlan.zhihu.com/p/478357750">AAAI 2022时空数据挖掘录用论文列表</a></li><li><a href="https://xiepeng21.cn/2021-01-06/%E6%97%B6%E7%A9%BA%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E8%AE%BA%E6%96%87-AAAI2021.html">AAAI 2021时空数据挖掘论文</a></li><li><a href="https://github.com/xiepeng21/research_spatio-temporal-data-mining#aaai-2019-2020">AAAI 2019-2020时空数据挖掘论文</a></li></ul></li><li><p>IJCAI （2016-2022）：</p><ul><li><a href="https://github.com/xiepeng21/research_spatio-temporal-data-mining/blob/master/IJCAI/IJCAI.md">IJCAI 2022 时空数据挖掘论文</a></li><li><a href="https://zhuanlan.zhihu.com/p/423323595">IJCAI 2021 时空数据挖掘论文</a></li><li><a href="https://github.com/xiepeng21/research_spatio-temporal-data-mining#ijcai-2016-2020">IJCAI 2016-2020 时空数据挖掘论文</a></li></ul></li><li><p>KDD （2016-2022）：</p><ul><li><a href="https://zhuanlan.zhihu.com/p/547262551">【KDD 2022】时空数据挖掘论文</a></li><li><a href="https://zhuanlan.zhihu.com/p/423342733">KDD 2021 时空数据挖掘论文</a></li><li><a href="https://github.com/xiepeng21/research_spatio-temporal-data-mining#kdd-2016-2020">KDD 2016-2020时空数据挖掘论文</a></li></ul></li><li><p>ICDM (2016-2019)</p><ul><li><a href="https://github.com/xiepeng21/research_spatio-temporal-data-mining#icdm-2016-2019">ICDM 2016-2019时空数据挖掘论文</a></li></ul></li><li><p>CIKM (2017-2020)</p><ul><li><a href="https://github.com/xiepeng21/research_spatio-temporal-data-mining#cikm-2017-2020">CIKM 2017-2020时空数据挖掘论文</a></li></ul></li><li><p>WWW (2016-2022)</p><ul><li><a href="https://github.com/xiepeng21/research_spatio-temporal-data-mining/blob/master/WWW/WWW.md">WWW 2022 时空数据挖掘论文</a></li><li><a href="https://zhuanlan.zhihu.com/p/440291388">WWW 2021 时空数据挖掘论文</a></li><li><a href="https://github.com/xiepeng21/research_spatio-temporal-data-mining#www-2016-2020">WWW 2016-2020时空数据挖掘论文</a></li></ul></li><li><p>SDM (2016-2020)</p><ul><li><a href="https://github.com/xiepeng21/research_spatio-temporal-data-mining#sdm-2016-2020">SDM 2016-2020时空数据挖掘论文</a></li></ul></li><li><p>SIGSPATIAL (2016-2019, 2021)</p><ul><li><a href="https://zhuanlan.zhihu.com/p/442419220">ACM SIGSPATIAL 2021 时空数据挖掘论文</a></li><li><a href="https://github.com/xiepeng21/research_spatio-temporal-data-mining#sigspatial-2016-2019">SIGSPATIAL 2016-2019时空数据挖掘论文</a></li></ul></li><li><p>WSDM (2022)</p><ul><li><a href="https://zhuanlan.zhihu.com/p/478363400">WSDM 2022 时空数据挖掘论文</a></li></ul></li><li><p>NuerIPS</p><ul><li>待更新</li></ul></li><li><p>ICLR（2022）</p><ul><li><a href="https://zhuanlan.zhihu.com/p/478362107">ICLR 2022时空数据挖掘录用论文列表</a></li></ul></li><li><p>ICML（2022）</p><ul><li><a href="https://zhuanlan.zhihu.com/p/548907678">【ICML 2022】时空数据挖掘论文</a></li></ul></li></ul><h4 id="按期刊"><a href="#按期刊" class="headerlink" title="按期刊"></a>按期刊</h4><ul><li><p>TKDE（2016-2020）</p><ul><li><a href="https://github.com/xiepeng21/research_spatio-temporal-data-mining#ieee-tkde-2016-2020">TKDE 2016-2020 时空数据挖掘论文</a></li></ul></li><li><p>TIST（2016-2020）</p><ul><li><a href="https://github.com/xiepeng21/research_spatio-temporal-data-mining#acm-tist-2016-2020">TIST 2016-2020 时空数据挖掘论文</a></li></ul></li><li><p>TITS</p><ul><li>待更新</li></ul></li><li><p>TPAMI</p><ul><li>待更新</li></ul></li><li><p>TNNLS</p><ul><li>待更新</li></ul></li></ul><h3 id="写在最后"><a href="#写在最后" class="headerlink" title="写在最后"></a>写在最后</h3><p><strong>关于如何入门机器学习、数据挖掘：</strong></p><ul><li>推荐书籍：1. 数据挖掘：概念与技术（第三版）中文版-Jiawei Han；2.《统计学习方法（第2版）》-李航。这两本书，看下目录，感兴趣的部分，详细读下，电子版和纸质版都可。如果喜欢看视频，再看看吴恩达或者李宏毅的机器学习课程，B站上有。后面如果对某个研究方向感兴趣，再看一些综述论文，比如城市计算、时空数据挖掘领域的论文：1. Urban Computing: Concepts, Methodologies, and Applications-Yu Zheng-TIST 2014. 2. Deep Learning for Spatio-Temporal Data Mining: A Survey-Senzhang Wang-TKDE2020。</li></ul><p><strong>关于时空数据挖掘的学习路线：</strong></p><ul><li>建议首先通过看<a href="https://github.com/xiepeng21/research_spatio-temporal-data-mining#survey">综述文章</a>、知乎、博客等，了解下什么是时空数据挖掘，<a href="https://www.microsoft.com/en-us/research/project/%E5%9F%8E%E5%B8%82%E8%AE%A1%E7%AE%97/">城市计算</a>，然后从顶会（KDD, IJCAI, AAAI等）、顶刊（TKDE, TITS, TIST等）上找与自己研究课题相近的论文阅读，此外，养成做论文笔记的习惯，可以从论文的动机（motivation）、任务（task）、方法（method），实验（experiment）等进行总结。最重要的一点，就是要复现论文、跑实验。遇到问题，多思考，多查资料，多交流。</li></ul><p><strong>关于看论文遇到不懂的地方，怎么办：</strong></p><ul><li>自己多看几遍，网上查阅资料，补充预备知识；</li><li>和老师、同学讨论；</li><li>发邮件联系作者，讨论，论文中有作者的邮箱。</li></ul><p>欢迎各位提出建议、问题，我们一起交流、学习、成长。</p><p>“问渠那得清如许？为有源头活水来” ヾ(◍°∇°◍)ﾉﾞ</p><p>– 我在半亩方塘等你 ^_^</p>]]></content>
    
    
    <categories>
      
      <category>随笔感悟</category>
      
    </categories>
    
    
    <tags>
      
      <tag>时空数据挖掘</tag>
      
      <tag>城市计算</tag>
      
      <tag>开学季</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【WSDM 2022】时空数据挖掘论文</title>
    <link href="/posts/e5ed55f3/"/>
    <url>/posts/e5ed55f3/</url>
    
    <content type="html"><![CDATA[<p>对WSDM 2022的录用论文进行了整理，筛选出其中与时空数据挖掘相关论文，并进行任务分类。</p><span id="more"></span><p>WSDM 2022 完整录用论文列表：<a href="https://www.wsdm-conference.org/2022/accepted-papers/">https://www.wsdm-conference.org/2022/accepted-papers/</a></p><h3 id="Human-mobility-prediction"><a href="#Human-mobility-prediction" class="headerlink" title="Human mobility prediction"></a>Human mobility prediction</h3><p><a href="https://dl.acm.org/doi/10.1145/3488560.3498438">RLMob: Deep Reinforcement Learning for Successive Mobility Prediction</a>. Ziyan Luo, Congcong Miao</p><h3 id="Precipitation-forecasting"><a href="#Precipitation-forecasting" class="headerlink" title="Precipitation forecasting"></a>Precipitation forecasting</h3><p><a href="https://dl.acm.org/doi/10.1145/3488560.3498448">A New Class of Polynomial Activation Functions of Deep Learning for Precipitation Forecasting</a>. Jiachuan Wang, Lei Chen, Charles Wang Wai Ng</p><h3 id="Route-recommendation"><a href="#Route-recommendation" class="headerlink" title="Route recommendation"></a>Route recommendation</h3><p><a href="https://dl.acm.org/doi/10.1145/3488560.3498512">Personalized Long-distance Fuel-efficient Route Recommendation Through Historical Trajectories Mining</a>. Zhan Wang, Zhaohui Peng, Senzhang Wang, Qiao Song</p><h3 id="Passenger-demand-prediction"><a href="#Passenger-demand-prediction" class="headerlink" title="Passenger demand prediction"></a>Passenger demand prediction</h3><p><a href="https://dl.acm.org/doi/10.1145/3488560.3498394">CMT-Net: A Mutual Transition Aware Framework for Taxicab Pick-ups and Drop-offs Co-Prediction</a>. Yudong Zhang, Binwu Wang, Ziyang Shan, Zhengyang Zhou, Yang Wang</p><h3 id="Urban-flow-prediction"><a href="#Urban-flow-prediction" class="headerlink" title="Urban flow prediction"></a>Urban flow prediction</h3><p><a href="https://dl.acm.org/doi/10.1145/3488560.3498444">ST-GSP: Spatial-Temporal Global Semantic Representation Learning for Urban Flow Prediction</a>. Liang Zhao, Min Gao, Zongwei Wang</p>]]></content>
    
    
    <categories>
      
      <category>论文阅读</category>
      
    </categories>
    
    
    <tags>
      
      <tag>时空数据挖掘</tag>
      
      <tag>WSDM 2022</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【ICLR 2022】时空数据挖掘论文</title>
    <link href="/posts/38a6ca75/"/>
    <url>/posts/38a6ca75/</url>
    
    <content type="html"><![CDATA[<p>对ICLR 2022的录用论文进行了整理，筛选出其中与时空数据挖掘相关论文，并进行任务分类。</p><span id="more"></span><p>ICLR 2022完整录用论文列表：<a href="https://openreview.net/group?id=ICLR.cc/2022/Conference#oral-submissions">https://openreview.net/group?id=ICLR.cc/2022/Conference#oral-submissions</a></p><h3 id="Time-series-signal-analysis"><a href="#Time-series-signal-analysis" class="headerlink" title="Time series signal analysis"></a>Time series signal analysis</h3><ol><li><a href="https://openreview.net/forum?id=U4uFaLyg7PV">T-WaveNet: A Tree-Structured Wavelet Neural Network for Time Series Signal Analysis</a>. Minhao LIU, Ailing Zeng, Qiuxia LAI, Ruiyuan Gao, Min Li, Jing Qin, Qiang Xu</li></ol><h3 id="Time-series-forecasting"><a href="#Time-series-forecasting" class="headerlink" title="Time series forecasting"></a>Time series forecasting</h3><ol><li><a href="https://openreview.net/forum?id=JpNH4CW_zl">Multivariate Time Series Forecasting with Latent Graph Inference</a>. Victor Garcia Satorras, Syama Sundar Rangapuram, Tim Januschowski</li><li><a href="https://openreview.net/forum?id=wv6g8fWLX2q">TAMP-S2GCNets: Coupling Time-Aware Multipersistence Knowledge Representation with Spatio-Supra Graph Convolutional Networks for Time-Series Forecasting</a>. Yuzhou Chen, Ignacio Segovia-Dominguez, Baris Coskunuzer, Yulia Gel</li><li><a href="https://openreview.net/forum?id=0EXmFzUn5I">Pyraformer: Low-Complexity Pyramidal Attention for Long-Range Time Series Modeling and Forecasting</a>. Shizhan Liu, Hang Yu, Cong Liao, Jianguo Li, Weiyao Lin, Alex X. Liu, Schahram Dustdar</li><li><a href="https://openreview.net/forum?id=AJAR-JgNw__">DEPTS: Deep Expansion Learning for Periodic Time Series Forecasting</a>. Wei Fan, Shun Zheng, Xiaohan Yi, Wei Cao, Yanjie Fu, Jiang Bian, Tie-Yan Liu</li><li><a href="https://openreview.net/forum?id=PilZY3omXV2">CoST: Contrastive Learning of Disentangled Seasonal-Trend Representations for Time Series Forecasting</a>. Gerald Woo, Chenghao Liu, Doyen Sahoo, Akshat Kumar, Steven Hoi</li><li><a href="https://openreview.net/forum?id=cGDAkQo1C0p">Reversible Instance Normalization for Accurate Time-Series Forecasting against Distribution Shift</a>. Taesung Kim, Jinhee Kim, Yunwon Tae, Cheonbok Park, Jang-Ho Choi, Jaegul Choo</li></ol><h3 id="Time-series-classification"><a href="#Time-series-classification" class="headerlink" title="Time series classification"></a>Time series classification</h3><ol><li><a href="https://openreview.net/forum?id=PDYs7Z2XFGv">Omni-Scale CNNs: a simple and effective kernel size configuration for time series classification</a>. Wensi Tang, Guodong Long, Lu Liu, Tianyi Zhou, Michael Blumenstein, Jing Jiang</li></ol><h3 id="Time-series-anomaly-detection"><a href="#Time-series-anomaly-detection" class="headerlink" title="Time series anomaly detection"></a>Time series anomaly detection</h3><ol><li><a href="https://openreview.net/forum?id=45L_dgP48Vd">Graph-Augmented Normalizing Flows for Anomaly Detection of Multiple Time Series</a>. Enyan Dai, Jie Chen</li><li><a href="https://openreview.net/forum?id=LzQQ89U1qm_">Anomaly Transformer: Time Series Anomaly Detection with Association Discrepancy</a>. Jiehui Xu, Haixu Wu, Jianmin Wang, Mingsheng Long</li></ol><h3 id="Time-series-imputation"><a href="#Time-series-imputation" class="headerlink" title="Time series imputation"></a>Time series imputation</h3><ol><li><a href="https://openreview.net/forum?id=kOu3-S3wJ7">Filling the G_ap_s: Multivariate Time Series Imputation by Graph Neural Networks</a>. Andrea Cini, Ivan Marisca, Cesare Alippi</li></ol><h3 id="Spatial-Temporal-Representation-Learning"><a href="#Spatial-Temporal-Representation-Learning" class="headerlink" title="Spatial-Temporal Representation Learning"></a>Spatial-Temporal Representation Learning</h3><ol><li><a href="https://openreview.net/forum?id=nBU_u6DLvoK">UniFormer: Unified Transformer for Efficient Spatial-Temporal Representation Learning</a>. Kunchang Li, Yali Wang, Gao Peng, Guanglu Song, Yu Liu, Hongsheng Li, Yu Qiao</li><li><a href="https://openreview.net/forum?id=Jh9VxCkrEZn">Spatiotemporal Representation Learning on Time Series with Dynamic Graph ODEs</a>. Ming Jin, Yuan-Fang Li, Yu Zheng, Bin Yang, Shirui Pan</li></ol><h3 id="Spatial-temporal-GNN"><a href="#Spatial-temporal-GNN" class="headerlink" title="Spatial-temporal GNN"></a>Spatial-temporal GNN</h3><ol><li><a href="https://openreview.net/forum?id=XJiajt89Omg">Space-Time Graph Neural Networks</a>. Samar Hadou, Charilaos I Kanatsoulis, Alejandro Ribeiro</li></ol><h3 id="Traffic-forecasting"><a href="#Traffic-forecasting" class="headerlink" title="Traffic forecasting"></a>Traffic forecasting</h3><ol><li><a href="https://openreview.net/forum?id=wwDg3bbYBIq">Learning to Remember Patterns: Pattern Matching Memory Networks for Traffic Forecasting</a>. Hyunwook Lee, Seungmin Jin, Hyeshin Chu, Hongkyu Lim, Sungahn Ko</li></ol><h3 id="Trajectory-prediction"><a href="#Trajectory-prediction" class="headerlink" title="Trajectory prediction"></a>Trajectory prediction</h3><ol><li><a href="https://openreview.net/forum?id=POxF-LEqnF">You Mostly Walk Alone: Analyzing Feature Attribution in Trajectory Prediction</a>. Osama Makansi, Julius Von Kügelgen, Francesco Locatello, Peter Vincent Gehler, Dominik Janzing, Thomas Brox, Bernhard Schölkopf</li></ol>]]></content>
    
    
    <categories>
      
      <category>论文阅读</category>
      
    </categories>
    
    
    <tags>
      
      <tag>时空数据挖掘</tag>
      
      <tag>ICLR 2022</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【AAAI 2022】时空数据挖掘论文</title>
    <link href="/posts/ab9afbeb/"/>
    <url>/posts/ab9afbeb/</url>
    
    <content type="html"><![CDATA[<p>对AAAI 2022的录用论文进行了整理，筛选出其中与时空数据挖掘相关论文，并进行任务分类。</p><span id="more"></span><p>AAAI 2022录用论文列表：<br><a href="https://aaai.org/Conferences/AAAI-22/wp-content/uploads/2021/12/AAAI-22_Accepted_Paper_List_Main_Technical_Track.pdf">https://aaai.org/Conferences/AAAI-22/wp-content/uploads/2021/12/AAAI-22_Accepted_Paper_List_Main_Technical_Track.pdf</a></p><p>全文还没有放出来，如果需要，可以在谷歌学术上查找，部分论文已经放在arXiv上。</p><h3 id="Traffic-forecasting"><a href="#Traffic-forecasting" class="headerlink" title="Traffic forecasting"></a>Traffic forecasting</h3><ol><li><strong>STDEN: Towards Physics-Guided Neural Networks for Traffic Flow Prediction</strong>. Jiahao Ji, Jingyuan Wang, Zhe Jiang, Jiawei Jiang, Hu Zhang</li><li><strong>Graph Neural Controlled Differential Equations for Traffic Forecasting</strong>. Jeongwhan Choi, Hwangyong Choi, Jeehyun Hwang, Noseong Park</li></ol><h3 id="Traffic-assignment"><a href="#Traffic-assignment" class="headerlink" title="Traffic assignment"></a>Traffic assignment</h3><ol><li><strong>Machine-Learned Prediction Equilibrium for Dynamic Traffic Assignment</strong>. Lukas Graf, Tobias Harks, Kostas Kollias, Michael Markl</li></ol><h3 id="Trajectory-prediction"><a href="#Trajectory-prediction" class="headerlink" title="Trajectory prediction"></a>Trajectory prediction</h3><ol><li><strong>Social Interpretable Tree for Pedestrian Trajectory Prediction</strong>. Liushuai Shi, Le Wang, Chengjiang Long, Sanping Zhou, Fang Zheng, Nanning Zheng, Gang Hua</li><li><strong>Complementary Attention Gated Network for Pedestrian Trajectory Prediction</strong>. Jinghai Duan, Le Wang, Chengjiang Long, Sanping Zhou, Fang Zheng, Liushuai Shi, Gang Hua</li></ol><h3 id="Meteorological-forecasting"><a href="#Meteorological-forecasting" class="headerlink" title="Meteorological forecasting"></a>Meteorological forecasting</h3><ol><li><strong>Conditional Local Convolution for Spatio-Temporal Meteorological Forecasting</strong> Haitao Lin, Zhangyang Gao, Yongjie Xu, Lirong Wu, Ling Li, Stan Z. Li</li><li><strong>Learning and Dynamical Models for Sub-Seasonal Climate Forecasting: Comparison and Collaboration</strong>. Sijie He, Xinyan Li, Laurie Trenary, Benjamin A. Cash, Timothy DelSole, Arindam Banerjee</li></ol><h3 id="Driver-request-assignment"><a href="#Driver-request-assignment" class="headerlink" title="Driver-request assignment"></a>Driver-request assignment</h3><ol><li><strong>Real-Time Driver-Request Assignment in Ridesourcing</strong>. Hao Wang, Xiaohui Bei</li></ol><h3 id="Time-series-anomaly-detection"><a href="#Time-series-anomaly-detection" class="headerlink" title="Time-series anomaly detection"></a>Time-series anomaly detection</h3><ol><li><strong>Towards a Rigorous Evaluation of Time-Series Anomaly Detection</strong>. Siwon Kim, Kukjin Choi, Hyun-Soo Choi, Byunghan Lee, Sungroh Yoon</li></ol><h3 id="Spatiotemporal-Graph"><a href="#Spatiotemporal-Graph" class="headerlink" title="Spatiotemporal Graph"></a>Spatiotemporal Graph</h3><ol><li><strong>Disentangled Spatiotemporal Graph Generative Model</strong>. Yuanqi Du, Xiaojie Guo, Hengning Cao, Yanfang Ye, Zhao Liang</li></ol><h3 id="Urban-crime-prediction"><a href="#Urban-crime-prediction" class="headerlink" title="Urban crime prediction"></a>Urban crime prediction</h3><ol><li><strong>Multi-Type Urban Crime Prediction</strong>. Xiangyu Zhao, Wenqi Fan, Hui Liu, Jiliang Tang</li><li><strong>HAGEN: Homophily-Aware Graph Convolutional Recurrent Network for Crime Forecasting</strong>. Chenyu Wang, Zongyu Lin, Xiaochen Yang, Jiao Sun, Mingxuan Yue, Cyrus Shahabi</li></ol><h3 id="Time-series-forecasting"><a href="#Time-series-forecasting" class="headerlink" title="Time series forecasting"></a>Time series forecasting</h3><ol><li><strong>CATN: Cross Attentive Tree-Aware Network for Multivariate Time Series Forecasting</strong>. Hui He, Qi Zhang, Simeng Bai, Kun Yi, Zhendong Niu</li><li><strong>Reinforcement Learning based Dynamic Model Combination for Time Series Forecasting</strong>. Yuwei Fu, Di Wu, Benoit Boulet</li></ol><h3 id="Spatio-temporal-patterns-modeling"><a href="#Spatio-temporal-patterns-modeling" class="headerlink" title="Spatio-temporal patterns modeling"></a>Spatio-temporal patterns modeling</h3><ol><li><strong>SPATE-GAN: Improved Generative Modeling of Dynamic Spatio-Temporal Patterns with an Autoregressive Embedding Loss</strong>. Konstantin Klemmer, Tianlin Xu, Beatrice Acciaio, Daniel B. Neill</li></ol><h3 id="Time-series-representation"><a href="#Time-series-representation" class="headerlink" title="Time series representation"></a>Time series representation</h3><ol><li><strong>TS2Vec: Towards Universal Representation of Time Series</strong>. Zhihan Yue, Yujing Wang, Juanyong Duan, Tianmeng Yang, Congrui Huang, Yunhai Tong, Bixiong Xu</li></ol><h3 id="Extreme-events-modeling"><a href="#Extreme-events-modeling" class="headerlink" title="Extreme events modeling"></a>Extreme events modeling</h3><ol><li><strong>DeepGPD: A Deep Learning Approach for Modeling Geospatio-Temporal Extreme Events</strong>. Tyler Wilson, Pang-Ning Tan, Lifeng Luo</li></ol><h3 id="Multimodal-mobility-nowcasting"><a href="#Multimodal-mobility-nowcasting" class="headerlink" title="Multimodal mobility nowcasting"></a>Multimodal mobility nowcasting</h3><ol><li><strong>Event-Aware Multimodal Mobility Nowcasting</strong>. Zhaonan Wang, Renhe Jiang, Hao Xue, Flora D. Salim, Xuan Song, Ryosuke Shibasaki</li></ol><h3 id="Time-series-analysis-and-embedding"><a href="#Time-series-analysis-and-embedding" class="headerlink" title="Time series analysis and embedding"></a>Time series analysis and embedding</h3><ol><li><strong>I-SEA: Importance Sampling and Expected Alignment-Based Deep Distance Metric Learning for Time Series Analysis and Embedding</strong>. Sirisha Rambhatla, Zhengping Che, Yan Liu</li></ol><h3 id="Time-series-generation"><a href="#Time-series-generation" class="headerlink" title="Time series generation"></a>Time series generation</h3><ol><li><strong>Conditional Loss and Deep Euler Scheme for Time Series Generation</strong>. Carl Remlinger, Joseph Mikael, Romuald Elie</li></ol><h3 id="Air-pollution-monitoring"><a href="#Air-pollution-monitoring" class="headerlink" title="Air pollution monitoring"></a>Air pollution monitoring</h3><ol><li><strong>Bayesian Optimisation for Active Monitoring of Air Pollution</strong>. Sigrid Passano Hellan, Christopher G. Lucas, Nigel H. Goddard</li></ol><h3 id="Air-quality-inference"><a href="#Air-quality-inference" class="headerlink" title="Air quality inference"></a>Air quality inference</h3><ol><li><strong>Accurate and Scalable Gaussian Processes for Fine-Grained Air Quality Inference</strong>. Zeel B Patel, Palak Purohit, Harsh Patel, Shivam Sahni, Nipun Batra</li></ol><h3 id="Epidemic-forecasting"><a href="#Epidemic-forecasting" class="headerlink" title="Epidemic forecasting"></a>Epidemic forecasting</h3><ol><li><strong>CausalGNN: Causal-Based Graph Neural Networks for Spatio-Temporal Epidemic Forecasting</strong>. Lijing Wang, Aniruddha Adiga, Jiangzhuo Chen, Adam Sadilek, Srinivasan Venkatramanan, Madhav Marathe</li></ol>]]></content>
    
    
    <categories>
      
      <category>论文阅读</category>
      
    </categories>
    
    
    <tags>
      
      <tag>时空数据挖掘</tag>
      
      <tag>AAAI 2022</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【论文投稿-2022】2022年人工智能和数据挖掘顶级会议投稿日期</title>
    <link href="/posts/7c9718ae/"/>
    <url>/posts/7c9718ae/</url>
    
    <content type="html"><![CDATA[<p>2022的前两个月，在过年、改论文，修改基金项目的过程中，时间不知不觉就过去了。刚好今天周六，趁这个时间，对2022年人工智能和数据挖掘相关顶级会议征稿日期进行统计。</p><span id="more"></span><table><thead><tr><th><strong>Year</strong></th><th><strong>Conference</strong></th><th><strong>Link</strong></th><th>**Deadline **</th></tr></thead><tbody><tr><td>2022</td><td>WSDM 2022</td><td><a href="http://www.wsdm-conference.org/2022/">http://www.wsdm-conference.org/2022/</a></td><td>2021-08-13</td></tr><tr><td></td><td>AAAI 2022</td><td><a href="https://aaai.org/Conferences/AAAI-22/aaai22call/">https://aaai.org/Conferences/AAAI-22/aaai22call/</a></td><td>2021-09-08</td></tr><tr><td></td><td>ICLR 2022</td><td><a href="https://iclr.cc/Conferences/2022/CallForPapers">https://iclr.cc/Conferences/2022/CallForPapers</a></td><td>2021-10-05</td></tr><tr><td></td><td>SDM 2022</td><td><a href="https://www.siam.org/conferences/cm/conference/sdm22">https://www.siam.org/conferences/cm/conference/sdm22</a></td><td>2021-10-12</td></tr><tr><td></td><td>WWW 2022</td><td><a href="https://www2022.thewebconf.org/">https://www2022.thewebconf.org/</a></td><td>2021-10-21</td></tr><tr><td></td><td>IJCAI 2022</td><td><a href="https://ijcai-22.org/calls-papers/">https://ijcai-22.org/calls-papers/</a></td><td>2022-01-14</td></tr><tr><td></td><td>ICML 2022</td><td><a href="https://icml.cc/Conferences/2022/CallForPapers">https://icml.cc/Conferences/2022/CallForPapers</a></td><td>2022-02-03</td></tr><tr><td></td><td>KDD 2022</td><td><a href="https://kdd.org/kdd2022/cfpResearch.html">https://kdd.org/kdd2022/cfpResearch.html</a></td><td>2022-02-10</td></tr><tr><td></td><td>CIKM 2022</td><td><a href="https://www.cikm2022.org/calls">https://www.cikm2022.org/calls</a></td><td>2022-05-16</td></tr><tr><td></td><td>NIPS 2022</td><td><a href="https://neurips.cc/Conferences/2022/CallForPapers">https://neurips.cc/Conferences/2022/CallForPapers</a></td><td>2022-05-19</td></tr><tr><td></td><td>ICDM 2022</td><td><a href="https://icdm22.cse.usf.edu/calls/Papers.html">https://icdm22.cse.usf.edu/calls/Papers.html</a></td><td>2022-06-10</td></tr><tr><td></td><td>SIGSPATIAL 2022</td><td><a href="https://sigspatial2022.sigspatial.org/">https://sigspatial2022.sigspatial.org/</a></td><td>2022-06-10</td></tr></tbody></table><p><strong>More:</strong> If you want to find more conferences information, you can visit the website (<a href="http://www.wikicfp.com/cfp/series?t=c&i=A">http://www.wikicfp.com/cfp/series?t=c&amp;i=A</a>).</p>]]></content>
    
    
    <categories>
      
      <category>论文阅读</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数据挖掘</tag>
      
      <tag>论文投稿</tag>
      
      <tag>人工智能</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>数说2021 展望2022</title>
    <link href="/posts/23dbe718/"/>
    <url>/posts/23dbe718/</url>
    
    <content type="html"><![CDATA[<p>过去的一年，疫情一直持续着，在过好自己生活的同时，也关注着疫情的发展。</p><span id="more"></span><p>希望新的一年，疫情早早过去，人们又可以热情地拥抱，开心地欢聚，自在地旅游。时间过得很快，今天就是今年的最后一天，对今年的进展进行梳理，回顾过去，立足当下，展望未来。</p><p>将过去一年的进展小结为12点。</p><ol><li>在知乎发布文章16篇<ul><li><a href="https://zhuanlan.zhihu.com/p/388237282">https://zhuanlan.zhihu.com/p/388237282</a> # 易经的智慧</li><li><a href="https://zhuanlan.zhihu.com/p/420738345">https://zhuanlan.zhihu.com/p/420738345</a> # 近3年用于时空数据挖掘的图神经网络论文（2018-2021）</li><li><a href="https://zhuanlan.zhihu.com/p/423323595">https://zhuanlan.zhihu.com/p/423323595</a> # IJCAI 2021 时空数据挖掘论文</li><li><a href="https://zhuanlan.zhihu.com/p/423342733">https://zhuanlan.zhihu.com/p/423342733</a> # KDD 2021 时空数据挖掘论文</li><li><a href="https://zhuanlan.zhihu.com/p/425080085">https://zhuanlan.zhihu.com/p/425080085</a> # 专利写作与申请</li><li><a href="https://zhuanlan.zhihu.com/p/426898203">https://zhuanlan.zhihu.com/p/426898203</a> # 【时空数据挖掘】- 任务</li><li><a href="https://zhuanlan.zhihu.com/p/427725872">https://zhuanlan.zhihu.com/p/427725872</a> # 【纪录片】-《我的章鱼老师》</li><li><a href="https://zhuanlan.zhihu.com/p/435647899">https://zhuanlan.zhihu.com/p/435647899</a> # 机器学习中的数学</li><li><a href="https://zhuanlan.zhihu.com/p/435844303">https://zhuanlan.zhihu.com/p/435844303</a> # 机器学习范式</li><li><a href="https://zhuanlan.zhihu.com/p/435882797">https://zhuanlan.zhihu.com/p/435882797</a> # 【时空数据挖掘】- 数据</li><li><a href="https://zhuanlan.zhihu.com/p/435890647">https://zhuanlan.zhihu.com/p/435890647</a> # 【时空数据挖掘】- 方法</li><li><a href="https://zhuanlan.zhihu.com/p/435895312">https://zhuanlan.zhihu.com/p/435895312</a> # 【时空数据挖掘】 - 层次体系构建</li><li><a href="https://zhuanlan.zhihu.com/p/438483095">https://zhuanlan.zhihu.com/p/438483095</a> # 论文写作–如何写好一篇综述</li><li><a href="https://zhuanlan.zhihu.com/p/438670862">https://zhuanlan.zhihu.com/p/438670862</a> # 空气质量知多少，早上跑步好不好？</li><li><a href="https://zhuanlan.zhihu.com/p/440291388">https://zhuanlan.zhihu.com/p/440291388</a> # WWW 2021 时空数据挖掘论文</li><li><a href="https://zhuanlan.zhihu.com/p/442419220">https://zhuanlan.zhihu.com/p/442419220</a> # ACM SIGSPATIAL 2021 时空数据挖掘论文</li></ul></li><li>在博客发布文章6篇<ul><li><a href="http://xiepeng21.cn/%E6%97%B6%E7%A9%BA%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E8%AE%BA%E6%96%87-AAAI2021.html">http://xiepeng21.cn/%E6%97%B6%E7%A9%BA%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E8%AE%BA%E6%96%87-AAAI2021.html</a> # 时空数据挖掘论文-AAAI 2021</li><li><a href="http://xiepeng21.cn/%E3%80%90%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%91Adaboost%E7%AE%97%E6%B3%95.html">http://xiepeng21.cn/%E3%80%90%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%91Adaboost%E7%AE%97%E6%B3%95.html</a> # 【机器学习】AdaBoost算法</li><li><a href="http://xiepeng21.cn/%E8%BF%91%E4%B8%89%E5%B9%B4%E7%94%A8%E4%BA%8E%E6%97%B6%E7%A9%BA%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E7%9A%84GNN%E8%AE%BA%E6%96%87%E6%B1%87%E6%80%BB.html">http://xiepeng21.cn/%E8%BF%91%E4%B8%89%E5%B9%B4%E7%94%A8%E4%BA%8E%E6%97%B6%E7%A9%BA%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E7%9A%84GNN%E8%AE%BA%E6%96%87%E6%B1%87%E6%80%BB.html</a> # 近三年用于时空数据挖掘的GNN论文汇总</li><li><a href="http://xiepeng21.cn/2021%E5%B9%B4%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%92%8C%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E7%9B%B8%E5%85%B3%E4%BC%9A%E8%AE%AE%E6%8A%95%E7%A8%BF%E6%97%B6%E9%97%B4.html">http://xiepeng21.cn/2021%E5%B9%B4%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%92%8C%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E7%9B%B8%E5%85%B3%E4%BC%9A%E8%AE%AE%E6%8A%95%E7%A8%BF%E6%97%B6%E9%97%B4.html</a> # 2021年机器学习和数据挖掘相关会议投稿时间</li><li><a href="http://xiepeng21.cn/%E7%94%A8Latex%E7%BC%96%E8%AF%91%E4%B8%AD%E6%96%87%E6%96%87%E6%A1%A3.html">http://xiepeng21.cn/%E7%94%A8Latex%E7%BC%96%E8%AF%91%E4%B8%AD%E6%96%87%E6%96%87%E6%A1%A3.html</a> # 【Latex经验】用Latex编译中文文档</li><li><a href="http://xiepeng21.cn/OneDrive%20%E7%99%BB%E5%BD%95%E6%97%B6%E4%B8%80%E7%9B%B4%E8%BD%AC%E5%9C%88%E5%9C%88.html">http://xiepeng21.cn/OneDrive%20%E7%99%BB%E5%BD%95%E6%97%B6%E4%B8%80%E7%9B%B4%E8%BD%AC%E5%9C%88%E5%9C%88.html</a> # OneDrive 登录时一直转圈圈</li></ul></li><li>主研1个国家重点研发项目课题</li><li>合作论文3篇，正在写1篇论文</li><li>申请专利1项</li><li>申请软著1项</li><li>成为1个国际数据挖掘领域顶级期刊TKDE的审稿人</li><li>看完12本书</li><li>运动50天 # 趁年轻 去运动</li><li>看完31部电影</li><li>看完3部电视剧</li><li>看完5部纪录片</li></ol><p>站在一年的结尾，想说的话很多，想了想，分享一段自己喜欢的话，作为今年的总结。</p><blockquote><p>人生错综复杂，我们应该为生活的神奇和丰富而欣喜，而不应为人生的变化而沮丧。生活是什么？生活是在你已经规划好的事情之外所发生的一切。</p></blockquote><p>新的一年，用心去生活，勇敢去拼搏。</p>]]></content>
    
    
    <categories>
      
      <category>随笔感悟</category>
      
    </categories>
    
    
    <tags>
      
      <tag>年度总结</tag>
      
      <tag>趁年轻 去运动</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>OneDrive 登录时一直转圈圈</title>
    <link href="/posts/7340ecaf/"/>
    <url>/posts/7340ecaf/</url>
    
    <content type="html"><![CDATA[<p>今天早上突然遇到OneDrive登录时，一直转圈圈，登录不了，采取了几种方法，查询了一些网上资料，现总结如下。</p><span id="more"></span><ol><li>换一个网络连接。可以使用手机热点，有人报告说电信网络曾经登录不了，我刚好就是电信网络；</li><li>更改网络设置。在“更改网络适配器”选项中，打开当前网络的“属性”，将“Internet 协议版本6”前面的√去掉，然后用快捷键“Win+R”输出cmd，调出命令窗口，输入“ipconfig &#x2F;flushdns”命令即可；</li><li>关闭科学上网软件。</li></ol><p>笔者是在经历了以上三个步骤之后，OneDrive就可以正常登录。如果你遇到不能登录OneDrive，以上方法不能解决或者有新的办法，欢迎留言交流。</p>]]></content>
    
    
    <categories>
      
      <category>经验技巧</category>
      
    </categories>
    
    
    <tags>
      
      <tag>OneDrive</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【Latex经验】用Latex编译中文文档</title>
    <link href="/posts/59479fbc/"/>
    <url>/posts/59479fbc/</url>
    
    <content type="html"><![CDATA[<p>我们知道用Latex编辑和编译英文文章十分高效和便捷，但是编译中文文档，经常会出现问题。那么常见的解决办法，如下：</p><span id="more"></span><p>加入包\usepackage[UTF8]{ctex}, 使用xelatex编译器。</p><p>或者<br>修改\documentclass [UTF8]{ctexart}<br>\begin {document}</p><p>及时做好文件备份，采用记事本复制粘贴文本，统一使用UTF8编码格式。</p><h4 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h4><ol><li><a href="https://blog.csdn.net/njc_sec/article/details/88630813">https://blog.csdn.net/njc_sec/article/details/88630813</a> LaTeX之TexStudio中文无法显示问题解决</li></ol>]]></content>
    
    
    <categories>
      
      <category>经验技巧</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Latex</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【论文投稿-2021】2021年机器学习和数据挖掘相关会议投稿时间</title>
    <link href="/posts/82aa9d8e/"/>
    <url>/posts/82aa9d8e/</url>
    
    <content type="html"><![CDATA[<p>按月份对2021年机器学习和数据挖掘相关会议征稿进行统计。</p><span id="more"></span><h3 id="2021年"><a href="#2021年" class="headerlink" title="2021年"></a>2021年</h3><h4 id="2021-01"><a href="#2021-01" class="headerlink" title="2021-01"></a>2021-01</h4><ol><li>IJCNN 2021（The international joint conference on neural networks），Online，截稿日期：2021-01-15 （推迟为2021-02-10）<a href="https://www.ijcnn.org/">https://www.ijcnn.org/</a></li><li>IJCAI 2021 (International Joint Conference on Artificial Intelligence), Montreal, Canada, 截稿日期：2021-01-20（摘要提交截止日期：2021-01-13）<a href="https://ijcai-21.org/">https://ijcai-21.org/</a></li></ol><h4 id="2021-02"><a href="#2021-02" class="headerlink" title="2021-02"></a>2021-02</h4><ol><li>KDD 2021（ACM SIGKDD Conference on Knowledge Discovery and Data Mining），Singapore，截稿日期：2021-02-08 <a href="https://www.kdd.org/kdd2021/">https://www.kdd.org/kdd2021/</a></li></ol><h4 id="2021-04"><a href="#2021-04" class="headerlink" title="2021-04"></a>2021-04</h4><ol><li>CICAI 2021 (CAAI International Conference on artificial intelligence 2021) (cicai.caai.cn), 中国杭州，截稿日期：2021-04-18 <a href="https://cicai.caai.cn/">https://cicai.caai.cn/</a></li></ol><h4 id="2021-05"><a href="#2021-05" class="headerlink" title="2021-05"></a>2021-05</h4><ol><li>CCKS 2021（China Conference on Knowledge Graph and Semantic Computing），中国广州，截稿日期：2021-5-10 <a href="http://sigkg.cn/ccks2021/">http://sigkg.cn/ccks2021/</a></li><li>CIKM 2021 （Conference on Information and Knowledge Management），Online，截稿日期：2021-05-26 （摘要提交截止日期：2021-05-19）<a href="https://www.cikm2021.org/">https://www.cikm2021.org/</a></li></ol><h4 id="2021-06"><a href="#2021-06" class="headerlink" title="2021-06"></a>2021-06</h4><ol><li>ACM SIGSPATIAL 2021 (ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems)，Beijing, China，截稿日期：2021-06-10 （摘要提交截止日期：2021-05-27）<a href="https://sigspatial2021.sigspatial.org/#:~:text=The%20ACM%20SIGSPATIAL%20International%20Conference%20on%20Advances%20in,the%20situation%20of%20COVID-19%20and%20international%20travel%20restrictions">https://sigspatial2021.sigspatial.org/#:~:text=The%20ACM%20SIGSPATIAL%20International%20Conference%20on%20Advances%20in,the%20situation%20of%20COVID-19%20and%20international%20travel%20restrictions</a>.</li><li>ICDM2021 （International Conference on Data Mining），Auckland, New Zealand，截稿日期：2021-06-11 <a href="https://icdm2021.auckland.ac.nz/">https://icdm2021.auckland.ac.nz/</a></li><li>ISKE2021 （International Conference on Intelligent Systems and Knowledge Engineering），中国成都，截稿日期：2021-06-30 (（推迟为2021-07-31）<a href="http://iske2021.org/#:~:text=Welcome%20to%20ISKE%202021%20It%20is%20our%20great,following%20the%20successful%20previous%20ISKE%20Conferences%20since%202006">http://iske2021.org/#:~:text=Welcome%20to%20ISKE%202021%20It%20is%20our%20great,following%20the%20successful%20previous%20ISKE%20Conferences%20since%202006</a>.</li></ol><h4 id="2021-08"><a href="#2021-08" class="headerlink" title="2021-08"></a>2021-08</h4><ol><li>WSDM2022 （Web Search and Data Mining）, Arizona, USA, 截止日期：2021-08-09 <a href="http://www.wsdm-conference.org/2022/">http://www.wsdm-conference.org/2022/</a></li></ol><h4 id="2021-09"><a href="#2021-09" class="headerlink" title="2021-09"></a>2021-09</h4><ol><li>AAAI2022（The Thirty-Sixth AAAI Conference on Artificial Intelligence），Vancouver, BC, Canada, 截稿日期：2021-09-08 （摘要提交截止日期：2021-08-30）<a href="https://aaai.org/Conferences/AAAI-22/">https://aaai.org/Conferences/AAAI-22/</a></li></ol><h4 id="2021-10"><a href="#2021-10" class="headerlink" title="2021-10"></a>2021-10</h4><ol><li>WWW 2022（International World Wide Web Conferences），Lyon, France, 截稿日期：2021-10-21 (摘要提交截止日期：2021-10-14) <a href="https://www2022.thewebconf.org/">https://www2022.thewebconf.org/</a></li><li>PAKDD 2022（The 26th Pacific-Asia Conference on Knowledge Discovery and Data Mining），Chengdu, China，截稿日期：2021-10-31 <a href="http://pakdd.net/">http://pakdd.net/</a></li></ol><h3 id="2022年"><a href="#2022年" class="headerlink" title="2022年"></a>2022年</h3><h4 id="2022-01"><a href="#2022-01" class="headerlink" title="2022-01"></a>2022-01</h4><ol><li>ICDM2022（IEEE International Conference on Data Mining），New York, USA，截稿日期：2022-01-15 <a href="https://www.data-mining-forum.de/icdm2022.php">https://www.data-mining-forum.de/icdm2022.php</a></li></ol><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><ol><li><a href="http://www.wikicfp.com/cfp/series?t=c&i=A">http://www.wikicfp.com/cfp/series?t=c&amp;i=A</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>论文阅读</category>
      
    </categories>
    
    
    <tags>
      
      <tag>机器学习</tag>
      
      <tag>数据挖掘</tag>
      
      <tag>论文投稿</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>近三年用于时空数据挖掘的GNN论文汇总</title>
    <link href="/posts/b0dd406c/"/>
    <url>/posts/b0dd406c/</url>
    
    <content type="html"><![CDATA[<h4 id="综述"><a href="#综述" class="headerlink" title="综述"></a>综述</h4><ol><li>Graph Neural Network for Traffic Forecasting: A Survey. arXiv 2021.<span id="more"></span></li></ol><h4 id="顶级会议论文"><a href="#顶级会议论文" class="headerlink" title="顶级会议论文"></a>顶级会议论文</h4><p>—2021—</p><ol><li>Traffic Flow Forecasting with Spatial-Temporal Graph Diffusion Network. AAAI 2021. code (<a href="https://github.com/jillbetty001/ST-GDN">https://github.com/jillbetty001/ST-GDN</a>)</li><li>Spatial-Temporal Fusion Graph Neural Networks for Traffic Flow Forecasting. AAAI 2021. code (<a href="https://github.com/MengzhangLI/STFGNN">https://github.com/MengzhangLI/STFGNN</a>)</li><li>Hierarchical Graph Convolution Networks for Traffic Forecasting. AAAI 2021. code (<a href="https://github.com/guokan987/HGCN">https://github.com/guokan987/HGCN</a>)</li><li>FC-GAGA: Fully Connected Gated Graph Architecture for Spatio-Temporal Traffic Forecasting. AAAI 2021. code (<a href="https://github.com/boreshkinai/fc-gaga">https://github.com/boreshkinai/fc-gaga</a>)</li><li>Coupled Layer-wise Graph Convolution for Transportation Demand Prediction. AAAI 2021. code (<a href="https://github.com/Essaim/CGCDemandPrediction">https://github.com/Essaim/CGCDemandPrediction</a>)</li><li>Discrete Graph Structure Learning for Forecasting Multiple Time Series. ICLR 2021. code (<a href="https://github.com/chaoshangcs/GTS">https://github.com/chaoshangcs/GTS</a>)</li></ol><p>—2020—<br>7. Adaptive graph convolutional recurrent network for traffic forecasting. NeurIPS 2020.<br>8. PM2. 5-GNN: A Domain Knowledge Enhanced Graph Neural Network For PM2. 5 Forecasting. SIGSPATIAL 2020. code (<a href="https://github.com/shawnwang-tech/PM2.5-GNN">https://github.com/shawnwang-tech/PM2.5-GNN</a>)<br>9. Spatial-temporal sychronous graph convolutional networks: A new framework for spatial-temporal network data forecasting. AAAI 2020. code (<a href="https://github.com/wanhuaiyu/STSGCN">https://github.com/wanhuaiyu/STSGCN</a>)<br>10. GMAN: A Graph Multi-Attention Network for Traffic Prediction. AAAI 2020. code (<a href="https://github.com/zhengchuanpan/GMAN">https://github.com/zhengchuanpan/GMAN</a>)<br>11. Spatio-Temporal Graph Structure Learning for Traffic Forecasting. AAAI 2020.<br>12. STGRAT: A Spatio-temporal Graph Attention Network for Traffic Forecasting. AAAI 2020.<br>13. Predicting Origin-Destination Flow via Multi-Perspective Graph Convolutional Network. ICDE 2020.<br>14. Stochastic Origin-Destination Matrix Forecasting Using Dual-Stage Graph Convolutional, Recurrent Neural Networks. ICDE 2020. code (<a href="https://github.com/hujilin1229/od-pred">https://github.com/hujilin1229/od-pred</a>)<br>15. Learning Effective Road Network Representation with Hierarchical Graph Neural Networks. KDD 2020.<br>16. Connecting the Dots: Multivariate Time Series Forecasting with Graph Neural Networks. KDD 2020. code (<a href="https://github.com/nnzhan/MTGNN">https://github.com/nnzhan/MTGNN</a>)<br>17. Calendar Graph Neural Networks for Modeling Time Structures in Spatiotemporal User Behaviors. KDD 2020.<br>18. ConSTGAT: Contextual Spatial-Temporal Graph Attention Network for Travel Time Estimation at Baidu Maps. KDD 2020.<br>19. Hybrid Spatio-Temporal Graph Convolutional Network: Improving Traffic Prediction with Navigation Data. KDD 2020.<br>20. Dynamic Heterogeneous Graph Neural Network for Real-time Event Prediction. KDD 2020.</p><p>—2019—<br>21. Spatiotemporal Multi-Graph Convolution Network for Ride-hailing Demand Forecasting. AAAI 2019.<br>22. Attention based spatial-temporal graph convolutional networks for traffic flow forecasting. AAAI 2019. code(<a href="https://github.com/guoshnBJTU/ASTGCN-r-pytorch">https://github.com/guoshnBJTU/ASTGCN-r-pytorch</a>)<br>23. Graph wavenet for deep spatial-temporal graph modeling. IJCAI 2019. (<a href="https://github.com/nnzhan/Graph-WaveNet">https://github.com/nnzhan/Graph-WaveNet</a>)</p><p>—2018—<br>24. Diffusion Convolutional Recurrent Neural Network: Data-driven Traffic Forecasting. ICLR 2018.<br>25. Bike flow prediction with multi-graph convolutional networks. SIGSPATIAL 2018. (<a href="https://github.com/Di-Chai/GraphCNN-Bike">https://github.com/Di-Chai/GraphCNN-Bike</a>)<br>26. Spatio-Temporal Graph Convolutional Networks: A Deep Learning Framework for Traffic Forecasting. IJCAI 2018. code (<a href="https://github.com/liyaguang/DCRNN">https://github.com/liyaguang/DCRNN</a>)<br>27. Incorporating Corporation Relationship via Graph Convolutional Neural Networks for Stock Price Prediction. CIKM 2018.</p><h4 id="期刊论文"><a href="#期刊论文" class="headerlink" title="期刊论文"></a>期刊论文</h4><p>—2021—</p><ol><li>Learning Dynamics and Heterogeneity of Spatial-Temporal Graph Data for Traffic Forecasting. TKDE 2021.</li><li>A Graph Convolutional Stacked Bidirectional Unidirectional-LSTM Neural Network for Metro Ridership Prediction. TITS 2021.</li><li>FTPG: A Fine-Grained Traffic Prediction Method With Graph Attention Network Using Big Trace Data. TITS 2021.</li><li>GraphTTE: Travel Time Estimation Based on Attention-Spatiotemporal Graphs. IEEE Signal Processing Letters 2021.</li><li>Predicting origin-destination ride-sourcing demand with a spatio-temporal encoder-decoder residual multi-graph convolutional network. Transportation Research Part C 2021. code (<a href="https://github.com/kejintao/ST-ED-RMGC">https://github.com/kejintao/ST-ED-RMGC</a>)</li><li>Multi-community passenger demand prediction at region level based on spatio-temporal graph convolutional network. Transportation Research Part C: Emerging Technologies 2021.</li><li>TAGCN: Station-level demand prediction for bike-sharing system via a temporal attention graph convolution network. Information Sciences 2021.</li><li>Long-term Origin-Destination Demand Prediction with Graph Deep Learning. IEEE Transactions on Big Data 2021.</li></ol><p>—2020—<br>9. Spatial temporal incidence dynamic graph neural networks for traffic flow forecasting. Information Sciences 2020. code (<a href="https://github.com/RingBDStack/GCNN-In-Traffic">https://github.com/RingBDStack/GCNN-In-Traffic</a>)<br>10. Predicting Citywide Crowd Flows in Irregular Regions Using Multi-View Graph Convolutional Networks. TKDE 2020.</p><h4 id="预印本论文"><a href="#预印本论文" class="headerlink" title="预印本论文"></a>预印本论文</h4><p>—2021—</p><ol><li>HighAir: A Hierarchical Graph Neural Network-Based Air Quality Forecasting Method. arXiv 2021. </li><li>Spatial-Temporal Tensor Graph Convolutional Network for Traffic Prediction. arXiv 2021. </li><li>Passenger Mobility Prediction via Representation Learning for Dynamic Directed and Weighted Graph. arXiv 2021. </li><li>Dynamic Planning of Bicycle Stations in Dockless Public Bicycle-sharing System Using Gated Graph Neural Network. arXiv 2021. </li><li>Bayesian Graph Convolutional Network for Traffic Prediction. arXiv 2021.</li></ol><p>—2020—<br>6. Physical-Virtual Collaboration Graph Network for Station-Level Metro Ridership Prediction. arXiv 2020. code (<a href="https://github.com/ivechan/PVCGN">https://github.com/ivechan/PVCGN</a>)<br>7. Transfer Learning with Graph Neural Networks for Short-Term Highway Traffic Forecasting. arXiv 2020. code (<a href="https://github.com/tanwimallick/TL-DCRNN">https://github.com/tanwimallick/TL-DCRNN</a>)</p><p>—2019—<br>8. Incrementally Improving Graph WaveNet Performance on Traffic Prediction. arXiv 2019. code (<a href="https://github.com/sshleifer/Graph-WaveNet">https://github.com/sshleifer/Graph-WaveNet</a>)<br>9. STGRAT: A Spatio-temporal Graph Attention Network for Traffic Forecasting. arXiv 2019.</p><p>—2018—<br>10. Efficient Metropolitan Traffic Prediction Based on Graph Recurrent Neural Network. arXiv 2018.<br>11. Dynamic spatio-temporal graph-based cnns for traffic prediction. arXiv 2018.</p><h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><p>欢迎各位在评论区留言，补充，提出您的宝贵意见和建议，我们一起学习，成长，进步。</p><h4 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h4><ol><li><a href="https://github.com/xiepeng21/research_spatio-temporal-data-mining">https://github.com/xiepeng21/research_spatio-temporal-data-mining</a></li><li><a href="https://github.com/jwwthu/GNN4Traffic/">https://github.com/jwwthu/GNN4Traffic/</a></li><li><a href="https://github.com/Knowledge-Precipitation-Tribe/Spatio-Temporal-papers">https://github.com/Knowledge-Precipitation-Tribe/Spatio-Temporal-papers</a></li><li><a href="https://github.com/datawhalechina/spatio-temporal-papers">https://github.com/datawhalechina/spatio-temporal-papers</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>论文阅读</category>
      
    </categories>
    
    
    <tags>
      
      <tag>时空数据挖掘</tag>
      
      <tag>GNN</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【机器学习】AdaBoost算法</title>
    <link href="/posts/2a69915c/"/>
    <url>/posts/2a69915c/</url>
    
    <content type="html"><![CDATA[<p><img src="/../images/AdaBoost.png"></p>]]></content>
    
    
    <categories>
      
      <category>机器学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>机器学习</tag>
      
      <tag>AdaBoost算法</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【AAAI 2021】时空数据挖掘论文</title>
    <link href="/posts/a944fccc/"/>
    <url>/posts/a944fccc/</url>
    
    <content type="html"><![CDATA[<p>今年AAAI2021接收论文投稿数为9034篇，总共有7911篇论文进行了评审，最终录取篇数为1692篇，接收率为21.4%。</p><span id="more"></span><h4 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h4><p>近日公布出了论文的接收列表，笔者对其中的时空数据挖掘相关的论文进行了梳理，共42篇，占总录取篇数比例为2.48%，具体如下：</p><ol><li><p><em><strong>Deep Switching Auto-Regressive Factorization: Application to Time Series Forecasting</strong></em>. Amirreza Farnoosh, Bahar Azari, Sarah Ostadabbas</p></li><li><p><em><strong>Traffic Flow Prediction with Vehicle Trajectories</strong></em>. Mingqian Li, Panrong Tong, Mo Li, Zhongming Jin, Jianqiang Huang, Xian-Sheng Hua</p></li><li><p><em><strong>Dynamic Gaussian Mixture Based Deep Generative Model for Robust Forecasting on Sparse Multivariate Time Series</strong></em>. Yinjun Wu, Jingchao Ni, Wei Cheng, Bo Zong, Dongjin Song, Zhengzhang Chen, Yanchi Liu, Xuchao Zhang, Haifeng Chen, Susan B Davidson</p></li><li><p><em><strong>Robust Spatio-Temporal Purchase Prediction via Deep Meta Learning</strong></em>. Huiling Qin, Songyu Ke, Xiaodu Yang, Haoran Xu, Xianyuan Zhan, Yu Zheng</p></li><li><p><em><strong>Attentive Neural Point Processes for Event Forecasting</strong></em>. Yulong Gu</p></li><li><p><em><strong>Pre-Training Context and Time Aware Location Embeddings from Spatial-Temporal Trajectories for User Next Location Prediction</strong></em>. Yan Lin, Huaiyu Wan, Shengnan Guo, Youfang Lin</p></li><li><p><em><strong>Disentangled Multi-Relational Graph Convolutional Network for Pedestrian Trajectory Prediction</strong></em>. Inhwan Bae, Hae-Gon Jeon</p></li><li><p><em><strong>Second Order Techniques for Learning Time-Series with Structural Breaks</strong></em>. Takayuki Osogami</p></li><li><p><em><strong>Correlative Channel-Aware Fusion for Multi-View Time Series Classification</strong></em>. Yue Bai, Lichen Wang, Zhiqiang Tao, Sheng Li, Yun Fu</p></li><li><p><em><strong>Coupled Layer-Wise Graph Convolution for Transportation Demand Prediction</strong></em>. Junchen Ye, Leilei Sun, Bowen Du, Yanjie Fu, Hui Xiong</p></li><li><p><em><strong>Learnable Dynamic Temporal Pooling for Time Series Classification</strong></em>. Dongha Lee, Seonghyeon Lee, Hwanjo Yu</p></li><li><p><em><strong>CARPe Posterum: A Convolutional Approach for Real-Time Pedestrian Path Prediction</strong></em>. Matias Mendieta, Hamed Tabkhi</p></li><li><p><em><strong>Learning Representations for Incomplete Time Series Clustering</strong></em>. Qianli Ma, Chuxin Chen, Sen Li, Garrison Cottrell</p></li><li><p><em><strong>Hierarchical Graph Convolution Network for Traffic Forecasting</strong></em>. Kan Guo, Yongli Hu, Yanfeng Sun, Sean Qian, Junbin Gao, Baocai Yin</p></li><li><p><em><strong>Physics-Informed Deep Learning for Traffic State Estimation: A Hybrid Paradigm Informed by Second-Order Traffic Models</strong></em>. Rongye Shi, Zhaobin Mo, Xuan Di</p></li><li><p><em><strong>PREMERE: Meta-Reweighting via Self-Ensembling for Point-of-Interest Recommendation</strong></em>. Minseok Kim, Hwanjun Song, Doyoung Kim, Kijung Shin, Jae-Gil Lee</p></li><li><p><em><strong>GSNet: Learning Spatial-Temporal Correlations from Geographical and Semantic Aspects for Traffic Accident Risk Forecasting</strong></em>. Beibei Wang, Youfang Lin, Shengnan Guo, Huaiyu Wan</p></li><li><p><em><strong>Temporal Latent Autoencoder: A Method for Probabilistic Multivariate Time Series Forecasting</strong></em>. Nam Nguyen, Brian Quanz</p></li><li><p><em><strong>A Multi-Step-Ahead Markov Conditional Forward Model with Cube Perturbations for Extreme Weather Forecasting</strong></em>. Chia-Yuan Chang, Cheng-Wei Lu, Chuan-Ju Wang</p></li><li><p><em><strong>Graph Neural Network-Based Anomaly Detection in Multivariate Time Series</strong></em>. Ailin Deng, Bryan Hooi</p></li><li><p><em><strong>ShapeNet: A Shapelet-Neural Network Approach for Multivariate Time Series Classification</strong></em>. Guozhong Li, Byron Choi, Jianliang Xu, Sourav S Bhowmick, Kwok-Pan Chun, Grace Lai-Hung Wong</p></li><li><p><em><strong>Joint-Label Learning by Dual Augmentation for Time Series Classification</strong></em>. Qianli Ma, Zhenjing Zheng, Jiawei Zheng, Sen Li, Wanqing Zhuang, Garrison Cottrell</p></li><li><p><em><strong>Out-of-Town Recommendation with Travel Intention Modeling</strong></em>. Haoran Xin, Xinjiang Lu, Tong Xu, Hao Liu, Jingjing Gu, Dejing Dou, Hui Xiong</p></li><li><p><em><strong>Reinforced Imitative Graph Representation Learning for Mobile User Profiling: An Adversarial Training Perspective</strong></em>. Dongjie Wang, Pengyang Wang, Kunpeng Liu, Yuanchun Zhou, Charles E Hughes, Yanjie Fu</p></li><li><p><em><strong>Spatial-Temporal Fusion Graph Neural Networks for Traffic Flow Forecasting</strong></em>. Mengzhang Li, Zhanxing Zhu</p></li><li><p><em><strong>Hierarchically and Cooperatively Learning Traffic Signal Control</strong></em>. Bingyu Xu, Yaowei Wang, Zhaozhi Wang, Huizhu Jia, Zongqing Lu</p></li><li><p><em><strong>Temporal Pyramid Network for Pedestrian Trajectory Prediction with Multi-Supervision</strong></em>. Rongqin Liang, Yuanman Li, Xia Li, Yi Tang, Jiantao Zhou, Wenbin Zou</p></li><li><p><em><strong>Capturing Uncertainty in Unsupervised GPS Trajectory Segmentation Using Bayesian Deep Learning</strong></em>. Christos Markos, James Yu, Richard Yi Da Xu</p></li><li><p><em><strong>Joint Air Quality and Weather Prediction Based on Multi-Adversarial Spatiotemporal Networks</strong></em>. Jindong Han, Hao Liu, Hengshu Zhu, Hui Xiong, Dejing Dou</p></li><li><p><em><strong>Community-Aware Multi-Task Transportation Demand Prediction</strong></em>. Hao Liu, Qiyu Wu, Fuzhen Zhuang, Xinjiang Lu, Dejing Dou, Hui Xiong</p></li><li><p><em><strong>Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting</strong></em>. Haoyi Zhou, Shanghang Zhang, Jieqi Peng, Shuai Zhang, Jianxin Li, Hui Xiong, Wancai Zhang</p></li><li><p><em><strong>Generative Semi-Supervised Learning for Multivariate Time Series Imputation</strong></em>. Xiaoye Miao, Yangyang Wu, Jun Wang, Yunjun Gao, Xudong Mao, Jianwei Yin</p></li><li><p><em><strong>Modeling Heterogeneous Relations across Multiple Modes for Potential Crowd Flow Prediction</strong></em>. Qiang Zhou, Jingjing Gu, Xinjiang Lu, Fuzhen Zhuang, Yanchao Zhao, Qiuhong Wang, Xiao Zhang</p></li><li><p><em><strong>Learning Precise Temporal Point Event Detection with Misaligned Labels</strong></em>. Julien Schroeter, Kirill Sidorov, David Marshal</p></li><li><p><em><strong>Outlier Impact Characterization for Time Series Data</strong></em>. Jianbo Li, Lecheng Zheng, Yada Zhu, Jingrui He</p></li><li><p><em><strong>AttnMove: History Enhanced Trajectory Recovery via Attentional Network</strong></em>. Tong Xia, Jie Feng, Yunhan Qi, Fengli Xu, Yong Li, Diansheng Guo, Funing Sun</p></li><li><p><em><strong>Sub-Seasonal Climate Forecasting via Machine Learning: Challenges, Analysis, and Advances</strong></em>. Sijie He, Xinyan Li, Timothy DelSole, Pradeep Ravikumar, Arindam Banerjee</p></li><li><p><em><strong>FC-GAGA: Fully Connected Gated Graph Architecture for Spatio-Temporal Traffic Forecasting</strong></em>. Boris N. Oreshkin, Arezou Amini, Lucy Coyle, Mark Coates</p></li><li><p><em><strong>Meta-Learning Framework with Applications to Zero-Shot Time-Series Forecasting</strong></em>. Boris N. Oreshkin, Dmitri Carpov, Chapados Nicolas, Yoshua Bengio</p></li><li><p><em><strong>Multi-Layer Networks for Ensemble Precipitation Forecasts Postprocessing</strong></em>. Fengyang Xu, Guanbin Li, Yunfei Du, Zhiguang Chen, Yutong Lu</p></li><li><p><em><strong>Minimizing Energy Use of Mixed-Fleet Public Transit for Fixed-Route Service</strong></em>. Amutheezan Sivagnanam, Afiya Ayman, Michael Wilbur, Philip Pugliese, Abhishek Dubey, Aron Laszka</p></li><li><p><em><strong>Traffic Flow Forecasting with Spatial-Temporal Graph Diffusion Network</strong></em>. Xiyue Zhang, Chao Huang, Yong Xu, Lianghao Xia, Peng Dai, Liefeng Bo, Junbo Zhang, Yu Zheng</p></li></ol><h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><p>欢迎各位在评论区留言，补充，提出您的宝贵意见和建议，我们一起学习，成长，进步。</p><h4 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h4><ol><li><a href="https://aaai.org/Conferences/AAAI-21/wp-content/uploads/2020/12/AAAI-21_Accepted-Paper-List.Main_.Technical.Track_.pdf">https://aaai.org/Conferences/AAAI-21/wp-content/uploads/2020/12/AAAI-21_Accepted-Paper-List.Main_.Technical.Track_.pdf</a> AAAI 2021录取论文完整列表</li></ol>]]></content>
    
    
    <categories>
      
      <category>论文阅读</category>
      
    </categories>
    
    
    <tags>
      
      <tag>时空数据挖掘</tag>
      
      <tag>AAAI 2021</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【论文笔记-4】Attention Is All You Need</title>
    <link href="/posts/d3e954aa/"/>
    <url>/posts/d3e954aa/</url>
    
    <content type="html"><![CDATA[<p>Vaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, and Illia Polosukhin. “<a href="https://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf">Attention is all you need</a>.” In Advances in neural information processing systems, pp. 5998-6008. 2017.</p><span id="more"></span><h4 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h4><p>RNN、LSTM和GRU在序列建模、语言建模和机器翻译等领域被广泛应用。大量的工作来研究如何突破循环语言模型和编码器-解码器模型之间的界限。循环模型通常沿着输入和输出序列的符号位置进行因子计算。在计算时间中将位置与步骤对齐，生成隐含状态$h_t$的一个序列，作为先前的隐含状态$h_{t-1}$和位置$t$的输入的函数。这种固有的顺序特性妨碍了训练样本的并行化，而在较长的序列长度下，并行化就变得至关重要，因为内存约束限制了样本之间的批处理。最近的工作通过因子分解技巧和条件计算在计算效率上取得了显著的提高，同时也提高了后者的模型性能。然而，顺序计算的基本约束仍然存在。</p><p>注意力机制已经成为序列建模和转换模型中引人注目的一个组成部分，允许建模依赖关系而不考虑它们在输入或输出序列中的距离。除了少数情况外，注意力机制往往与循环神经网络一起使用。</p><p>在文章中，作者提出了Transformer模型，该模型避免了循环，而完全依赖于一个注意力机制来刻画输入和输出之间的全局依赖关系。</p><p>Transformer可以实现更大程度的并行化，在8块P100 GPU上只训练了12个小时，就可以在翻译质量方面达到一个新的水平。</p><h4 id="模型结构"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构</h4><p>大多数的经典神经序列转换模型都有一个编码器-解码器的结构。编码器将一个符号表示的输入序列$(x_1,…,x_n)$映射成连续表示的序列$z&#x3D;(z_1,…,z_n)$。给定$z$，解码器接下来生成符号表示的输出序列$(y_1,…,y_m)$，每次生成一个元素。在每一步，模型都是自回归的，在生成下一个符号时，使用先前生成的符号作为附加输入。Transformer模型沿袭了这种结构，在编码器和解码器中使用堆叠的自注意力、逐点的和全连接层，如下图所示，左边是编码器，右边是解码器。<br><img src="https://i.loli.net/2020/10/26/1XYm8ghp7R3nMtk.png" alt="1.png"></p><h5 id="编码器和解码器"><a href="#编码器和解码器" class="headerlink" title="编码器和解码器"></a>编码器和解码器</h5><p><strong>编码器部分：</strong> 编码器由6个相同的层堆叠组成。每层有两个子层，由下往上，第一层是一个多头自注意力机制，第二层是逐点式的全连接前馈网络。在每个子层上使用一个残差连接，然后进行层规范化（layer normalization）。也就是说每个子层的输出是LayerNorm($x$+Sublayer($x$))。</p><p><strong>解码器部分：</strong> 解码器也由6个相同的层堆叠组成。除了编码器的两个子层，解码器还加入了第三个子层，这个子层在编码器的输出上执行多头注意力操作。与编码器类似，解码器也会在每个子层上使用一个残差连接，然后进行层规范化。修改了解码器堆栈中的自注意力子层，以防止位置注意到后续位置。这个修改，是基于输出嵌入有一个位置偏移的事实考虑，确保了对位置$i$的预测只能依赖于小于$i$的已知输出。</p><h5 id="注意力机制"><a href="#注意力机制" class="headerlink" title="注意力机制"></a>注意力机制</h5><p>注意力机制函数可以被描述成将查询（query）、键（key）、值（value）映射到一个输出，其中查询、键、值和输出都是向量。输出以值的加权和的形式计算，其中分配给每个值的权重由查询与相应键的兼容函数计算。</p><h6 id="按比例的点积注意力（Scaled-Dot-Product-Attention）"><a href="#按比例的点积注意力（Scaled-Dot-Product-Attention）" class="headerlink" title="按比例的点积注意力（Scaled Dot-Product Attention）"></a>按比例的点积注意力（Scaled Dot-Product Attention）</h6><p>按比例的点积注意力结构如下图所示。输入包括$d_k$维的查询和键，以及$d_v$维的值。计算公式是$Attention(Q, K, V)&#x3D;\operatorname{softmax}\left(\frac{Q K^{T}}{\sqrt{d_{k}}}\right) V$。<br><img src="https://i.loli.net/2020/10/26/zg2RiLaEK7du9WQ.png" alt="2.png"></p><h6 id="多头注意力-Multi-Head-Attention"><a href="#多头注意力-Multi-Head-Attention" class="headerlink" title="多头注意力 (Multi-Head Attention)"></a>多头注意力 (Multi-Head Attention)</h6><p>与使用$d_{model}$维的键，值，查询执行单一注意力函数不同，作者发现使用不同的学习线性投影将查询，键，值投影到$d_k, d_k, d_v$维是有益的。然后，对每一个查询、键和值的投影版本并行执行注意力函数，生成$d_v$维的输出值。它们被连接起来并再次投影，从而产生最终的值。如下图所示。多头注意力使模型能够在不同的表示子空间中，在不同的位置共同关注信息。计算公式是<br>$$<br>\begin{aligned}<br>\text { MultiHead }(Q, K, V) &amp;&#x3D;\text { Concat }\left(\text { head }<em>{1}, \ldots, \text { head }</em>{\mathrm{h}}\right) W^{O} \<br>\text { where head }<em>{\mathrm{i}} &amp;&#x3D;\text { Attention }\left(Q W</em>{i}^{Q}, K W_{i}^{K}, V W_{i}^{V}\right)<br>\end{aligned}<br>$$<br><img src="https://i.loli.net/2020/10/26/LbFpjcHBoX2TqOx.png" alt="3.png"><br>其中，投影是参数矩阵，$W_{i}^{Q} \in \mathbb{R}^{d_{\text {model }} \times d_{k}}$，$W_{i}^{K} \in \mathbb{R}^{d_{\text {model }} \times d_{k}}$，$W_{i}^{V} \in \mathbb{R}^{d_{\text {model }} \times d_{v}}$ and $W^{O} \in \mathbb{R}^{h d_{v} \times d_{model}}$。本文中采用了$h&#x3D;8$个分布式的注意力层（头），每层的$d_k&#x3D;d_v&#x3D;d_{model}&#x2F;h&#x3D;64$。由于每个头的维数降低，其总计算代价与全维单头关注的计算代价相似。</p><h6 id="注意力机制在模型中的应用"><a href="#注意力机制在模型中的应用" class="headerlink" title="注意力机制在模型中的应用"></a>注意力机制在模型中的应用</h6><ul><li>在“编码器-解码器注意力”层中，查询来自前一解码器层，键和值来自编码器的输出。</li><li>编码器包含子注意力层。在自注意力层中，所有的键、值和查询都来自相同的位置，在本例中是编码器中前一层的输出。所述编码器中的每个位置都可以顾及所述编码器的前一层中的所有位置。</li><li>解码器中的自注意力层允许解码器中的每个位置关注解码器中的所有位置，直到并包括该位置。</li></ul><h5 id="逐点式的前馈神经网络"><a href="#逐点式的前馈神经网络" class="headerlink" title="逐点式的前馈神经网络"></a>逐点式的前馈神经网络</h5><p>这部分包括两个线性转换，中间有一个ReLU激活函数。计算公式是<br>$$<br>\mathrm{FFN}(x)&#x3D;\max \left(0, x W_{1}+b_{1}\right) W_{2}+b_{2}<br>$$</p><h5 id="Embedding-and-Softmax"><a href="#Embedding-and-Softmax" class="headerlink" title="Embedding and Softmax"></a>Embedding and Softmax</h5><p>与其他序列转换模型类似，使用学习到的嵌入将输入符号和输出符号转换为$d_{model}$维的向量。也使用通常学习到的线性变换和Softmax函数将解码器的输出转换为预测的下一个符号的概率。</p><h5 id="位置编码"><a href="#位置编码" class="headerlink" title="位置编码"></a>位置编码</h5><p>由于本模型不包含循环和卷积，为了让模型利用序列的顺序，必须注入一些关于序列中符号的相对或绝对位置的信息。因此，在编码器和解码器堆栈底部的输入嵌入中添加了“位置编码”。位置编码与嵌入具有相同的$d_{model}$维数，因此可以将两者相加。在本文中，使用了不同频率的正弦和余弦函数，如公式所示<br>$$<br>\begin{aligned}<br>P E_{(p o s, 2 i)} &amp;&#x3D;\sin \left(p o s &#x2F; 10000^{2 i &#x2F; d_{\text {model }}}\right) \<br>P E_{(p o s, 2 i+1)} &amp;&#x3D;\cos \left(\text { pos } &#x2F; 10000^{2 i &#x2F; d_{\text {model }}}\right)<br>\end{aligned}<br>$$<br>其中，$pos$是位置，$i$是维数。也就是说，位置编码的每一维对应一个正弦信号。</p><h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><p>在这项工作中，提出了Transformer，这是第一个完全基于注意力机制的序列转换模型，用多头自注意力取代了编码器-解码器结构中最常用的循环层。对于翻译任务，Transformer的训练速度比基于循环层或卷积层的架构要快得多。</p><h4 id="更多资料"><a href="#更多资料" class="headerlink" title="更多资料"></a>更多资料</h4><ol><li>图解Transformer（完整版）<a href="https://mp.weixin.qq.com/s/cJqhESxTMy5cfj0EXh9s4w">https://mp.weixin.qq.com/s/cJqhESxTMy5cfj0EXh9s4w</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>论文阅读</category>
      
    </categories>
    
    
    <tags>
      
      <tag>注意力</tag>
      
      <tag>Transformer</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>机器学习中的数学（一）</title>
    <link href="/posts/9ff4b4d5/"/>
    <url>/posts/9ff4b4d5/</url>
    
    <content type="html"><![CDATA[<p>理清机器学习中的数学概念和相关基础知识，对于理解机器学习算法的原理以及改进算法至关重要。因此本系列笔记打算针对《Mathematics for machine learning》一书，进行学习笔记整理，希望提升自己的同时，能帮助他人一起成长。</p><span id="more"></span><h3 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h3><ul><li><a href="">Part I Mathematical Foundations</a><ul><li><a href="">1. Introduction and Motivation</a></li><li><a href="">2. Linear Algebra</a></li><li><a href="">3. Analytic Geometry</a></li><li><a href="">4. Matrix Decompositions</a></li><li><a href="">5. Vector Calculus</a></li><li><a href="">6. Probability and Distributions</a></li><li><a href="">7. Continuous Optimization</a></li></ul></li><li><a href="">Part II When Models Meet Data</a><ul><li><a href="">8. When Models Meet Data</a></li><li><a href="">9. Linear Regression</a></li><li><a href="">10. Dimensionality Reduction with Principal Component Analysis</a></li><li><a href="">11. Density Estimation with Gaussian Mixture Models</a></li><li><a href="">12. Classification with Support Vector Machines</a></li></ul></li></ul><h3 id="第一部分-数学基础"><a href="#第一部分-数学基础" class="headerlink" title="第一部分 数学基础"></a>第一部分 数学基础</h3><h4 id="1-简介和动机"><a href="#1-简介和动机" class="headerlink" title="1. 简介和动机"></a>1. 简介和动机</h4><h5 id="1-1-基本概念"><a href="#1-1-基本概念" class="headerlink" title="1.1 基本概念"></a>1.1 基本概念</h5><p>机器学习是通过设计算法来自动地从数据中提取有价值的信息。由于机器学习是一类数据驱动的方法，所以数据是机器学习的核心。机器学习涉及到三个重要的组成核心：数据、模型和学习。</p><p>那么对于数据、模型和学习这三个重要的概念，本书有三个重要的观点：</p><ul><li>将数据看作向量；</li><li>要么使用概率的，要么使用优化的视角来选择合适模型；</li><li>使用数值优化方法从可获得的数据中学习，使得模型能够在没有见过的数据集上表现良好。</li></ul><h5 id="1-2-阅读本书的两种方式"><a href="#1-2-阅读本书的两种方式" class="headerlink" title="1.2 阅读本书的两种方式"></a>1.2 阅读本书的两种方式</h5><ul><li>自底向上：由浅入深，从基本的概念开始，学习到更先进的；</li><li>自顶向下：从实际需求出发，去学习一些基本的概念，这是一种任务驱动的方式。</li></ul><p>这种书分为了两个部分，第一部分是数学基础部分，第二部分是机器学习任务及方法。可以根据自己的实际需求，选择阅读方法，我推荐自底向上的方式，当然也可以两种方式结合。</p><p>接下来介绍数学基础部分和机器学习四大支柱（常见任务）的关系，如图所示：<br><img src="https://i.loli.net/2020/09/27/qKN3VwrYuUGFRLx.png" alt="mml.jpg"></p><h5 id="1-3-练习与反馈"><a href="#1-3-练习与反馈" class="headerlink" title="1.3 练习与反馈"></a>1.3 练习与反馈</h5><p>这本书可以从<a href="https://mml-book.com这个网站下载.第一部分主要适用笔和纸完成练习,第二部分提供有编程的代码用于加深机器学习算法的理解./">https://mml-book.com这个网站下载。第一部分主要适用笔和纸完成练习，第二部分提供有编程的代码用于加深机器学习算法的理解。</a></p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>机器学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Ubuntu 16.04将cuda 10.1降到cuda10.0</title>
    <link href="/posts/8517e2d2/"/>
    <url>/posts/8517e2d2/</url>
    
    <content type="html"><![CDATA[<p>最近因为跑程序，需要用到cuda的版本为10.0，但是机器的cuda版本为10.1，所以就将其版本进行了降低。</p><span id="more"></span><h5 id="卸载cuda-10-1"><a href="#卸载cuda-10-1" class="headerlink" title="卸载cuda 10.1"></a>卸载cuda 10.1</h5><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs awk">sudo <span class="hljs-regexp">/usr/</span>local<span class="hljs-regexp">/cuda-10.1/</span>bin/uninstall_cuda_10.<span class="hljs-number">1</span>.pl<br>sudo apt --purge remove nvidia*<br></code></pre></td></tr></table></figure><h5 id="下载cuda和cudnn"><a href="#下载cuda和cudnn" class="headerlink" title="下载cuda和cudnn"></a>下载cuda和cudnn</h5><p>在官网下载cuda10.0和cudnn7.3.1，两者的版本一定要匹配。<br>cuda和cudnn匹配列表：<br><a href="https://developer.nvidia.com/rdp/cudnn-archive#a-collapse731-10">https://developer.nvidia.com/rdp/cudnn-archive#a-collapse731-10</a></p><p>cuda10.0下载地址（选择runfile的文件下载，安装比较方便）：<br><a href="https://developer.nvidia.com/cuda-10.0-download-archive?target_os=Linux&target_arch=x86_64&target_distro=Ubuntu&target_version=1604&target_type=runfilelocal">https://developer.nvidia.com/cuda-10.0-download-archive?target_os&#x3D;Linux&amp;target_arch&#x3D;x86_64&amp;target_distro&#x3D;Ubuntu&amp;target_version&#x3D;1604&amp;target_type&#x3D;runfilelocal</a></p><p>cudnn7.3.1下载地址：<br><a href="https://developer.nvidia.com/compute/machine-learning/cudnn/secure/v7.3.1/prod/10.0_2018927/cudnn-10.0-linux-x64-v7.3.1.20">https://developer.nvidia.com/compute/machine-learning/cudnn/secure/v7.3.1/prod/10.0_2018927&#x2F;cudnn-10.0-linux-x64-v7.3.1.20</a></p><h5 id="安装cuda"><a href="#安装cuda" class="headerlink" title="安装cuda"></a>安装cuda</h5><p><strong>1. 禁用nouveau driver</strong></p><figure class="highlight 1c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs 1c">lsmod <span class="hljs-string">| grep nouveau</span><br></code></pre></td></tr></table></figure><p>如果没有结果输出，则代表禁用掉了。如果有内容输出，则代表没有禁用掉。需要执行如下操作，</p><p>1）在&#x2F;etc&#x2F;modprobe.d中创建文件blacklist-nouveau.conf,</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> /etc/modprobe.d<br>sudo <span class="hljs-built_in">touch</span> blacklist-nouveau.conf<br></code></pre></td></tr></table></figure><p>2）在文件blacklist-nouveau.conf中输入如下内容，</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">blacklist</span> nouveau<br><span class="hljs-attribute">options</span> nouveau modeset=<span class="hljs-number">0</span><br></code></pre></td></tr></table></figure><p>保存并退出后，执行如下命令，</p><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs ebnf"><span class="hljs-attribute">sudo update-initramfs -u</span><br></code></pre></td></tr></table></figure><p>3）执行命令<code>lsmod | grep nouveau</code> 检查是否禁用成功。</p><p><strong>2. 进入文本模式</strong><br>按Ctrl+Alt+F1，进入文本模式，执行如下命令，关闭图形界面，</p><figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs arduino">sudo service lightdm stop<br></code></pre></td></tr></table></figure><p>然后进入cuda的安装包所在文件夹，执行如下命令：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">sudo</span> sh cuda_10.<span class="hljs-number">0</span>.<span class="hljs-number">130</span>_410.<span class="hljs-number">48</span>_linux.run<br></code></pre></td></tr></table></figure><p>输入上述命令后，会显示用户许可证信息，按空格键直到显示为100%，然后输入accept。</p><p>在这个过程中，会遇到如下选项，NVIDIA Accelerated Graphics Driver: 选择n;<br>openGL（有时不会出现）: 选择n;<br>其他：都选择y；<br>安装路径可以选择默认：直接回车。</p><p>接着，输入命令<code>sudo service lightdm start</code>, 启动图形化界面，按住Alt+Ctrl+F7,返回图形化登录界面，输入账号密码后登录。 或者输入命令<code>sudo reboot</code>，重启回到图形界面。</p><p><strong>3. 环境配置</strong><br>输入如下命令，打开&#x2F;etc&#x2F;profile文件，</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk">vim <span class="hljs-regexp">/etc/</span>profile<br></code></pre></td></tr></table></figure><p>在文件中输入如下内容，</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs awk">export PATH=<span class="hljs-regexp">/usr/</span>local<span class="hljs-regexp">/cuda-10.0/</span>bin<br>export LD_LIBRARY_PATH=<span class="hljs-regexp">/usr/</span>local<span class="hljs-regexp">/cuda-10.0/</span>lib64<br></code></pre></td></tr></table></figure><p>然后，保存并退出文件。接着，执行如下命令，使配置生效，</p><figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs gradle"><span class="hljs-keyword">source</span> <span class="hljs-regexp">/etc/</span>profile<br></code></pre></td></tr></table></figure><p><strong>4. 检查cuda是否安装成功</strong><br>输入如下命令，查看nvidia驱动的版本：</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk">cat <span class="hljs-regexp">/proc/</span>driver<span class="hljs-regexp">/nvidia/</span>version<br></code></pre></td></tr></table></figure><p>我的版本为410.48。<br>输入如下命令，查看CUDA Toolkit的版本：</p><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs ebnf"><span class="hljs-attribute">nvcc -V</span><br></code></pre></td></tr></table></figure><p>我的版本是V10.0.130。<br>至此，cuda安装成功，接下来安装cudnn。</p><h5 id="安装cudnn"><a href="#安装cudnn" class="headerlink" title="安装cudnn"></a>安装cudnn</h5><p><strong>1. 解压cudnn安装包</strong></p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">tar</span> -xvf cudnn-<span class="hljs-number">10</span>.<span class="hljs-number">0</span>-linux-x64-v<span class="hljs-number">7.3.1.20</span>.tgz<br></code></pre></td></tr></table></figure><p><strong>2. 配置cudnn</strong><br>在当前目录输入依次执行如下命令，</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs awk">sudo cp cuda<span class="hljs-regexp">/include/</span>cudnn.h <span class="hljs-regexp">/usr/</span>local<span class="hljs-regexp">/cuda/i</span>nclude/<br>sudo cp cuda<span class="hljs-regexp">/lib64/</span>libcudnn* <span class="hljs-regexp">/usr/</span>local<span class="hljs-regexp">/cuda/</span>lib64/<br>sudo chmod a+r <span class="hljs-regexp">/usr/</span>local<span class="hljs-regexp">/cuda/i</span>nclude/cudnn.h<br>sudo chmod a+r <span class="hljs-regexp">/usr/</span>local<span class="hljs-regexp">/cuda/</span>lib64/libcudnn*<br></code></pre></td></tr></table></figure><p><strong>3. 查看cudnn版本</strong><br>输入如下命令，查看版本，</p><figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs gradle">cat <span class="hljs-regexp">/usr/</span>local<span class="hljs-regexp">/cuda/i</span>nclude/cudnn.h | <span class="hljs-keyword">grep</span> CUDNN_MAJOR -A <span class="hljs-number">2</span><br></code></pre></td></tr></table></figure><p>如果有对应的CUDNN_MAJOR输出，则代表安装成功。</p><h5 id="检查cuda和cudnn是否都安装成功"><a href="#检查cuda和cudnn是否都安装成功" class="headerlink" title="检查cuda和cudnn是否都安装成功"></a>检查cuda和cudnn是否都安装成功</h5><p>输入如下命令，</p><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs ebnf"><span class="hljs-attribute">modprobe nvidia</span><br><span class="hljs-attribute">nvidia-smi</span><br></code></pre></td></tr></table></figure><p>如果出现GPU的信息列表，则说明安装成功。</p><h5 id="常见错误"><a href="#常见错误" class="headerlink" title="常见错误"></a>常见错误</h5><ol><li>如果出现无法进入Ubuntu系统，输入如下命令，清除安装的驱动，<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs routeros">sudo apt-<span class="hljs-built_in">get</span> purge nvidia*<br></code></pre></td></tr></table></figure>然后再输入命令<code>sudo reboot</code>重启，如果问题依然没有解决，按照上述步骤，重新安装cuda。</li></ol><h5 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h5><ol><li><a href="https://www.pythonf.cn/read/110763">https://www.pythonf.cn/read/110763</a></li><li><a href="https://www.jianshu.com/p/89f1ab962d75">https://www.jianshu.com/p/89f1ab962d75</a></li><li><a href="https://blog.csdn.net/weixin_42279044/article/details/83181686">https://blog.csdn.net/weixin_42279044/article/details/83181686</a></li><li><a href="https://blog.csdn.net/lihe4151021/article/details/90237681">https://blog.csdn.net/lihe4151021/article/details/90237681</a></li><li><a href="https://blog.csdn.net/qq_45049586/article/details/104582468">https://blog.csdn.net/qq_45049586/article/details/104582468</a></li><li><a href="https://blog.csdn.net/qq_41915226/article/details/103051602">https://blog.csdn.net/qq_41915226/article/details/103051602</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>经验技巧</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CUDA</tag>
      
      <tag>GPU</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【论文笔记-3】用于交通预测的多范围注意力双组分图卷积网络</title>
    <link href="/posts/e8cb7573/"/>
    <url>/posts/e8cb7573/</url>
    
    <content type="html"><![CDATA[<p>Chen, Weiqi, Ling Chen, Yu Xie, Wei Cao, Yusong Gao, and Xiaojie Feng. “<a href="https://arxiv.org/pdf/1911.12093">Multi-Range Attentive Bicomponent Graph Convolutional Network for Traffic Forecasting</a>.” arXiv preprint arXiv:1911.12093 (2019). Accepted by AAAI2020.</p><span id="more"></span><p>提出了一种交通预测深度学习模型——多范围注意力双组分图卷积网络(MRA-BGCN)。该模型首先根据路网距离构建节点向图，根据不同的边相互模式构建边向图。然后利用双组分图卷积实现了节点和边的相互作用建模。此外引入多范围注意力机制，对不同邻域范围内的信息进行聚合，自动学习不同范围的重要性。在两个交通数据集（METR-LA和PEMS-BAY）上的实验结果表明取得了很好的效果。</p><h4 id="问题定义"><a href="#问题定义" class="headerlink" title="问题定义"></a>问题定义</h4><p><img src="https://i.loli.net/2020/06/14/QH5ysCw64l38ExS.png" alt="2338_1.png"></p><p>交通预测问题的任务是：学习一个函数$f$, 能够给出$T^{\prime}$历史的图信号和图$G$，预测$T$未来的图信号。</p><h4 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h4><p><img src="https://i.loli.net/2020/06/14/j6E2md7kYRh8v3A.png" alt="2339_1.png"></p><p>METR-LA and PEMS-BAY是两个公开的交通网络数据集。METR-LA记录了从2012年3月1日到2012年6月30日四个月的交通速度统计数据，包括洛杉矶公路上的207个传感器。PEMS-BAY记录了从2017年1月1日到2017年5月31日的5个月的交通速度统计数据，其中包括旧金山湾区的325个传感器。</p><h4 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h4><p><img src="https://i.loli.net/2020/06/14/A3yE9oUKbCZGsRp.png" alt="2337_1.png"></p><p>论文中的模型如上图所示，包括2部分，（1）双组分图卷积模块 （2）多范围注意力层。</p><h5 id="双组分图卷积"><a href="#双组分图卷积" class="headerlink" title="双组分图卷积"></a>双组分图卷积</h5><p><img src="https://i.loli.net/2020/06/14/S9vIA3t8C7ngRXk.png" alt="2340_1.png"></p><p>图卷积是对给定图结构的节点间相互作用进行建模的一种有效操作。双组分图卷积可以显式地对节点和边的相互作用进行建模。</p><h6 id="流连接"><a href="#流连接" class="headerlink" title="流连接"></a>流连接</h6><p>在交通网络中，一个路段可能受到其上下游路段的影响。</p><h6 id="竞争关系"><a href="#竞争关系" class="headerlink" title="竞争关系"></a>竞争关系</h6><p>共享同一源节点的道路链路可能会争夺交通资源，产生竞争关系。</p><h5 id="多范围注意力"><a href="#多范围注意力" class="headerlink" title="多范围注意力"></a>多范围注意力</h5><p>提出了双组分图卷积的多范围注意力机制，能自动学习不同邻域范围的重要性，从而实现对不同邻域范围内信息的聚集，而不仅仅是给定的邻域范围。</p><h5 id="双组分图卷积RNN"><a href="#双组分图卷积RNN" class="headerlink" title="双组分图卷积RNN"></a>双组分图卷积RNN</h5><p><img src="https://i.loli.net/2020/06/14/NR6qQJAofOwHpPK.png" alt="2343_1.png"></p><p>将多个BGCGRU层堆叠起来，并使用Sequence to Sequence体系结构进行多步前向交通预测。</p><h4 id="评估"><a href="#评估" class="headerlink" title="评估"></a>评估</h4><ul><li>性能比较<br><img src="https://i.loli.net/2020/06/14/yZXAJwsHdM7niQ8.png" alt="2342_1.png"></li><li>边向图的影响<br><img src="https://i.loli.net/2020/06/14/NGrHvd23eYkqgpM.png" alt="2341_1.png"></li><li>多范围注意力机制的影响<br><img src="https://i.loli.net/2020/06/14/9QkNBjcV8fMJsyv.png" alt="2344_1.png"></li></ul><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>提出了一种用于交通预测的多范围注意力双组分图卷积网络。具体来说，采用双组分图卷积来明确地建模节点和边的相关性，利用一种边向图构造方法来编码边的上下游连通性和竞争关系，使用多范围注意力机制，有效地聚合多个邻域范围信息，生成综合的表示。可以进一步研究的地方是，可以考虑更多的影响因素，比如交通事故以及周围的兴趣点；目前论文中考虑的是单模态输入图，还可以研究多模态输入图。</p>]]></content>
    
    
    <categories>
      
      <category>论文阅读</category>
      
    </categories>
    
    
    <tags>
      
      <tag>交通预测</tag>
      
      <tag>图神经网络</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>常用linux命令</title>
    <link href="/posts/4206c037/"/>
    <url>/posts/4206c037/</url>
    
    <content type="html"><![CDATA[<p>下列命令在Ubuntu16.04 LTS 系统下测试通过。</p><span id="more"></span><h5 id="查看内存"><a href="#查看内存" class="headerlink" title="查看内存"></a>查看内存</h5><p>free<br>参数：<br>-help: 查看free命令的帮助内容<br>-h 以人类可读的直观方式<br>-b －k －m：分别以Byte、KB、MB为单位显示内存使用情况<br>-t：显示内存总和列</p><h5 id="查看CPU"><a href="#查看CPU" class="headerlink" title="查看CPU"></a>查看CPU</h5><p>lscpu<br>查看当前操作系统内核信息  uname -a<br>查看当前操作系统发行版信息  cat &#x2F;etc&#x2F;issue<br>查看物理cpu颗数  cat &#x2F;proc&#x2F;cpuinfo | grep physical | uniq -c<br>查看完整CPU信息  cat &#x2F;proc&#x2F;cpuinfo</p><h5 id="查看GPU"><a href="#查看GPU" class="headerlink" title="查看GPU"></a>查看GPU</h5><p>nvidia-smi<br>查看显卡信息 lspci | grep -i nvidia<br>周期性的输出显卡的使用情况 watch -n 10 nvidia-smi</p><h5 id="查看硬盘大小"><a href="#查看硬盘大小" class="headerlink" title="查看硬盘大小"></a>查看硬盘大小</h5><p>df -h</p><h5 id="创建用户"><a href="#创建用户" class="headerlink" title="创建用户"></a>创建用户</h5><p>sudo useradd -d &#x2F;usr&#x2F;sam -m sam 创建一个名为sam的用户</p><h5 id="删除用户"><a href="#删除用户" class="headerlink" title="删除用户"></a>删除用户</h5><p>sudo userdel -r sam  其中，-r的作用是把该用户的主目录一起删除</p><h5 id="将用户加入组"><a href="#将用户加入组" class="headerlink" title="将用户加入组"></a>将用户加入组</h5><p>sudo usermod -G xiep sam 将用户sam加入xiep组</p><h5 id="查看当前登录用户名"><a href="#查看当前登录用户名" class="headerlink" title="查看当前登录用户名"></a>查看当前登录用户名</h5><p>whoami</p><h5 id="查看当前用户所在组"><a href="#查看当前用户所在组" class="headerlink" title="查看当前用户所在组"></a>查看当前用户所在组</h5><p>groups sam</p><h5 id="查看系统用户"><a href="#查看系统用户" class="headerlink" title="查看系统用户"></a>查看系统用户</h5><p>cat &#x2F;etc&#x2F;passwd</p><h5 id="查看系统用户分组"><a href="#查看系统用户分组" class="headerlink" title="查看系统用户分组"></a>查看系统用户分组</h5><p>cat &#x2F;etc&#x2F;group</p>]]></content>
    
    
    <categories>
      
      <category>经验技巧</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Linux</tag>
      
      <tag>Ubuntu</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>hexo博客搭建及多电脑同步</title>
    <link href="/posts/53375297/"/>
    <url>/posts/53375297/</url>
    
    <content type="html"><![CDATA[<p>之前写了一篇用hexo+github搭建博客的教程，大致流程为：本地博客搭建，将博客部署到github，配置域名访问。详细可参考我的博客（<a href="https://www.jianshu.com/p/058d4054bc3f">Hexo搭建个人博客教程</a>）。最近因为遇到在实验室写好博客，但是想在寝室发布博客，所以涉及到多电脑同步的问题，现将解决方案记录如下。</p><span id="more"></span><h5 id="方案一"><a href="#方案一" class="headerlink" title="方案一"></a>方案一</h5><p>用百度云或onedrive一类的云盘备份hexo文件夹。这种方法方便快捷，但是仅仅可以用作博客备份，不方便用于同步更新博客，每次更改博客后都要等待云盘同步，才能继续完成接下来的发布步骤。</p><h5 id="方案二"><a href="#方案二" class="headerlink" title="方案二"></a>方案二</h5><p>利用coding.net存放hexo博客源文件，github存放hexo博客的网页静态文件。这种方案可以实现多电脑同步。</p><h6 id="实验室电脑"><a href="#实验室电脑" class="headerlink" title="实验室电脑"></a>实验室电脑</h6><ol><li>注册coding账号（<a href="https://coding.net/login">注册</a>），新建项目hexo_blog（设置成不公开），存放博客源文件。</li><li>关联远程库并推送到hexo_blog。<figure class="highlight armasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs armasm"><span class="hljs-symbol">git</span> remote <span class="hljs-keyword">add</span> origin https:<span class="hljs-comment">//git.coding.net/xiepeng21/hexo_blog.git</span><br><span class="hljs-symbol">git</span> <span class="hljs-keyword">add</span> .<br><span class="hljs-symbol">git</span> commit -m <span class="hljs-string">&quot;backup_v1&quot;</span><br><span class="hljs-symbol">git</span> <span class="hljs-keyword">push</span> -u origin master<br></code></pre></td></tr></table></figure></li></ol><h6 id="寝室电脑"><a href="#寝室电脑" class="headerlink" title="寝室电脑"></a>寝室电脑</h6><ol><li><p>安装好nodejs,git,hexo，具体操作，不再赘述，可参考文首的博客(<a href="https://www.jianshu.com/p/058d4054bc3f">Hexo搭建个人博客教程</a>)。</p></li><li><p>将存放在远程的hexo_blog克隆到本地</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk">git clone https:<span class="hljs-regexp">//gi</span>t.coding.net<span class="hljs-regexp">/xiepeng21/</span>hexo_blog.git<br></code></pre></td></tr></table></figure></li><li><p>安装博客依赖的包(读取的是package.json的配置)</p><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cmake">npm <span class="hljs-keyword">install</span><br></code></pre></td></tr></table></figure></li><li><p>接下来就可以在这台电脑上发布博客了。</p></li></ol><p>注：如果遇到其他问题，可以按照搭建博客的流程分析问题解决办法（<a href="https://www.jianshu.com/p/058d4054bc3f">Hexo搭建个人博客教程</a>）。</p><h5 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h5><ol><li><a href="http://chenfengkg.cn/personal-blog-build/">http://chenfengkg.cn/personal-blog-build/</a> 博客一之博客搭建</li><li><a href="https://godweiyang.com/2018/04/13/hexo-blog/">https://godweiyang.com/2018/04/13/hexo-blog/</a> 超详细Hexo+Github博客搭建小白教程</li><li><a href="https://www.zybuluo.com/mdeditor">https://www.zybuluo.com/mdeditor</a> 作业部落（在线markdown编辑）</li></ol>]]></content>
    
    
    <categories>
      
      <category>经验技巧</category>
      
    </categories>
    
    
    <tags>
      
      <tag>博客</tag>
      
      <tag>Hexo</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>红楼梦书评</title>
    <link href="/posts/637f259f/"/>
    <url>/posts/637f259f/</url>
    
    <content type="html"><![CDATA[<p>昨天看完了《红楼梦》一书，还记得是从去年暑假开始看，差不多花了半年时间。因为之前身边有同学看，加之暑假打算看一看书，之前也没有看过，只零星看过红楼梦的电视剧，所以就选择了《红楼梦》。</p><span id="more"></span><p><img src="https://i.loli.net/2019/01/03/5c2e2d1619a35.jpg" alt="s1070959.jpg"></p><p>在这本书里，见证了大量的诗词、中医养生的内容以及人物言谈对话，感受到了荣、宁二府由兴到衰再到“兴”的过程，还有贾宝玉、林黛玉、薛宝钗、老太太以及王熙凤等人生命历程。<br /><br>其中，给我印象最深的是薛宝钗，她不仅担负起薛家的家庭重担，也要承受着贾宝玉无心功名、沉迷闺阁的反传统压力。而她自己却是旧传统下的知书达理、贤良之妻。这个世界给了她不公，但她却从容应对，不刻薄他人，维持着家庭的和睦，不失高贵和优雅。<br /><br>总的来说，这本书，包含的内容及其丰富，从日常生活到社会万象，囊括万千，值得一读，甚至多读。<br /><br><strong>注:</strong> 这本书，我看的是Kindle电子书版本（《红楼梦》（古典名著普及文库）），在当当上搜索了一下，红楼梦有不同版本，推荐人民文学出版社的《红楼梦》。</p>]]></content>
    
    
    <categories>
      
      <category>随笔感悟</category>
      
    </categories>
    
    
    <tags>
      
      <tag>书籍</tag>
      
      <tag>阅读</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>2019年书单</title>
    <link href="/posts/353b91f9/"/>
    <url>/posts/353b91f9/</url>
    
    <content type="html"><![CDATA[<p>新的一年，保持阅读和写作的习惯，每一个月读完一本书写一篇读书笔记(简称三一计划)。</p><span id="more"></span><p><img src="https://i.loli.net/2019/01/02/5c2cce1e92717.jpg" alt="booklist.jpg"></p><p>今年准备阅读的12本书如下:</p><ol><li>易经</li><li>理想国</li><li>自然哲学的数学原理</li><li>红楼梦</li><li>瓦尔登湖</li><li>科学与方法</li><li>科学史</li><li>小王子</li><li>西方哲学史</li><li>中国哲学简史</li><li>从一到无穷大</li><li>美的历程</li></ol>]]></content>
    
    
    <categories>
      
      <category>随笔感悟</category>
      
    </categories>
    
    
    <tags>
      
      <tag>书籍</tag>
      
      <tag>阅读</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【论文笔记-2】深度学习</title>
    <link href="/posts/c0d0024f/"/>
    <url>/posts/c0d0024f/</url>
    
    <content type="html"><![CDATA[<p>这篇文章是关于深度学习的一篇综述文章。是由深度学习界的三位大牛（YannLeCun, Yoshua Bengio, Geoffrey Hinton）所写。在本文中，介绍了反向传播算法、卷积神经网络与循环神经网络的经典应用，给出了细致的图解和深入的分析，是深度学习中的高质量的重要文献。文中还提到了深度学习未来的发展，比如将卷积神经网络、循环神经网络与强化学习结合起来；将表示学习与复杂推理结合起来。</p><span id="more"></span><h5 id="多层神经网络及反向传播"><a href="#多层神经网络及反向传播" class="headerlink" title="多层神经网络及反向传播"></a>多层神经网络及反向传播</h5><p><img src="https://i.loli.net/2018/12/26/5c239d8290693.jpg" alt="19-24-17.jpg"></p><h5 id="给图片加描述文字"><a href="#给图片加描述文字" class="headerlink" title="给图片加描述文字"></a>给图片加描述文字</h5><ul><li><a href="https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Vinyals_Show_and_Tell_2015_CVPR_paper.pdf">Show and Tell: A Neural Image Caption Generator</a>;</li><li><a href="http://proceedings.mlr.press/v37/xuc15.pdf">Show, attend and tell: Neural image caption generation with visual attention</a></li></ul><p><img src="https://i.loli.net/2018/12/26/5c239e4ca2174.jpg" alt="19-26-01.jpg"></p><h5 id="循环神经网络单元"><a href="#循环神经网络单元" class="headerlink" title="循环神经网络单元"></a>循环神经网络单元</h5><p><img src="https://i.loli.net/2018/12/26/5c239ea287cfa.jpg" alt="19-27-35.jpg"></p><h5 id="论文链接"><a href="#论文链接" class="headerlink" title="论文链接"></a>论文链接</h5><p><a href="https://creativecoding.soe.ucsc.edu/courses/cs523/slides/week3/DeepLearning_LeCun.pdf">LeCun Y, Bengio Y, Hinton G. Deep learning[J]. nature, 2015, 521(7553): 436.</a></p>]]></content>
    
    
    <categories>
      
      <category>论文阅读</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【论文笔记-1】注意力人流量机器</title>
    <link href="/posts/a7c2a378/"/>
    <url>/posts/a7c2a378/</url>
    
    <content type="html"><![CDATA[<p>文章提出了一种称为注意力人流量机器（Attentive Crowd Flow Machines）的神经网络模型，该模型能够通过带注意力机制的时变数据动态表示来推断城市人流量的演变。它由两层ConvLSTM单元以及用于空间权重预测的卷积层组成。文章的创新点在于：1.引入了注意力机制 2.权重时变的融合方法。</p><span id="more"></span><p><img src="https://i.loli.net/2018/12/26/5c23a1622ae38.png" alt="Image.png"></p><h5 id="论文链接"><a href="#论文链接" class="headerlink" title="论文链接"></a>论文链接</h5><p><a href="http://www.linliang.net/wp-content/uploads/2018/10/ACMMM2018_FlowMachines.pdf">Liu L, Zhang R, Peng J, et al. Attentive Crowd Flow Machines[C]&#x2F;&#x2F;2018 ACM Multimedia Conference on Multimedia Conference. ACM, 2018: 1553-1561.</a></p>]]></content>
    
    
    <categories>
      
      <category>论文阅读</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CNN</tag>
      
      <tag>LSTM</tag>
      
      <tag>Crowd Flow Prediction</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>如何计算经过CNN（卷积神经网络）卷积后的图片大小</title>
    <link href="/posts/fb776320/"/>
    <url>/posts/fb776320/</url>
    
    <content type="html"><![CDATA[<p>对于给定的一张图片，如下图，32×32大小的输入图片经过一次卷积之后，如何得到28×28的feature maps?</p><span id="more"></span><p><img src="https://i.loli.net/2018/12/23/5c1fac8bbfa94.png" alt="Screenshot_2018-09-29-15-31-03-61.png"></p><p>设卷积前的图像大小为n×n, 过滤器大小为f×f, padding(填充)为p, stride(步长)为 s, 则卷积后的图像 m×m 大小为：<br>m &#x3D; (n+2p-f)&#x2F;s + 1.（如果商不为整数，向下取整）</p><p>(32+0-5)&#x2F;1 + 1 &#x3D; 28. 所以上图中的输入图片经过一次卷积之后，得到了28×28的feature maps.</p>]]></content>
    
    
    <categories>
      
      <category>机器学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>CNN</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>L1、L2正则化</title>
    <link href="/posts/a02b6105/"/>
    <url>/posts/a02b6105/</url>
    
    <content type="html"><![CDATA[<h5 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h5><p>在之前的博客里介绍了<a href="http://xiepeng21.cn/%E3%80%90%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%91%E9%98%B2%E6%AD%A2%E8%BF%87%E6%8B%9F%E5%90%88%E7%9A%84%E6%96%B9%E6%B3%95.html">常见的防止过拟合的方法</a>,这次主要就其中的L1、L2正则化方法进行介绍并比较它们的不同。</p><span id="more"></span><p>我们使用L1、L2正则化方法的目的，在于减缓机器学习中的过拟合现象。</p><p>为什么它们能减缓过拟合现象呢，由于正则项的加入，使得权重矩阵的值减小，因为它假定一个拥有更小权重矩阵的神经网络将产生更简单的模型，进而在一定程度上能减缓过拟合。</p><p>在L1和L2中，所采用的正则化项是不同的。</p><p>在L2中，其中λ是正则化参数，这个超参数可以通过优化得到更好的结果。同时L2正则化也被称为权重衰减（weight decay），因为它使权重衰减至0（但不等于0）。</p><p><img src="https://i.loli.net/2018/11/07/5be2dc708e5c7.png" alt="1.png"></p><p>在L1中，我们惩罚权重的绝对值，这里权重可能会减至0。因此，当我们尝试压缩我们的模型时，使用L1十分有用。在其他方面，我们更倾向于使用L2。</p><p><img src="https://i.loli.net/2018/11/07/5be2ddd4db9af.png" alt="2.png"></p><h5 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h5><ol><li><a href="http://xiepeng21.cn/%E3%80%90%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%91%E9%98%B2%E6%AD%A2%E8%BF%87%E6%8B%9F%E5%90%88%E7%9A%84%E6%96%B9%E6%B3%95.html">http://xiepeng21.cn/%E3%80%90%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%91%E9%98%B2%E6%AD%A2%E8%BF%87%E6%8B%9F%E5%90%88%E7%9A%84%E6%96%B9%E6%B3%95.html</a> 【机器学习】防止过拟合的方法</li><li><a href="https://www.analyticsvidhya.com/blog/2018/04/fundamentals-deep-learning-regularization-techniques/">https://www.analyticsvidhya.com/blog/2018/04/fundamentals-deep-learning-regularization-techniques/</a> An Overview of Regularization Techniques in Deep Learning (with Python code)</li></ol>]]></content>
    
    
    <categories>
      
      <category>机器学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>机器学习</tag>
      
      <tag>正则化</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Longest Substring Without Repeating Characters</title>
    <link href="/posts/8e8877f3/"/>
    <url>/posts/8e8877f3/</url>
    
    <content type="html"><![CDATA[<h5 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h5><p>Given a string, find the length of the longest substring without repeating characters.</p><span id="more"></span><h5 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h5><ul><li>Example 1:</li></ul><p>Input: “abcabcbb”<br>Output: 3<br>Explanation: The answer is “abc”, with the length of 3. </p><ul><li>Example 2:</li></ul><p>Input: “bbbbb”<br>Output: 1<br>Explanation: The answer is “b”, with the length of 1.</p><ul><li>Example 3:</li></ul><p>Input: “pwwkew”<br>Output: 3<br>Explanation: The answer is “wke”, with the length of 3.<br>             Note that the answer must be a substring, “pwke” is a subsequence and not a substring. </p><h5 id="算法思路"><a href="#算法思路" class="headerlink" title="算法思路"></a>算法思路</h5><p>该问题可以简化成查找一个字符串中最长的不重复字符子串，返回子串的长度。第一种方法用到了枚举和字典，感觉有点绕，我没有理解清楚；第二种方法采用了字符串的split方法，很巧妙，不过比较难想到。两种方法相比，第二种方法运行时间更短（84ms &lt; 88ms）,推荐使用第二种方法，感兴趣的朋友可以研究下第一种方法。</p><p>方法一：</p><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs vim">class Solution(object):<br>    def lengthOfLongestSubstring(self, s):<br>        dic, <span class="hljs-keyword">res</span>, start, = &#123;&#125;, <span class="hljs-number">0</span>, <span class="hljs-number">0</span><br>        <span class="hljs-keyword">for</span> i, ch in enumerate(s):<br>            # when char already in dictionary<br>            <span class="hljs-keyword">if</span> ch in dic:<br>                # check length from start of <span class="hljs-built_in">string</span> <span class="hljs-keyword">to</span> <span class="hljs-built_in">index</span><br>                <span class="hljs-keyword">res</span> = <span class="hljs-built_in">max</span>(<span class="hljs-keyword">res</span>, i-start)<br>                # <span class="hljs-keyword">update</span> start of <span class="hljs-built_in">string</span> <span class="hljs-built_in">index</span> <span class="hljs-keyword">to</span> the <span class="hljs-keyword">next</span> <span class="hljs-built_in">index</span><br>                start = <span class="hljs-built_in">max</span>(start, dic[ch]+<span class="hljs-number">1</span>)<br>            # <span class="hljs-built_in">add</span>/<span class="hljs-keyword">update</span> char <span class="hljs-keyword">to</span>/of dictionary <br>            dic[ch] = i<br>        # answer <span class="hljs-keyword">is</span> either in the begining/middle OR some mid <span class="hljs-keyword">to</span> the end of <span class="hljs-built_in">string</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">max</span>(<span class="hljs-keyword">res</span>, <span class="hljs-built_in">len</span>(s)-start)<br></code></pre></td></tr></table></figure><p>方法二：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">lengthOfLongestSubstring</span>(<span class="hljs-params">self, s</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        :type s: str</span><br><span class="hljs-string">        :rtype: int</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        maxnum,num,ss =<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-string">&#x27;&#x27;</span><br>        <span class="hljs-keyword">for</span> each <span class="hljs-keyword">in</span> s:<br>            <span class="hljs-keyword">if</span> each <span class="hljs-keyword">in</span> ss:<br>                ss = ss.split(each)[-<span class="hljs-number">1</span>]+each <span class="hljs-comment"># ‘’+each</span><br>                num =<span class="hljs-built_in">len</span>(ss)<br>            <span class="hljs-keyword">else</span>:<br>                num += <span class="hljs-number">1</span><br>                ss += each<br>                <span class="hljs-keyword">if</span> num&gt;=maxnum:<br>                    maxnum = num<br>        <span class="hljs-keyword">return</span> maxnum<br></code></pre></td></tr></table></figure><h5 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h5><ol><li><a href="https://www.w3schools.com/python/ref_string_split.asp">https://www.w3schools.com/python/ref_string_split.asp</a> Python String split() Method</li><li><a href="https://leetcode.com/problems/longest-substring-without-repeating-characters/">https://leetcode.com/problems/longest-substring-without-repeating-characters/</a> longest-substring-without-repeating-characters</li></ol>]]></content>
    
    
    <categories>
      
      <category>算法</category>
      
    </categories>
    
    
    <tags>
      
      <tag>算法</tag>
      
      <tag>python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Add Two Numbers</title>
    <link href="/posts/64c8f80f/"/>
    <url>/posts/64c8f80f/</url>
    
    <content type="html"><![CDATA[<h5 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h5><p>You are given two non-empty linked lists representing two non-negative integers. The digits are stored in reverse order and each of their nodes contain a single digit. Add the two numbers and return it as a linked list.</p><p>You may assume the two numbers do not contain any leading zero, except the number 0 itself.</p><span id="more"></span><h5 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h5><p>Input: (2 -&gt; 4 -&gt; 3) + (5 -&gt; 6 -&gt; 4)<br>Output: 7 -&gt; 0 -&gt; 8<br>Explanation: 342 + 465 &#x3D; 807.</p><h5 id="算法思路"><a href="#算法思路" class="headerlink" title="算法思路"></a>算法思路</h5><p>在这个问题中，有两种解决思路，第一种是先将输入的链表计算结果转换成字符串，再转成链表输出；第二种是直接采用链表操作。总的来说，第一种方法更易于理解，执行效率更高（runtime is 116ms），第二种方法更加复杂，耗时更长(runtime is 288ms),所以推荐使用方法一。</p><h5 id="代码实现（Python3）"><a href="#代码实现（Python3）" class="headerlink" title="代码实现（Python3）"></a>代码实现（Python3）</h5><p>方法一：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">addTwoNumbers</span>(<span class="hljs-params">self, l1, l2</span>):<br>        twoSum = <span class="hljs-built_in">str</span>(<span class="hljs-built_in">int</span>(self.getNumber(l1)) + <span class="hljs-built_in">int</span>(self.getNumber(l2)))<br>        <span class="hljs-keyword">return</span> self.constructList(twoSum)<br>    <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">getNumber</span>(<span class="hljs-params">self, head</span>):<br>        current, res = head, []<br>        <span class="hljs-keyword">while</span> current:<br>            res.append(<span class="hljs-built_in">str</span>(current.val))<br>            current = current.<span class="hljs-built_in">next</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-string">&#x27;&#x27;</span>.join(res[::-<span class="hljs-number">1</span>]) <span class="hljs-comment"># reverse res</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">constructList</span>(<span class="hljs-params">self, num</span>):<br>        head = ListNode(<span class="hljs-built_in">int</span>(num[-<span class="hljs-number">1</span>])) <span class="hljs-comment"># get the last element</span><br>        current = head<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(num) - <span class="hljs-number">2</span>, -<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>): <span class="hljs-comment"># range(start, stop, step)</span><br>            node = ListNode(<span class="hljs-built_in">int</span>(num[i]))<br>            current.<span class="hljs-built_in">next</span> = node<br>            current = current.<span class="hljs-built_in">next</span><br>        <span class="hljs-keyword">return</span> head<br></code></pre></td></tr></table></figure><p>方法二：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Definition for singly-linked list.</span><br><span class="hljs-comment"># class ListNode(object):</span><br><span class="hljs-comment">#     def __init__(self, x):</span><br><span class="hljs-comment">#         self.val = x</span><br><span class="hljs-comment">#         self.next = None</span><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>(<span class="hljs-title class_ inherited__">object</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">addTwoNumbers</span>(<span class="hljs-params">self, l1, l2</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        :type l1: ListNode</span><br><span class="hljs-string">        :type l2: ListNode</span><br><span class="hljs-string">        :rtype: ListNode</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <br>        <span class="hljs-comment"># Carry over place holder.</span><br>        carry = <span class="hljs-number">0</span><br>        <br>        <span class="hljs-comment"># Create a dummy head, tail node to keep track of the start and end of the list</span><br>        dummy_head = tail = ListNode(<span class="hljs-number">0</span>)<br>        <br>        <span class="hljs-comment"># While there are elements in either list we add them</span><br>        <span class="hljs-keyword">while</span> l1 <span class="hljs-keyword">or</span> l2:<br>            <br>            <span class="hljs-comment"># Get the two element values, if there is not a node use 0</span><br>            num_one = l1.val <span class="hljs-keyword">if</span> l1 <span class="hljs-keyword">else</span> <span class="hljs-number">0</span><br>            num_two = l2.val <span class="hljs-keyword">if</span> l2 <span class="hljs-keyword">else</span> <span class="hljs-number">0</span><br>            <br>            <span class="hljs-comment"># Get the new total with two numbers plus the carry over</span><br>            new_sum = num_one + num_two + carry<br>            <br>            <span class="hljs-comment"># Check to see if the number will create a carry</span><br>            <span class="hljs-keyword">if</span> new_sum &gt; <span class="hljs-number">9</span>:<br>                <span class="hljs-comment"># Set the tail node equal to the new node.</span><br>                tail.<span class="hljs-built_in">next</span> = ListNode(new_sum - <span class="hljs-number">10</span>)<br>                <span class="hljs-comment"># Set a carry because the number was larger than 10</span><br>                carry = <span class="hljs-number">1</span><br>            <span class="hljs-keyword">else</span>:<br>                tail.<span class="hljs-built_in">next</span> = ListNode(new_sum)<br>                carry = <span class="hljs-number">0</span><br>                <br>            <span class="hljs-comment"># Set the tail node to the new tail.</span><br>            tail = tail.<span class="hljs-built_in">next</span> <br>            <br>            <span class="hljs-comment"># Set the current nodes to the next number</span><br>            <span class="hljs-keyword">if</span> l1:<br>                l1 = l1.<span class="hljs-built_in">next</span><br>            <span class="hljs-keyword">if</span> l2:<br>                l2 = l2.<span class="hljs-built_in">next</span><br>        <br>        <span class="hljs-comment"># Once the adding has been completed if there is still a carry append a new node</span><br>        <span class="hljs-keyword">if</span> carry:<br>            tail.<span class="hljs-built_in">next</span> = ListNode(carry)<br>            <br>        <span class="hljs-comment"># Return the first number set, dummy head was just a place holder. The tail would point to the last node and not the first number in the linked list.</span><br>        <span class="hljs-keyword">return</span> dummy_head.<span class="hljs-built_in">next</span><br></code></pre></td></tr></table></figure><h5 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h5><ol><li><a href="https://stackoverflow.com/questions/31633635/what-is-the-meaning-of-inta-1-in-python">https://stackoverflow.com/questions/31633635/what-is-the-meaning-of-inta-1-in-python</a> What is the meaning of “int(a[::-1])” in Python?</li><li><a href="https://stackoverflow.com/questions/930397/getting-the-last-element-of-a-list-in-python">https://stackoverflow.com/questions/930397/getting-the-last-element-of-a-list-in-python</a> Getting the last element of a list in Python</li><li><a href="https://www.pythoncentral.io/pythons-range-function-explained/">https://www.pythoncentral.io/pythons-range-function-explained/</a> Python’s range() Function Explained</li><li><a href="https://leetcode.com/problems/add-two-numbers/">https://leetcode.com/problems/add-two-numbers/</a> Add Two Numbers</li></ol>]]></content>
    
    
    <categories>
      
      <category>算法</category>
      
    </categories>
    
    
    <tags>
      
      <tag>算法</tag>
      
      <tag>python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Two Sum</title>
    <link href="/posts/e83060be/"/>
    <url>/posts/e83060be/</url>
    
    <content type="html"><![CDATA[<h5 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h5><p>Given an array of integers, return indices of the two numbers such that they add up to a specific target.<br>You may assume that each input would have exactly one solution, and you may not use the same element twice.</p><span id="more"></span><h5 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h5><p>Given nums &#x3D; [2, 7, 11, 15], target &#x3D; 9,<br>Because nums[0] + nums[1] &#x3D; 2 + 7 &#x3D; 9,<br>return [0, 1].</p><h5 id="算法思路"><a href="#算法思路" class="headerlink" title="算法思路"></a>算法思路</h5><p>比较容易想到的是，用两个循环，两两元素之和与目标数比较，但是算法复杂度为O（n^2）,会超时。另一种办法是用字典和枚举，用字典存储查询过的值和索引，用枚举来遍历整个列表，算法复杂度为O（n）,所以推荐用第二种方法。</p><h5 id="代码实现（python3）"><a href="#代码实现（python3）" class="headerlink" title="代码实现（python3）"></a>代码实现（python3）</h5><p>方法一：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">twoSum</span>(<span class="hljs-params">self, nums, target</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        :type nums: List[int]</span><br><span class="hljs-string">        :type target: int</span><br><span class="hljs-string">        :rtype: List[int]</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        r = []<br>        l = <span class="hljs-built_in">len</span>(nums)<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(l):<br>            <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(l):<br>                <span class="hljs-keyword">if</span> nums[i] + nums[j] == target <span class="hljs-keyword">and</span> i != j:<br>                    <span class="hljs-keyword">return</span> i,j<br>        r = r.append(i,j)<br>        <span class="hljs-keyword">return</span> r<br></code></pre></td></tr></table></figure><p>方法二：</p><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs angelscript"><span class="hljs-keyword">class</span> <span class="hljs-symbol">Solution:</span><br><span class="hljs-symbol">    <span class="hljs-symbol">def</span></span> <span class="hljs-symbol">twoSum</span>(<span class="hljs-symbol">self, <span class="hljs-symbol">nums</span>, <span class="hljs-symbol">target</span></span>):<br>        &quot;&quot;&quot;<br>        :<span class="hljs-symbol">type</span> <span class="hljs-symbol">nums: <span class="hljs-symbol">List</span></span>[<span class="hljs-symbol">int</span>]<br>        :<span class="hljs-symbol">type</span> <span class="hljs-symbol">target: <span class="hljs-symbol">int</span></span><br>        :<span class="hljs-symbol">rtype: <span class="hljs-symbol">List</span></span>[<span class="hljs-symbol">int</span>]<br>        &quot;&quot;&quot;<br>        <span class="hljs-symbol">collected</span> = &#123;&#125;<br>        <span class="hljs-keyword">for</span> i,x <span class="hljs-keyword">in</span> enumerate(nums):<br>            diff = target-x<br>            <span class="hljs-keyword">if</span> diff <span class="hljs-keyword">in</span> collected:<br>                <span class="hljs-keyword">return</span> [collected[diff], i]<br>            collected[x] = i<br></code></pre></td></tr></table></figure><h5 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h5><ol><li><a href="https://www.tutorialspoint.com/python/python_dictionary.htm">https://www.tutorialspoint.com/python/python_dictionary.htm</a> Python - Dictionary</li><li><a href="https://www.geeksforgeeks.org/enumerate-in-python/">https://www.geeksforgeeks.org/enumerate-in-python/</a> Enumerate() in Python</li><li><a href="https://leetcode.com/problems/two-sum/">https://leetcode.com/problems/two-sum/</a> two-sum</li></ol>]]></content>
    
    
    <categories>
      
      <category>算法</category>
      
    </categories>
    
    
    <tags>
      
      <tag>算法</tag>
      
      <tag>python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>使用pyecharts绘制关系图</title>
    <link href="/posts/84391376/"/>
    <url>/posts/84391376/</url>
    
    <content type="html"><![CDATA[<p>首先介绍下什么是pyecharts, 它是使用Echarts来生成图表的一个python库，我们知道Echarts是百度的一个开源数据可视化javascript库，提供了大量的图表样例，功能十分强大，用起来很方便。今天我们就用pyecharts来绘制一个关系图。</p><span id="more"></span><h5 id="最终效果"><a href="#最终效果" class="headerlink" title="最终效果"></a>最终效果</h5><p><a href="https://i.loli.net/2018/10/04/5bb624e008b33.png"><img src="https://i.loli.net/2018/10/04/5bb624e008b33.png" alt="1.png"></a></p><h5 id="接下来，讲一讲实现步骤"><a href="#接下来，讲一讲实现步骤" class="headerlink" title="接下来，讲一讲实现步骤"></a>接下来，讲一讲实现步骤</h5><ol><li><p>安装pyecharts（以Ubuntu系统为例）: </p><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cmake">$ pip <span class="hljs-keyword">install</span> pyecharts<br></code></pre></td></tr></table></figure></li><li><p>代码实现</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-keyword">from</span> pyecharts import Graph<br><br>nodes = [&#123;<span class="hljs-string">&quot;name&quot;</span>: <span class="hljs-string">&quot;node1&quot;</span>, <span class="hljs-string">&quot;symbolSize&quot;</span>: 10&#125;,<br>         &#123;<span class="hljs-string">&quot;name&quot;</span>: <span class="hljs-string">&quot;node2&quot;</span>, <span class="hljs-string">&quot;symbolSize&quot;</span>: 20&#125;,<br>         &#123;<span class="hljs-string">&quot;name&quot;</span>: <span class="hljs-string">&quot;node3&quot;</span>, <span class="hljs-string">&quot;symbolSize&quot;</span>: 30&#125;,<br>         &#123;<span class="hljs-string">&quot;name&quot;</span>: <span class="hljs-string">&quot;node4&quot;</span>, <span class="hljs-string">&quot;symbolSize&quot;</span>: 40&#125;,<br>         &#123;<span class="hljs-string">&quot;name&quot;</span>: <span class="hljs-string">&quot;node5&quot;</span>, <span class="hljs-string">&quot;symbolSize&quot;</span>: 50&#125;,<br>         &#123;<span class="hljs-string">&quot;name&quot;</span>: <span class="hljs-string">&quot;node6&quot;</span>, <span class="hljs-string">&quot;symbolSize&quot;</span>: 40&#125;,<br>         &#123;<span class="hljs-string">&quot;name&quot;</span>: <span class="hljs-string">&quot;node7&quot;</span>, <span class="hljs-string">&quot;symbolSize&quot;</span>: 30&#125;,<br>         &#123;<span class="hljs-string">&quot;name&quot;</span>: <span class="hljs-string">&quot;node8&quot;</span>, <span class="hljs-string">&quot;symbolSize&quot;</span>: 20&#125;]<br>links = []<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> nodes:<br>    <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> nodes:<br>        links.append(&#123;<span class="hljs-string">&quot;source&quot;</span>: i.<span class="hljs-built_in">get</span>(<span class="hljs-string">&#x27;name&#x27;</span>), <span class="hljs-string">&quot;target&quot;</span>: j.<span class="hljs-built_in">get</span>(<span class="hljs-string">&#x27;name&#x27;</span>)&#125;)<br>graph = Graph(<span class="hljs-string">&quot;关系图-环形布局示例&quot;</span>)<br>graph.<span class="hljs-built_in">add</span>(<span class="hljs-string">&quot;&quot;</span>, nodes, links, <span class="hljs-attribute">is_label_show</span>=<span class="hljs-literal">True</span>,<br>          <span class="hljs-attribute">graph_repulsion</span>=8000, <span class="hljs-attribute">graph_layout</span>=<span class="hljs-string">&#x27;circular&#x27;</span>,<br>          <span class="hljs-attribute">label_text_color</span>=None)<br>graph.render(<span class="hljs-string">&quot;graph.html&quot;</span>)<br></code></pre></td></tr></table></figure><p>最后，还要提到的一点是，以上只是简单的示例，仅供学习，实际使用过程中，需要适当调整代码，达到更好的效果，或选用其他可视化方式。</p></li></ol><h5 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h5><ol><li><a href="https://github.com/pyecharts/pyecharts">https://github.com/pyecharts/pyecharts</a>  pyecharts</li><li><a href="http://echarts.baidu.com/">http://echarts.baidu.com/</a> echarts</li><li><a href="https://mp.weixin.qq.com/s?__biz=MzI5NDY1MjQzNA==&mid=2247487437&idx=1&sn=0a79cfc2870cdfe87ce32d73bd64483f&chksm=ec5ed0b0db2959a609b22be2ebdc792132f40870ce56c10856085acbd24cca5c2971e03c63e9&scene=21#wechat_redirect">https://mp.weixin.qq.com/s?__biz=MzI5NDY1MjQzNA==&amp;mid=2247487437&amp;idx=1&amp;sn=0a79cfc2870cdfe87ce32d73bd64483f&amp;chksm=ec5ed0b0db2959a609b22be2ebdc792132f40870ce56c10856085acbd24cca5c2971e03c63e9&amp;scene=21#wechat_redirect</a> 人生苦短，我要用pyecharts画图</li></ol>]]></content>
    
    
    <categories>
      
      <category>经验技巧</category>
      
    </categories>
    
    
    <tags>
      
      <tag>python</tag>
      
      <tag>可视化</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>加一</title>
    <link href="/posts/2e394548/"/>
    <url>/posts/2e394548/</url>
    
    <content type="html"><![CDATA[<h5 id="要求："><a href="#要求：" class="headerlink" title="要求："></a>要求：</h5><p>给定一个非负整数组成的非空数组，在该数的基础上加一，返回一个新的数组。<br><br>最高位数字存放在数组的首位， 数组中每个元素只存储一个数字。<br><br>你可以假设除了整数 0 之外，这个整数不会以零开头。</p><span id="more"></span><h5 id="示例："><a href="#示例：" class="headerlink" title="示例："></a>示例：</h5><p>（1）<br><br>输入: [1,2,3]<br><br>输出: [1,2,4]<br><br>解释: 输入数组表示数字 123。<br><br>（2）<br><br>输入: [4,3,2,1]<br><br>输出: [4,3,2,2]<br><br>解释: 输入数组表示数字 4321。</p><h5 id="分析："><a href="#分析：" class="headerlink" title="分析："></a>分析：</h5><p>从后向前判断每个元素，如有进位，将进位符flag置为1，将元素所在位变为0；若无进位，将元素所在位+1，并将进位符置0，最后判断进位符标志，如果为1，则在数组第0位增加一个元素1。</p><h5 id="代码："><a href="#代码：" class="headerlink" title="代码："></a>代码：</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">plusOne</span>(<span class="hljs-params">self, digits</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        :type digits: List[int]</span><br><span class="hljs-string">        :rtype: List[int]</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <br>        flag = <span class="hljs-number">1</span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(digits)-<span class="hljs-number">1</span>,-<span class="hljs-number">1</span>,-<span class="hljs-number">1</span>):<br>            <span class="hljs-keyword">if</span> flag + digits[i] == <span class="hljs-number">10</span>:<br>                digits[i] = <span class="hljs-number">0</span><br>                flag = <span class="hljs-number">1</span><br>            <span class="hljs-keyword">else</span>:<br>                digits[i] = digits[i] + flag<br>                flag = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">if</span> flag == <span class="hljs-number">1</span>:<br>            digits.insert(<span class="hljs-number">0</span>,<span class="hljs-number">1</span>)<br>        <span class="hljs-keyword">return</span> digits<br></code></pre></td></tr></table></figure><h5 id="参考资料："><a href="#参考资料：" class="headerlink" title="参考资料："></a>参考资料：</h5><p>1、leetcode 66.Plus One python <a href="https://blog.csdn.net/mario_mmh/article/details/79845181">https://blog.csdn.net/mario_mmh/article/details/79845181</a></p>]]></content>
    
    
    <categories>
      
      <category>算法</category>
      
    </categories>
    
    
    <tags>
      
      <tag>python</tag>
      
      <tag>数组</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>两个数组的交集Ⅱ</title>
    <link href="/posts/8ed9ffc/"/>
    <url>/posts/8ed9ffc/</url>
    
    <content type="html"><![CDATA[<h5 id="要求："><a href="#要求：" class="headerlink" title="要求："></a>要求：</h5><p>给定两个数组，写一个方法来计算它们的交集。</p><span id="more"></span><h5 id="示例："><a href="#示例：" class="headerlink" title="示例："></a>示例：</h5><p>给定 nums1 &#x3D; [1, 2, 2, 1], nums2 &#x3D; [2, 2], 返回 [2, 2].</p><h5 id="分析："><a href="#分析：" class="headerlink" title="分析："></a>分析：</h5><p>先对两个数组由小到大排序，用两个指针index1和index2遍历两个数组，比较对应元素的大小，如果相等，则添加进result数组，如果不相等，元素小的数组指针加一，最终其中一个数组遍历结束，就停止程序。</p><h5 id="代码："><a href="#代码：" class="headerlink" title="代码："></a>代码：</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">intersect</span>(<span class="hljs-params">self, nums1, nums2</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        :type nums1: List[int]</span><br><span class="hljs-string">        :type nums2: List[int]</span><br><span class="hljs-string">        :rtype: List[int]</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        result = []<br>        nums1.sort()<br>        nums2.sort()<br>        index1, index2 = <span class="hljs-number">0</span>, <span class="hljs-number">0</span><br>        n1, n2 = <span class="hljs-built_in">len</span>(nums1), <span class="hljs-built_in">len</span>(nums2)<br>        <br>        <span class="hljs-keyword">while</span> index1 &lt; n1 <span class="hljs-keyword">and</span> index2 &lt; n2:<br>            <span class="hljs-keyword">if</span> nums1[index1] == nums2[index2]:<br>                result.append(nums1[index1])<br>                index1 += <span class="hljs-number">1</span><br>                index2 += <span class="hljs-number">1</span><br>            <span class="hljs-keyword">elif</span> nums1[index1] &gt; nums2[index2]:<br>                index2 += <span class="hljs-number">1</span><br>            <span class="hljs-keyword">else</span>:<br>                index1 += <span class="hljs-number">1</span><br>        <span class="hljs-keyword">return</span> result<br></code></pre></td></tr></table></figure><h5 id="参考资料："><a href="#参考资料：" class="headerlink" title="参考资料："></a>参考资料：</h5><p>1、两数组的交 II <a href="https://blog.csdn.net/guoziqing506/article/details/51569488">https://blog.csdn.net/guoziqing506/article/details/51569488</a></p>]]></content>
    
    
    <categories>
      
      <category>算法</category>
      
    </categories>
    
    
    <tags>
      
      <tag>python</tag>
      
      <tag>数组</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>只出现一次的数字</title>
    <link href="/posts/2c835ddc/"/>
    <url>/posts/2c835ddc/</url>
    
    <content type="html"><![CDATA[<h5 id="要求："><a href="#要求：" class="headerlink" title="要求："></a>要求：</h5><p>给定一个非空整数数组，除了某个元素只出现一次以外，其余每个元素均出现两次。找出那个只出现了一次的元素。（算法应该具有线性时间复杂度）</p><span id="more"></span><h5 id="示例："><a href="#示例：" class="headerlink" title="示例："></a>示例：</h5><p>（1）<br>输入: [2,2,1]<br><br>输出: 1<br><br>（2）<br>输入: [4,1,2,1,2]<br><br>输出: 4</p><h5 id="分析："><a href="#分析：" class="headerlink" title="分析："></a>分析：</h5><p>为了找出只出现一次的元素，可以先将所有元素出现的次数变为一次，然后对所有元素求和，乘以2倍，减去原来数组元素的和，即为只出现一次的元素的值。</p><h5 id="代码："><a href="#代码：" class="headerlink" title="代码："></a>代码：</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">singleNumber</span>(<span class="hljs-params">self, nums</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        :type nums: List[int]</span><br><span class="hljs-string">        :rtype: int</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">sum</span>(<span class="hljs-built_in">set</span>(nums))*<span class="hljs-number">2</span> - <span class="hljs-built_in">sum</span>(nums)<br></code></pre></td></tr></table></figure><h5 id="参考资料："><a href="#参考资料：" class="headerlink" title="参考资料："></a>参考资料：</h5><p>1、LeetCode 136. 只出现一次的数字 Python <a href="https://blog.csdn.net/ma412410029/article/details/80511684">https://blog.csdn.net/ma412410029/article/details/80511684</a></p>]]></content>
    
    
    <categories>
      
      <category>算法</category>
      
    </categories>
    
    
    <tags>
      
      <tag>python</tag>
      
      <tag>数组</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>存在重复</title>
    <link href="/posts/e449a9c3/"/>
    <url>/posts/e449a9c3/</url>
    
    <content type="html"><![CDATA[<h5 id="要求："><a href="#要求：" class="headerlink" title="要求："></a>要求：</h5><p>给定一个整数数组，判断是否存在重复元素。<br>如果任何值在数组中出现至少两次，函数返回 true。如果数组中每个元素都不相同，则返回 false。</p><span id="more"></span><h5 id="示例："><a href="#示例：" class="headerlink" title="示例："></a>示例：</h5><p>(1)<br>输入: [1,2,3,1]<br><br>输出: true <br><br>(2)<br>输入: [1,2,3,4]<br><br>输出: false <br><br>(3)<br>输入: [1,1,1,3,3,4,3,2,4,2]<br><br>输出: true</p><h5 id="分析："><a href="#分析：" class="headerlink" title="分析："></a>分析：</h5><p>直接元素之间比较，会很容易想到用两个for循环来进行元素间判断，但是这种方法会超时，所以不使用这种方法；可以通过将数组转换成集合，然后判断转换前的数组和集合的长度是否相等，如果相等，则没有重复元素，如果不相等，则存在重复元素。（这种方法，很巧妙，也应用了集合的特性）。</p><h5 id="代码："><a href="#代码：" class="headerlink" title="代码："></a>代码：</h5><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs angelscript"><span class="hljs-keyword">class</span> <span class="hljs-symbol">Solution:</span><br><span class="hljs-symbol">    <span class="hljs-symbol">def</span></span> <span class="hljs-symbol">containsDuplicate</span>(<span class="hljs-symbol">self, <span class="hljs-symbol">nums</span></span>):<br>        &quot;&quot;&quot;<br>        :<span class="hljs-symbol">type</span> <span class="hljs-symbol">nums: <span class="hljs-symbol">List</span></span>[<span class="hljs-symbol">int</span>]<br>        :<span class="hljs-symbol">rtype: <span class="hljs-symbol">bool</span></span><br>        &quot;&quot;&quot;<br>        <span class="hljs-symbol">if</span> (<span class="hljs-symbol">len</span>(<span class="hljs-symbol">nums</span>) != <span class="hljs-symbol">len</span>(<span class="hljs-symbol">set</span>(<span class="hljs-symbol">nums</span>))):<br>            <span class="hljs-symbol">return</span> <span class="hljs-symbol">True</span><br>        <span class="hljs-symbol">else:</span><br><span class="hljs-symbol">            <span class="hljs-symbol">return</span></span> <span class="hljs-symbol">False</span><br></code></pre></td></tr></table></figure><h5 id="参考资料："><a href="#参考资料：" class="headerlink" title="参考资料："></a>参考资料：</h5><p>1、LeetCode-containsDuplicate-存在重复 <a href="https://segmentfault.com/a/1190000014325206">https://segmentfault.com/a/1190000014325206</a></p>]]></content>
    
    
    <categories>
      
      <category>算法</category>
      
    </categories>
    
    
    <tags>
      
      <tag>python</tag>
      
      <tag>数组</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>旋转数组</title>
    <link href="/posts/fb62c7d3/"/>
    <url>/posts/fb62c7d3/</url>
    
    <content type="html"><![CDATA[<h5 id="要求："><a href="#要求：" class="headerlink" title="要求："></a>要求：</h5><p>给定一个数组，将数组中的元素向右移动 k 个位置，其中 k 是非负数。</p><span id="more"></span><h5 id="示例："><a href="#示例：" class="headerlink" title="示例："></a>示例：</h5><p>（1）<br>输入: [1,2,3,4,5,6,7] 和 k &#x3D; 3<br>输出: [5,6,7,1,2,3,4]解释:<br>向右旋转 1 步: [7,1,2,3,4,5,6]<br>向右旋转 2 步: [6,7,1,2,3,4,5]<br>向右旋转 3 步: [5,6,7,1,2,3,4] <br><br>（2）<br>输入: [-1,-100,3,99] 和 k &#x3D; 2<br>输出: [3,99,-1,-100]<br>解释:<br>向右旋转 1 步: [99,-1,-100,3]<br>向右旋转 2 步: [3,99,-1,-100]</p><h5 id="分析："><a href="#分析：" class="headerlink" title="分析："></a>分析：</h5><p>将前k个元素移动到数组的后半部分，将后(n-k)个元素移动到数组的前半部分。</p><h5 id="代码："><a href="#代码：" class="headerlink" title="代码："></a>代码：</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">rotate</span>(<span class="hljs-params">self, nums, k</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        :type nums: List[int]</span><br><span class="hljs-string">        :type k: int</span><br><span class="hljs-string">        :rtype: void Do not return anything, modify nums in-place instead.</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        n = <span class="hljs-built_in">len</span>(nums) - k  <br>        nums[:] = nums[n:] + nums[:n]<br></code></pre></td></tr></table></figure><h5 id="拓展："><a href="#拓展：" class="headerlink" title="拓展："></a>拓展：</h5><p>1、这是一个直观的算法操作，以切片（分块）的方式操作数组，比较符合人的思维，但是要注重观察示例特征，否则容易陷入单个元素移动的怪圈。<br><br>2、nums[:] &#x3D; 和 nums &#x3D; 的区别：</p><figure class="highlight python-repl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python-repl"><span class="hljs-meta prompt_">&gt;&gt;&gt;</span> <span class="language-python">a = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>))</span><br><span class="hljs-meta prompt_">&gt;&gt;&gt;</span> <span class="language-python">b = a</span><br><span class="hljs-meta prompt_">&gt;&gt;&gt;</span> <span class="language-python">a[:] = [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>] <span class="hljs-comment"># changes what a and b both refer to</span></span><br><span class="hljs-meta prompt_">&gt;&gt;&gt;</span> <span class="language-python">b</span><br>[0, 0, 0]<br><br><span class="hljs-meta prompt_">&gt;&gt;&gt;</span> <span class="language-python">a = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>))</span><br><span class="hljs-meta prompt_">&gt;&gt;&gt;</span> <span class="language-python">b = a</span><br><span class="hljs-meta prompt_">&gt;&gt;&gt;</span> <span class="language-python">a = [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>] <span class="hljs-comment"># a now refers to a different list than b</span></span><br><span class="hljs-meta prompt_">&gt;&gt;&gt;</span> <span class="language-python">b</span><br>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>算法</category>
      
    </categories>
    
    
    <tags>
      
      <tag>python</tag>
      
      <tag>数组</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>买卖股票的最佳时机Ⅱ</title>
    <link href="/posts/43c05810/"/>
    <url>/posts/43c05810/</url>
    
    <content type="html"><![CDATA[<h5 id="要求："><a href="#要求：" class="headerlink" title="要求："></a>要求：</h5><p>给定一个数组，它的第 i 个元素是一支给定股票第 i 天的价格。<br>设计一个算法来计算你所能获取的最大利润。你可以尽可能地完成更多的交易（多次买卖一支股票）。<br>注意：你不能同时参与多笔交易（你必须在再次购买前出售掉之前的股票）。</p><span id="more"></span><h5 id="示例："><a href="#示例：" class="headerlink" title="示例："></a>示例：</h5><p>（1）输入: [7,1,5,3,6,4]<br>输出: 7<br>解释: 在第 2 天（股票价格 &#x3D; 1）的时候买入，在第 3 天（股票价格 &#x3D; 5）的时候卖出, 这笔交易所能获得利润 &#x3D; 5-1 &#x3D; 4 。<br>     随后，在第 4 天（股票价格 &#x3D; 3）的时候买入，在第 5 天（股票价格 &#x3D; 6）的时候卖出, 这笔交易所能获得利润 &#x3D; 6-3 &#x3D; 3 。<br><br>（2）输入: [1,2,3,4,5]<br>输出: 4<br>解释: 在第 1 天（股票价格 &#x3D; 1）的时候买入，在第 5 天 （股票价格 &#x3D; 5）的时候卖出, 这笔交易所能获得利润 &#x3D; 5-1 &#x3D; 4 。<br>     注意你不能在第 1 天和第 2 天接连购买股票，之后再将它们卖出。<br>     因为这样属于同时参与了多笔交易，你必须在再次购买前出售掉之前的股票。<br><br>（3）输入: [7,6,4,3,1]<br>输出: 0<br>解释: 在这种情况下, 没有交易完成, 所以最大利润为 0。</p><h5 id="分析："><a href="#分析：" class="headerlink" title="分析："></a>分析：</h5><p>通过比较相邻两个值的大小，低价买入，高价卖出，然后计算收益，另外考虑不买入和不卖出的特殊情况。</p><h5 id="代码："><a href="#代码：" class="headerlink" title="代码："></a>代码：</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">maxProfit</span>(<span class="hljs-params">self, prices</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        :type prices: List[int]</span><br><span class="hljs-string">        :rtype: int</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        status = <span class="hljs-number">0</span><br>        length = <span class="hljs-built_in">len</span>(prices)<br>        result = <span class="hljs-number">0</span><br>        buy = <span class="hljs-number">0</span><br>        sell = <span class="hljs-number">0</span><br>        <span class="hljs-comment">#当列表为空或者只有一位时，返回0</span><br>        <span class="hljs-keyword">if</span> length &lt;= <span class="hljs-number">1</span>:<br>            <span class="hljs-keyword">return</span> <span class="hljs-number">0</span><br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-comment">#遍历列表</span><br>            <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(length-<span class="hljs-number">1</span>):<br>                <span class="hljs-comment">#当状态为未买入，并且后一位的值大于前一位值时，买入，并且把状态改为买入</span><br>                <span class="hljs-keyword">if</span> status == <span class="hljs-number">0</span> <span class="hljs-keyword">and</span> prices[x] &lt; prices[x+<span class="hljs-number">1</span>]:<br>                    buy = prices[x]<br>                    status = <span class="hljs-number">1</span><br>                <span class="hljs-comment">#当状态为买入，并且后一位的值小于等于前一位值时，卖出，并且把状态改为未买入，累计result</span><br>                <span class="hljs-keyword">elif</span> status == <span class="hljs-number">1</span> <span class="hljs-keyword">and</span> prices[x] &gt;= prices[x+<span class="hljs-number">1</span>]:<br>                    sell = prices[x]<br>                    result = result + sell - buy<br>                    status = <span class="hljs-number">0</span> <span class="hljs-comment"># 正常情况最后状态一定是未买入，即status=0</span><br>                    <br>            <span class="hljs-comment">#用来排除[5,4,3,2,1]这种一直没有买入的情况</span><br>            <span class="hljs-keyword">if</span> status == <span class="hljs-number">0</span> <span class="hljs-keyword">and</span> sell == <span class="hljs-number">0</span>:<br>                result = <span class="hljs-number">0</span><br>            <span class="hljs-comment">#用来解决[1,2,3,4,5]这种一直没有卖出的情况</span><br>            <span class="hljs-keyword">elif</span> status == <span class="hljs-number">1</span>:<br>                result = result + prices[length-<span class="hljs-number">1</span>] - buy<br>            <span class="hljs-keyword">return</span> result<br></code></pre></td></tr></table></figure><h5 id="参考资料："><a href="#参考资料：" class="headerlink" title="参考资料："></a>参考资料：</h5><p>1、买卖股票的最佳时机 II-Python-LeetCode <a href="https://blog.csdn.net/linfeng886/article/details/80070804">https://blog.csdn.net/linfeng886/article/details/80070804</a></p>]]></content>
    
    
    <categories>
      
      <category>算法</category>
      
    </categories>
    
    
    <tags>
      
      <tag>python</tag>
      
      <tag>数组</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>从排序数组中删除重复项</title>
    <link href="/posts/2b4bef4e/"/>
    <url>/posts/2b4bef4e/</url>
    
    <content type="html"><![CDATA[<h5 id="要求："><a href="#要求：" class="headerlink" title="要求："></a>要求：</h5><p>给定一个排序数组，你需要在原地删除重复出现的元素，使得每个元素只出现一次，返回移除后数组的新长度。（不要使用额外的数组空间，你必须在原地修改输入数组并在使用O（1）额外空间的条件下完成）。</p><span id="more"></span><h5 id="示例："><a href="#示例：" class="headerlink" title="示例："></a>示例：</h5><p>给定数组 nums &#x3D; [1,1,2],<br>函数应该返回新的长度 2, 并且原数组 nums 的前两个元素被修改为 1, 2。你不需要考虑数组中超出新长度后面的元素。</p><h5 id="分析："><a href="#分析：" class="headerlink" title="分析："></a>分析：</h5><p>遍历一遍数组，将不重复的数字保留，重复的数字覆盖，并删除末尾剩余的数字。</p><h5 id="代码（python3）"><a href="#代码（python3）" class="headerlink" title="代码（python3）:"></a>代码（python3）:</h5><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs angelscript"><span class="hljs-keyword">class</span> <span class="hljs-symbol">Solution:</span><br><span class="hljs-symbol">    <span class="hljs-symbol">def</span></span> <span class="hljs-symbol">removeDuplicates</span>(<span class="hljs-symbol">self, <span class="hljs-symbol">nums</span></span>):<br>        &quot;&quot;&quot;<br>        :<span class="hljs-symbol">type</span> <span class="hljs-symbol">nums: <span class="hljs-symbol">List</span></span>[<span class="hljs-symbol">int</span>]<br>        :<span class="hljs-symbol">rtype: <span class="hljs-symbol">int</span></span><br>        &quot;&quot;&quot;<br>        <span class="hljs-symbol">k</span> = <span class="hljs-symbol">0</span><br>        <span class="hljs-symbol">for</span> <span class="hljs-symbol">i</span> <span class="hljs-symbol">in</span> <span class="hljs-symbol">range</span>(<span class="hljs-symbol">1,<span class="hljs-symbol">len</span></span>(<span class="hljs-symbol">nums</span>)):<br>            <span class="hljs-symbol">if</span> <span class="hljs-symbol">nums</span>[<span class="hljs-symbol">i</span>] != <span class="hljs-symbol">nums</span>[<span class="hljs-symbol">k</span>]:<br>                <span class="hljs-symbol">k</span> = <span class="hljs-symbol">k</span>+<span class="hljs-symbol">1</span><br>                <span class="hljs-symbol">nums</span>[<span class="hljs-symbol">k</span>] = <span class="hljs-symbol">nums</span>[<span class="hljs-symbol">i</span>]<br>        <span class="hljs-symbol">del</span> <span class="hljs-symbol">nums</span>[<span class="hljs-symbol">k</span>+<span class="hljs-symbol">1:<span class="hljs-symbol">len</span></span>(<span class="hljs-symbol">nums</span>)]<br>        <span class="hljs-symbol">return</span> <span class="hljs-symbol">len</span>(<span class="hljs-symbol">nums</span>)<br></code></pre></td></tr></table></figure><h5 id="参考资料："><a href="#参考资料：" class="headerlink" title="参考资料："></a>参考资料：</h5><p>1、LintCode（100）删除排序数组中的重复数字 <a href="https://blog.csdn.net/fly_yr/article/details/51548657">https://blog.csdn.net/fly_yr/article/details/51548657</a></p>]]></content>
    
    
    <categories>
      
      <category>算法</category>
      
    </categories>
    
    
    <tags>
      
      <tag>python</tag>
      
      <tag>数组</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hexo常用命令</title>
    <link href="/posts/24caea6b/"/>
    <url>/posts/24caea6b/</url>
    
    <content type="html"><![CDATA[<p>hexo的基本命令有13个，但平时发布文章，经常用的命令只有下列几个：</p><span id="more"></span><h2 id="常用命令（按发布文章时使用命令的顺序）"><a href="#常用命令（按发布文章时使用命令的顺序）" class="headerlink" title="常用命令（按发布文章时使用命令的顺序）"></a>常用命令（按发布文章时使用命令的顺序）</h2><figure class="highlight actionscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs actionscript">hexo <span class="hljs-keyword">new</span> <span class="hljs-string">&quot;hello&quot;</span><br></code></pre></td></tr></table></figure><p>新建一篇标题为“hello”的文章。文章在文件夹\Hexo\source_posts下查看，也可以缩写成 hexo n。</p><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs ebnf"><span class="hljs-attribute">hexo g</span><br></code></pre></td></tr></table></figure><p>生成博客的静态文件到文件夹\Hexo\public。便于查看生成博客的静态文件。该命令是hexo generate的缩写。如果使用过gulp压缩过博客，可以使用组合命令“hexo g &amp;&amp; gulp”来达到压缩博客静态文件，提高博客访问速度的目的。</p><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs ebnf"><span class="hljs-attribute">hexo s</span><br></code></pre></td></tr></table></figure><p>用于启动本地服务器，查看网站预览效果。默认本地访问地址为：<a href="http://localhost:4000/">http://localhost:4000/</a> 。该命令是hexo server的缩写。预览的同时可以修改文章内容或该主题的代码，保存后刷新当前页即可。如果要修改博客根目录的_config.yml文件，需要重新执行hexo s才能预览效果。</p><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs ebnf"><span class="hljs-attribute">hexo d</span><br></code></pre></td></tr></table></figure><p>将本地博客文件部署到设定的github仓库中去。到该步骤，外网可以访问该博客。该命令是hexo deploy的缩写。</p><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs ebnf"><span class="hljs-attribute">hexo cl</span><br></code></pre></td></tr></table></figure><p>清除缓存文件db.json 和已生成的静态文件 public。通常在博客访问异常时使用。该命令是hexo clean的缩写。</p><figure class="highlight haxe"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs haxe">hexo <span class="hljs-keyword">new</span> <span class="hljs-type">page</span> <span class="hljs-string">&quot;mypage&quot;</span><br></code></pre></td></tr></table></figure><p>新建一个标题为mypage的页面，默认超链接地址为博客主页地址&#x2F;mypage&#x2F;。该页面不会出现在首页文章列表和归档中，也不支持设置分类和标签。</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ol><li><a href="http://moxfive.xyz/2015/12/21/common-hexo-commands/#comments">http://moxfive.xyz/2015/12/21/common-hexo-commands/#comments</a></li><li><a href="https://leaferx.online/2017/06/16/use-gulp-to-minimize/">https://leaferx.online/2017/06/16/use-gulp-to-minimize/</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>经验技巧</category>
      
    </categories>
    
    
    <tags>
      
      <tag>hexo命令</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>关于科学范式的感悟</title>
    <link href="/posts/fe6166bc/"/>
    <url>/posts/fe6166bc/</url>
    
    <content type="html"><![CDATA[<p>一个国家的科学发展，在于体制机制和科学思想（文化氛围、理念），它就相当于科学发展的土壤。</p><span id="more"></span><p>库恩提出的科学范式是一种科学规范、规则，也是一种科学理论，从实践中来，又能够经得起历史和实践的检验。科学的发展，不仅仅是科学知识的积累，还应当是科学范式的传承和发展。另外，学科和科学看似是两个相同的字组成，但两者包含的研究方法和理念，应当是有区别的。学科代表分而治之的观念，分科治学，能让学科走向更深的深度，更大限度拓深人的专长，解决某个专门领域的问题。而科学不仅仅是一种理论，也是一种体制机制下追求真理的精神，是一种理念、文化和氛围，能够在全社会广泛认可，取得广泛的影响。</p><p>由科学产生的范式，犹如大海航行中的海图，犹如探险家的攻略，也代表着进行科研的一种规则，通用的理念与方法，它是经过无数科学家在科研实践中，总结、提炼、升华出来的一种理论，并经过了历史与实践的检验，能引领后来的科研工作者，站在巨人的肩上，继续探索科学，为我们指明了科学发现与研究的路线，也为我们指出了科学的界限、层次与禁忌。</p><p>作为计算机科学与技术专业的一名研究生，正如在专业名字中体现出的内涵一致，研究计算机，不仅要当作一门学科，也要注重它的技术应用，更重要的是了解它的起源、研究规则、规范、该领域优秀科学家的思想和理念，这也就涉及到了范式。在一定的科研规范、路径下，遵循前人的科研理念，方法，在已有的科研基础上，继承与发展科研范式，创新开展科研工作，形成新时代、新阶段下的科研范式，进而提升为该学科、各学科通用，并能有效融合的，大家公认的具有广泛理论应用基础的科学范式。</p><p>科学与学科，分久必合，合久必分，在这个过程中，范式调整与发展、传承与创新、范式一直在发展，变得适合科学，助力科学发展。</p><p>注：感悟来自《自然辩证法》课程。</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ol><li>维基百科-范式<br> <a href="https://zh.wikipedia.org/wiki/%E8%8C%83%E5%BC%8F">https://zh.wikipedia.org/wiki/%E8%8C%83%E5%BC%8F</a></li><li>豆瓣-库恩范式理论及其发展模式<br> <a href="https://site.douban.com/134820/widget/notes/5899818/note/186441816/">https://site.douban.com/134820/widget/notes/5899818/note/186441816/</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>随笔感悟</category>
      
    </categories>
    
    
    <tags>
      
      <tag>科学范式</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【机器学习】防止过拟合的方法</title>
    <link href="/posts/3634e5b5/"/>
    <url>/posts/3634e5b5/</url>
    
    <content type="html"><![CDATA[<h1 id="什么是过拟合"><a href="#什么是过拟合" class="headerlink" title="什么是过拟合"></a>什么是过拟合</h1><p>从训练样本中尽可能学出适用于所有潜在样本的“普遍规律”，这样才能在遇到新样本时做出正确的判别。然而，当学习器把训练样本学得“太好”了的时候，很可能已经把训练样本自身的一些特点当作了所有潜在样本都会具有的一般性质，这样就会导致泛化性能下降。这种现象在机器学习中称为“过拟合”（overfitting）。<br>与过拟合相对的是“欠拟合”（underfitting），这是指对训练样本的一般性质尚未学好。</p><span id="more"></span><h1 id="过拟合产生的原因"><a href="#过拟合产生的原因" class="headerlink" title="过拟合产生的原因"></a>过拟合产生的原因</h1><ol><li>训练数据量的限制</li><li>训练参数的增多</li><li>学习能力过于强大（由学习算法和数据内涵共同决定）</li></ol><h1 id="防止过拟合的方法"><a href="#防止过拟合的方法" class="headerlink" title="防止过拟合的方法"></a>防止过拟合的方法</h1><ol><li>数据增强（data augmentation）：一般想要获得更好的模型，需要大量的训练参数，这也是为什么CNN网络越来越深的原因之一，而如果训练样本缺乏多样性，那再多的训练参数也毫无意义，因为这造成了过拟合，训练模型的泛化能力相应也会很差。大量数据带来的特征多样性有助于充分利用所有的训练参数。办法一般有：（1）收集更多的数据 （2）对已有的数据进行修剪（crop），翻动（flip），加光照等（3）利用生成模型（比如GAN）生成一些数据。</li><li>权重衰减（weight decay）:常用的权重衰减有L1和L2正则化，L1较L2能够获得更稀疏的参数，但L1零点不可导。在损失函数中，权重衰减是放在正则项（regulation）前面的一个系数，正则项一般指示模型的复杂度，所以权重衰减的作用是调节模型复杂度对损失函数的影响，若权重衰减很大，则复杂的模型损失函数的值也就大。</li><li>提前终止：提前终止其实是另一种正则化方法，就是在训练集和验证集上，一次迭代之后计算各自的错误率，当在验证集上的错误率最小，在没开始增大之前就停止训练，因为如果接着训练，训练集上的错误率一般是会继续减小的，但验证集上的错误率会上升，这就说明模型的泛化能力开始变差了，出现过拟合问题，及时停止能获得泛化能力更好的模型。如下图（左图是训练集错误率，右图是验证集错误率，在虚线处提前结束训练）：<br><img src="https://res.cloudinary.com/pengpeng/image/upload/v1524219052/%E8%BF%87%E6%8B%9F%E5%90%88.png" alt="image"></li><li>退出（dropout）：CNN训练过程中使用dropout是在每次训练中随机将部分神经元的权重置为0，即让一些神经元失效，这样可以缩减参数量，避免过拟合。原因在于：（1）每次迭代随机使部分神经元失效，使得模型的多样性增强，获得了类似于多个模型组合（ensemble,合唱）的效果，避免过拟合；（2）dropout其实也是一个数据增强的过程，它导致了稀疏性，使得局部数据簇差异性明显增强，有效避免过拟合。</li></ol><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ol><li>周志华.《机器学习》.清华大学出版社.第2章-模型评估与选择.</li><li><a href="https://blog.csdn.net/leo_xu06/article/details/71320727">https://blog.csdn.net/leo_xu06/article/details/71320727</a>  卷积神经网络（CNN）防止过拟合的方法.</li><li>Krizhevsky A, Sutskever I, Hinton G E. ImageNet classification with deep convolutional neural networks[C]&#x2F;&#x2F; International Conference on Neural Information Processing Systems. Curran Associates Inc. 2012:1097-1105.</li></ol>]]></content>
    
    
    <categories>
      
      <category>机器学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>机器学习</tag>
      
      <tag>过拟合</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>数学之美第二版读后感</title>
    <link href="/posts/553248e1/"/>
    <url>/posts/553248e1/</url>
    
    <content type="html"><![CDATA[<h2 id="感悟："><a href="#感悟：" class="headerlink" title="感悟："></a>感悟：</h2><ul><li>一个正确的数学模型形式上通常是简单的。从这本书中，领会到了，google背后算法的力量，数学的力量，大数据的力量。</li><li>正确的数学模型可以将一个计算量看似很大的问题的计算复杂度大大降低，这便是数学的妙用。</li><li>数学是描述世间万般表象背后规律的最好工具，它是简单的，它是美的。<span id="more"></span></li><li>计算机本身没有智能，只有极强的计算能力，只有找到解决这些问题的数学模型，才能让计算机在数据的驱动下，变得看起来智能。</li><li>数据的重要性，大量准确的数据对研发很重要，让我们迫切需要学会收集数据，处理数据，善于运用数据，才能不被数据的海洋淹没。</li><li>在计算机科学领域，一个好的算法应该像AK-47冲锋枪那样：简单、有效、可靠性好而且容易读懂（或者说易操作），而不应该是故弄玄虚。</li><li>信息指纹：是指将一段信息（文字、图片、音频、视频等）随机地映射到一个多维二进制空间中的一个点（一个二进制数字）。只要这个随机函数做得好，那么不同信息对应的这些点就不会重合，因此，这些二进制的数字就成了原来的信息所具有的独一无二的指纹。</li></ul><h2 id="推荐阅读："><a href="#推荐阅读：" class="headerlink" title="推荐阅读："></a>推荐阅读：</h2><ol><li><a href="https://book.douban.com/subject/10750155/" title="数学之美第一版">数学之美第一版</a></li><li><a href="https://book.douban.com/subject/26163454/" title="数学之美第二版">数学之美第二版</a></li><li>文本分类的经典论文，<a href="http://www.aclweb.org/anthology/P99-1022">http://www.aclweb.org/anthology/P99-1022</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>随笔感悟</category>
      
    </categories>
    
    
    <tags>
      
      <tag>读后感</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>常用Markdown语法文章写作格式</title>
    <link href="/posts/a6a7c1a2/"/>
    <url>/posts/a6a7c1a2/</url>
    
    <content type="html"><![CDATA[<p>什么是Markdown？Markdown是一种轻量级的「标记语言」，通常为程序员群体所用，目前它已是全球最大的技术分享网站 GitHub 和技术问答网站 StackOverFlow 的御用书写格式。另外有越来越多的作家和写作爱好者也用Markdown语法进行写作，因为它能让人优雅地沉浸式记录，专注内容而不是纠结排版。下面将介绍7种常用的Markdown语法文章写作格式。</p><span id="more"></span><h2 id="标题"><a href="#标题" class="headerlink" title="标题"></a>标题</h2><p>在markdown语法中，标题共分为六级，用#后面跟一个空格加上标题文字的形式即可。#的个数就是标题的级数。</p><figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs clean"># 一级标题<br>## 二级标题<br>### 三级标题<br></code></pre></td></tr></table></figure><p><img src="http://res.cloudinary.com/pengpeng/image/upload/v1520220021/%E5%B8%B8%E7%94%A8markdown%E8%AF%AD%E6%B3%95%E6%96%87%E7%AB%A0/1.png" alt="image"></p><h2 id="列表"><a href="#列表" class="headerlink" title="列表"></a>列表</h2><h3 id="无序列表"><a href="#无序列表" class="headerlink" title="无序列表"></a>无序列表</h3><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs markdown"><span class="hljs-bullet">-</span> 列表1<br><span class="hljs-bullet">-</span> 列表2<br><span class="hljs-bullet">    -</span> 列表2.1<br><span class="hljs-bullet">-</span> 列表3<br></code></pre></td></tr></table></figure><p><img src="http://res.cloudinary.com/pengpeng/image/upload/v1520220021/%E5%B8%B8%E7%94%A8markdown%E8%AF%AD%E6%B3%95%E6%96%87%E7%AB%A0/2.png" alt="image"></p><h3 id="有序列表"><a href="#有序列表" class="headerlink" title="有序列表"></a>有序列表</h3><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">1</span>. 列表<span class="hljs-number">1</span><br><span class="hljs-attribute">2</span>. 列表<span class="hljs-number">2</span><br>    <span class="hljs-attribute">1</span>. 列表<span class="hljs-number">2</span>.<span class="hljs-number">1</span><br>    <span class="hljs-attribute">2</span>. 列表<span class="hljs-number">2</span>.<span class="hljs-number">2</span><br><span class="hljs-attribute">3</span>. 列表<span class="hljs-number">3</span><br></code></pre></td></tr></table></figure><p><img src="http://res.cloudinary.com/pengpeng/image/upload/v1520220021/%E5%B8%B8%E7%94%A8markdown%E8%AF%AD%E6%B3%95%E6%96%87%E7%AB%A0/3.png" alt="image"></p><h2 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h2><figure class="highlight node-repl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs node-repl"><span class="hljs-meta prompt_">&gt;</span> <span class="language-javascript">知识就是力量！ --培根</span><br></code></pre></td></tr></table></figure><p><img src="http://res.cloudinary.com/pengpeng/image/upload/v1520220021/%E5%B8%B8%E7%94%A8markdown%E8%AF%AD%E6%B3%95%E6%96%87%E7%AB%A0/4.png" alt="image"></p><h2 id="粗体和斜体"><a href="#粗体和斜体" class="headerlink" title="粗体和斜体"></a>粗体和斜体</h2><figure class="highlight asciidoc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs asciidoc"><span class="hljs-strong">*这是斜体*</span><br><br><span class="hljs-strong">**这是粗体**</span><br></code></pre></td></tr></table></figure><p><img src="http://res.cloudinary.com/pengpeng/image/upload/v1520220021/%E5%B8%B8%E7%94%A8markdown%E8%AF%AD%E6%B3%95%E6%96%87%E7%AB%A0/5.png" alt="image"></p><h2 id="链接与图片"><a href="#链接与图片" class="headerlink" title="链接与图片"></a>链接与图片</h2><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs awk"><span class="hljs-comment">#### 插入链接</span><br>[百度](http:<span class="hljs-regexp">//</span>www.baidu.com <span class="hljs-string">&quot;百度&quot;</span>)<br><br><span class="hljs-comment">#### 插入图片</span><br>![百度](http:<span class="hljs-regexp">//</span>offlintab.firefoxchina.cn<span class="hljs-regexp">/static/img</span><span class="hljs-regexp">/search/</span>baidu_web.png <span class="hljs-string">&quot;百度图标&quot;</span>)<br></code></pre></td></tr></table></figure><p><img src="http://res.cloudinary.com/pengpeng/image/upload/v1520220021/%E5%B8%B8%E7%94%A8markdown%E8%AF%AD%E6%B3%95%E6%96%87%E7%AB%A0/6.png" alt="image"></p><h2 id="分割线"><a href="#分割线" class="headerlink" title="分割线"></a>分割线</h2><figure class="highlight asciidoc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs asciidoc">这是第一部分内容，下面是华丽丽的分割线<br><span class="hljs-bullet">***</span><br><span class="hljs-bullet"></span>这是第二部分内容<br></code></pre></td></tr></table></figure><p><img src="http://res.cloudinary.com/pengpeng/image/upload/v1520220021/%E5%B8%B8%E7%94%A8markdown%E8%AF%AD%E6%B3%95%E6%96%87%E7%AB%A0/7.png" alt="image"></p><h2 id="表格"><a href="#表格" class="headerlink" title="表格"></a>表格</h2><figure class="highlight gherkin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs gherkin">身高 |<span class="hljs-string"> 体重 </span>|<span class="hljs-string"> 年龄</span><br><span class="hljs-string">---</span>|<span class="hljs-string">---</span>|<span class="hljs-string">---</span><br><span class="hljs-string">175cm </span>|<span class="hljs-string"> 80kg </span>|<span class="hljs-string"> 30</span><br><span class="hljs-string">170cm </span>|<span class="hljs-string"> 70kg </span>|<span class="hljs-string"> 45</span><br></code></pre></td></tr></table></figure><p><img src="http://res.cloudinary.com/pengpeng/image/upload/v1520220021/%E5%B8%B8%E7%94%A8markdown%E8%AF%AD%E6%B3%95%E6%96%87%E7%AB%A0/8.png" alt="image"></p><p><em>注：推荐使用markdown语法的编辑器编辑文章，例如有道云笔记或是MarkdownPad,如果忘记了Markdown语法，还可以用辅助工具栏上面的按钮，可视化输入代码，但熟悉了之后，最好直接键入代码，达到心中无尘，码字入神的境界。</em></p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol><li><a href="http://note.youdao.com/iyoudao/?p=2411">【简明版】有道云笔记Markdown指南</a></li><li><a href="http://markdownpad.com/">MarkdownPad编辑器</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>经验技巧</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Markdown</tag>
      
      <tag>写作</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
